var ptx_lunr_search_style = "textbook";
var ptx_lunr_docs = [
{
  "id": "front-colophon",
  "level": "1",
  "url": "front-colophon.html",
  "type": "Colophon",
  "number": "",
  "title": "Colophon",
  "body": ""
},
{
  "id": "about",
  "level": "1",
  "url": "about.html",
  "type": "Section",
  "number": "1.1",
  "title": "What is this?",
  "body": " What is this?  I've been trying to work my way though \"Conceptual Mathematics\" by Lawvere and Schanuel (herein \"L&S\") on my own and it's been kind of difficult. Part of the problem is that I don't have any feedback about whether my solutions to exercises are correct or not. In an effort to resolve this, I've decided to publish my solutions as I go through it so I can discuss them on social media.  With that in mind, it seemed like this would be a good opportunity for me to simulaneously learn how to work with PreTeXt . I've done a lot of work using latex for equations before but I'm expecting this content gives me some much needed practice rendering diagrams with the TiKz package.  To start, I went through my old notes on L&S from my first attempted reading. It looks like I made to to around session 11 before I started really getting lost. Furthermore, the erasable ink I had used to solve the exercises originally had faded significantly since I originally worked on this. Since I'm expecting one of my major difficulties with this to be recreating the diagrams, I figured restarting from the very beginning would be the best way forward.  I know myself better than to make promises about the rate I get through this, but part of me thinks it would be fun to do \"cat theory on caturday\". Giving myself a day of the week to finish by might give me the push I need to get it done. Besides, everything is better with cats.  "
},
{
  "id": "session1",
  "level": "1",
  "url": "session1.html",
  "type": "Section",
  "number": "1.2",
  "title": "Session 1",
  "body": " Session 1  Since L&S start Session 1 prior to \"Part 1\", I figured I should do the same. I'm presuming the reader has access to the source material and hope that my abbreviated reproduction of the prompts this way is \"fair use\". After all, calling them \"exercises\" implies they're meant for me to work out, no?   Exercise 1:   \"...other examples of combining two objects to get a third...\"    Since I was already thinking about cats in the context of category theory, my first thought was perhaps might satisfy the pattern here. The way my cats seem to behave is based in part on certain natural instincts to hunt and hide, but they have been brought up in an environment where those tendencies manifest as behaviors that we classify as cute and playful. On closer inspection, however, I became a little less confident in this when I tried to identify the \"maps\".  The diagrams in session 1 had the following structure:   A typical diagram of the examples considered in L&S \"Session 1\"      It didn't really make sense to me to think of \"behavior\" as A in this diagram and nature\/nuture as B\/C because I could think of many situations where a single behavior might make sense in different environments. It seems more natural to think of behavior as function of environment rather than the environment as a function of the behavior. I feel like the qualities I identified might more accurately be arranged like so:   Alternate explanation structure of behavior (A), nature (B), and nurture (C)      I think some of this unease comes from the complexity associated with behavior. I think on some level I'm confusing a \"behavioral genotype\" with a \"behavioral phenotype\". Being a cat creates a behavior profile of the actions they might engage in, but the environment selects for which actions are allowed to manifest.  Let's define as \"the set of animals\". We can consider \"instincts\" as a map that maps each animal to its \"natural behavior profile\" in set B. We can also consider \"selection\" as a map that maps each animal to an \"environmental reward profile\" in set C. Under these definitions, it seems reasonable to think of the composite map (or ) producing an \"observed behavior profile\" in set D.   Full diagram of behavior expression as maps.      As an example of these maps in action, consider the case of my cats \"playing with toys\". Given that they are cats, I know that they have certain hunting related instincts as a result. However, I also restrict their environment so that they have stuffed toys instead of live prey. What we percieve as \"playing\" is really a proxy for murderous insticts with no where else to go created by the combination of their instincts and the environment.  I think I can see how this additional structure helped to clarify what had started as an vague idea. It makes a lot more sense to think of mapping from a specific cat to a behavior profile, than trying to map from a cat's behavior profile to a specific environment.     Exercise 2:   \"...describe an experiment for deciding whether two nearby points are at the same level...\"    I feel there's an obvious answer to this question: a level. By using a bit of water in a clear container, you could convievably build a rudamentary level by comparing the slant of the water against a marked line. The only tricky part is designing it so you could align it with the points you want to compare, but the basic idea is that if the points are level then the water wouldn't tilt. The authors' use of the word \"level\" in the prompt makes me think they were heavily leading the reader towards something like this. A level makes it easy to hang pictures expressly because it removes the need to measure up from the floor.    "
},
{
  "id": "session1-3",
  "level": "2",
  "url": "session1.html#session1-3",
  "type": "Example",
  "number": "1.2.1",
  "title": "Exercise 1:.",
  "body": " Exercise 1:   \"...other examples of combining two objects to get a third...\"    Since I was already thinking about cats in the context of category theory, my first thought was perhaps might satisfy the pattern here. The way my cats seem to behave is based in part on certain natural instincts to hunt and hide, but they have been brought up in an environment where those tendencies manifest as behaviors that we classify as cute and playful. On closer inspection, however, I became a little less confident in this when I tried to identify the \"maps\".  The diagrams in session 1 had the following structure:   A typical diagram of the examples considered in L&S \"Session 1\"      It didn't really make sense to me to think of \"behavior\" as A in this diagram and nature\/nuture as B\/C because I could think of many situations where a single behavior might make sense in different environments. It seems more natural to think of behavior as function of environment rather than the environment as a function of the behavior. I feel like the qualities I identified might more accurately be arranged like so:   Alternate explanation structure of behavior (A), nature (B), and nurture (C)      I think some of this unease comes from the complexity associated with behavior. I think on some level I'm confusing a \"behavioral genotype\" with a \"behavioral phenotype\". Being a cat creates a behavior profile of the actions they might engage in, but the environment selects for which actions are allowed to manifest.  Let's define as \"the set of animals\". We can consider \"instincts\" as a map that maps each animal to its \"natural behavior profile\" in set B. We can also consider \"selection\" as a map that maps each animal to an \"environmental reward profile\" in set C. Under these definitions, it seems reasonable to think of the composite map (or ) producing an \"observed behavior profile\" in set D.   Full diagram of behavior expression as maps.      As an example of these maps in action, consider the case of my cats \"playing with toys\". Given that they are cats, I know that they have certain hunting related instincts as a result. However, I also restrict their environment so that they have stuffed toys instead of live prey. What we percieve as \"playing\" is really a proxy for murderous insticts with no where else to go created by the combination of their instincts and the environment.  I think I can see how this additional structure helped to clarify what had started as an vague idea. It makes a lot more sense to think of mapping from a specific cat to a behavior profile, than trying to map from a cat's behavior profile to a specific environment.   "
},
{
  "id": "session1-4",
  "level": "2",
  "url": "session1.html#session1-4",
  "type": "Example",
  "number": "1.2.5",
  "title": "Exercise 2:.",
  "body": " Exercise 2:   \"...describe an experiment for deciding whether two nearby points are at the same level...\"    I feel there's an obvious answer to this question: a level. By using a bit of water in a clear container, you could convievably build a rudamentary level by comparing the slant of the water against a marked line. The only tricky part is designing it so you could align it with the points you want to compare, but the basic idea is that if the points are level then the water wouldn't tilt. The authors' use of the word \"level\" in the prompt makes me think they were heavily leading the reader towards something like this. A level makes it easy to hang pictures expressly because it removes the need to measure up from the floor.   "
},
{
  "id": "article1",
  "level": "1",
  "url": "article1.html",
  "type": "Section",
  "number": "2.1",
  "title": "Article 1: Sets, maps, composition",
  "body": " Article 1: Sets, maps, composition  This is technically my second time through this content and I think I made some errors in my original solutions to exercises 2-5. Rather than ignore my mistakes, I've made the decision to recreate them here and explain why I think I was wrong afterward. I hope this method will give more insight into my thought process. To prevent accidental spoilers, this will be treated as a \"Hidden Exercise 10\".   Exercise 1:   \"...understand how we got diagrams...\"    Okay let's start by recreating diagram (i).   The original associative law diagram (i) from L&S Article 1.      For diagram (iv), we drop set C and connect B directly to D.   Completed associative law diagram (iv) from L&S Article 1.      To get from here to diagram (v), we drop set B and connect A directly to D.   Completed associative law diagram (v) from L&S Article 1.      As expected, this diagram is an exact match of diagram (iii).     Exercise 2   How many different maps are there with domain and codomain ?...    So I approached this like I would an algebraic function like , but instead of feeding in a number I'm feeding in John ( ), Mary ( ) or Sam ( ) and getting out a breakfast order at a diner that only serves eggs ( ) or coffee ( ) and has a 1 item limit per order.  I know that the number of outcomes is going to be the same for each person, so it made sense to focus on one person at a time. I imagined John's breakfast order, , as having 3 possible outcomes.   John orders eggs:  John orders coffee:  John fails to place an order at all: is undefined   Likewise, Mary and Sam have the same 3 possible outcomes: {eggs,coffee,undefined}. Since these events are independent of each other, the total number of possible outcomes is maps in total.     Exercise 3   Same, but for maps     I thought of this function like the \"favorite person\" map example from the reading. Using John as an example, I imagined 4 possible character roles in a hypothetical Hollywood love triangle:   John is in love with Mary.  John is in love with Sam.  John is a narcissist, in love with himself:  John is a psychopath, incapable of love: is undefined   Given an analogous set of 4 outcomes for Mary and Sam, the total number of possible plot outcomes is .     Exercise 4   Same, but for maps     I imagined this one as a \"mystery breakfast order\". I'm the a waiter in a diner delivering one order of eggs and one order of coffee to a table where John, Mary, and Sam are seated. The map tells me who ordered a given dish. Like before, I'll consider one example at a time. There are 4 possible outcomes for the source of the eggs:   John ordered the eggs:  Mary ordered the eggs:  Sam ordered the eggs:  Nobody ordered eggs: is undefined   Since there must likewise be 4 sources for the coffee, the total number of possible outcomes is .     Exercise 5   Same, but for maps     At this point I had observed a pattern and attempted to generalize. Following my reasoning from exercises 2-4, I notice all my answers fit a pattern:   In exercise 5, the size of the domain and codmain would each be 2. Evaluating the expression above gives us possible maps.     Exercise 6   How many maps satisfy ?    This is where I started to notice some problems with my previous reasoning. In order for me to talk about the properties of , it didn't make sense for to be \"undefined\" for an element in my domain. If I didn't get something \"out\", I wouldn't be able to feed it back in. So instead of considering all possible \"love triangles\" I identified earlier, I could narrow my search down to a more limited set of maps by excluding the \"psychopaths\" from my romance movies because they make it impossible to produce a sequel (more on that idea later).  This narrowed my search, but 27 is still too many for me too sort out by hand so I started looking for ways to break it down further. I knew I could satisfy the constraint with the identity map because clearly . I also know I could satisfy with a \"constant function\" such as the following:  Furthermore, there would need to be a total of 3 such \"constant functions\" because you'd need one for each of the 3 possible destinations. At that point it seemed clear I was still missing some. If I could construct a function with 1 arrow to each point and also a function with 3 arrows to a single point, it seemed reasonable to assume there'd be a class of maps with 2 arrows leading to a single point.  Let's consider the case where that point with two arrows leading in to be \"John\". One of the arrows leading to John has to be from himself for to be true, but the other arrow could originate at either Mary or Sam. Given these two possible maps exist for each person, we'd have maps of this type.  Putting everything together, some patterns seem to emerge when I listed these out in a table using binomials.     number of fixed points  number of maps  as binomial    1  3     2  6     3  1      Adding up all of these up gives us total of possible maps.     Exercise 7   How many maps satisfy ?    This was made even easier by the pattern I noticed in the previous example. Given that there are only two elements in the domain, there are maps with 1 fixed point and map with 2 fixed points (namely, ) for total of .     Exercise 8   ... for which ?...    None? B has fewer choices in it than A, so when f maps from A to B it must destroy at least one of them. The map g would not be able to produce 3 outputs from only 2 inputs, so there's no possible way for the composition to cover all elements of A.     Exercise 9   ... for which ?...    I started here by considering a blank diagram that would fit the composition, and start filling it in one point at a time.   Empty diagram for      Since I know each point has to end up back where it started, the only real \"choice\" is which of the 3 middle points the path goes through.   Diagram of potential paths for first point in      Once I fix the first path, the next point only has two possible intermediary points that it can go through.   Diagram of potential paths for second point in      Given that there were 3 choices for the first path and 2 choices for the second, there's a total of paths altogether.  This also makes sense as the binomial , because we have 3 possible intermediary points and we need to choose 2 of them.     Exercise 10   [hidden]    What first clued me in that my answers to exercises 2-5 might be wrong was the hint about \"BOOKKEEPING rules\" at the very end of the section. Looking back, it's seem like my programming background may have clouded my understanding of \"map\".  I was thinking about a \"map\" like I would a \"function\" in a program. In this analogy I had interpreted \"domain\" as my \"input type\" and \"codomain\" as \"output type\". The flaw in this reasoning is that I was allowing \"functions\" to \"error\", which is not true under the definitions of \"map\" and \"domain\" that were presented. If the map produced something \"undefined\", it would be inaccurate to include in the domain of to begin with.  This means that the generalized formula I came up with earlier is \"off by 1\", and the corrected formula should be as follows:   Under these revised definitions, the answers to excercises 2-5 should be as follows:     Excercise  Size of domain  Size of codomain  Expression  Result    2  3  2  2^3  8    3  3  3  3^3  27    4  2  3  3^2  9    5  2  2  2^2  4     I can see why these definitions simplify the process of talking about \"bookkeeping\" for the number maps. It's much easier to count the maps if we limit ourselves to the ones that are well-formed to start with. I'm left wondering if there's a situation where having an \"undefined\" output token like I used might be a useful construct, but the costs seem to far outweigh the benefits.  I can also see some programming parallels here between the \"switch\" statement in C-like languages and the \"match\" statement in Rust. The Rust compiler goes an extra step to verify that every possible outcome has been handled before even attempting to complile the code you give it. This provides an extra level of assurance that these functions will behave as expected.    "
},
{
  "id": "article1-3",
  "level": "2",
  "url": "article1.html#article1-3",
  "type": "Example",
  "number": "2.1.1",
  "title": "Exercise 1:.",
  "body": " Exercise 1:   \"...understand how we got diagrams...\"    Okay let's start by recreating diagram (i).   The original associative law diagram (i) from L&S Article 1.      For diagram (iv), we drop set C and connect B directly to D.   Completed associative law diagram (iv) from L&S Article 1.      To get from here to diagram (v), we drop set B and connect A directly to D.   Completed associative law diagram (v) from L&S Article 1.      As expected, this diagram is an exact match of diagram (iii).   "
},
{
  "id": "article1-4",
  "level": "2",
  "url": "article1.html#article1-4",
  "type": "Example",
  "number": "2.1.5",
  "title": "Exercise 2.",
  "body": " Exercise 2   How many different maps are there with domain and codomain ?...    So I approached this like I would an algebraic function like , but instead of feeding in a number I'm feeding in John ( ), Mary ( ) or Sam ( ) and getting out a breakfast order at a diner that only serves eggs ( ) or coffee ( ) and has a 1 item limit per order.  I know that the number of outcomes is going to be the same for each person, so it made sense to focus on one person at a time. I imagined John's breakfast order, , as having 3 possible outcomes.   John orders eggs:  John orders coffee:  John fails to place an order at all: is undefined   Likewise, Mary and Sam have the same 3 possible outcomes: {eggs,coffee,undefined}. Since these events are independent of each other, the total number of possible outcomes is maps in total.   "
},
{
  "id": "article1-5",
  "level": "2",
  "url": "article1.html#article1-5",
  "type": "Example",
  "number": "2.1.6",
  "title": "Exercise 3.",
  "body": " Exercise 3   Same, but for maps     I thought of this function like the \"favorite person\" map example from the reading. Using John as an example, I imagined 4 possible character roles in a hypothetical Hollywood love triangle:   John is in love with Mary.  John is in love with Sam.  John is a narcissist, in love with himself:  John is a psychopath, incapable of love: is undefined   Given an analogous set of 4 outcomes for Mary and Sam, the total number of possible plot outcomes is .   "
},
{
  "id": "article1-6",
  "level": "2",
  "url": "article1.html#article1-6",
  "type": "Example",
  "number": "2.1.7",
  "title": "Exercise 4.",
  "body": " Exercise 4   Same, but for maps     I imagined this one as a \"mystery breakfast order\". I'm the a waiter in a diner delivering one order of eggs and one order of coffee to a table where John, Mary, and Sam are seated. The map tells me who ordered a given dish. Like before, I'll consider one example at a time. There are 4 possible outcomes for the source of the eggs:   John ordered the eggs:  Mary ordered the eggs:  Sam ordered the eggs:  Nobody ordered eggs: is undefined   Since there must likewise be 4 sources for the coffee, the total number of possible outcomes is .   "
},
{
  "id": "article1-7",
  "level": "2",
  "url": "article1.html#article1-7",
  "type": "Example",
  "number": "2.1.8",
  "title": "Exercise 5.",
  "body": " Exercise 5   Same, but for maps     At this point I had observed a pattern and attempted to generalize. Following my reasoning from exercises 2-4, I notice all my answers fit a pattern:   In exercise 5, the size of the domain and codmain would each be 2. Evaluating the expression above gives us possible maps.   "
},
{
  "id": "article1-8",
  "level": "2",
  "url": "article1.html#article1-8",
  "type": "Example",
  "number": "2.1.9",
  "title": "Exercise 6.",
  "body": " Exercise 6   How many maps satisfy ?    This is where I started to notice some problems with my previous reasoning. In order for me to talk about the properties of , it didn't make sense for to be \"undefined\" for an element in my domain. If I didn't get something \"out\", I wouldn't be able to feed it back in. So instead of considering all possible \"love triangles\" I identified earlier, I could narrow my search down to a more limited set of maps by excluding the \"psychopaths\" from my romance movies because they make it impossible to produce a sequel (more on that idea later).  This narrowed my search, but 27 is still too many for me too sort out by hand so I started looking for ways to break it down further. I knew I could satisfy the constraint with the identity map because clearly . I also know I could satisfy with a \"constant function\" such as the following:  Furthermore, there would need to be a total of 3 such \"constant functions\" because you'd need one for each of the 3 possible destinations. At that point it seemed clear I was still missing some. If I could construct a function with 1 arrow to each point and also a function with 3 arrows to a single point, it seemed reasonable to assume there'd be a class of maps with 2 arrows leading to a single point.  Let's consider the case where that point with two arrows leading in to be \"John\". One of the arrows leading to John has to be from himself for to be true, but the other arrow could originate at either Mary or Sam. Given these two possible maps exist for each person, we'd have maps of this type.  Putting everything together, some patterns seem to emerge when I listed these out in a table using binomials.     number of fixed points  number of maps  as binomial    1  3     2  6     3  1      Adding up all of these up gives us total of possible maps.   "
},
{
  "id": "article1-9",
  "level": "2",
  "url": "article1.html#article1-9",
  "type": "Example",
  "number": "2.1.11",
  "title": "Exercise 7.",
  "body": " Exercise 7   How many maps satisfy ?    This was made even easier by the pattern I noticed in the previous example. Given that there are only two elements in the domain, there are maps with 1 fixed point and map with 2 fixed points (namely, ) for total of .   "
},
{
  "id": "article1-10",
  "level": "2",
  "url": "article1.html#article1-10",
  "type": "Example",
  "number": "2.1.12",
  "title": "Exercise 8.",
  "body": " Exercise 8   ... for which ?...    None? B has fewer choices in it than A, so when f maps from A to B it must destroy at least one of them. The map g would not be able to produce 3 outputs from only 2 inputs, so there's no possible way for the composition to cover all elements of A.   "
},
{
  "id": "article1-11",
  "level": "2",
  "url": "article1.html#article1-11",
  "type": "Example",
  "number": "2.1.13",
  "title": "Exercise 9.",
  "body": " Exercise 9   ... for which ?...    I started here by considering a blank diagram that would fit the composition, and start filling it in one point at a time.   Empty diagram for      Since I know each point has to end up back where it started, the only real \"choice\" is which of the 3 middle points the path goes through.   Diagram of potential paths for first point in      Once I fix the first path, the next point only has two possible intermediary points that it can go through.   Diagram of potential paths for second point in      Given that there were 3 choices for the first path and 2 choices for the second, there's a total of paths altogether.  This also makes sense as the binomial , because we have 3 possible intermediary points and we need to choose 2 of them.   "
},
{
  "id": "article1-12",
  "level": "2",
  "url": "article1.html#article1-12",
  "type": "Example",
  "number": "2.1.17",
  "title": "Exercise 10.",
  "body": " Exercise 10   [hidden]    What first clued me in that my answers to exercises 2-5 might be wrong was the hint about \"BOOKKEEPING rules\" at the very end of the section. Looking back, it's seem like my programming background may have clouded my understanding of \"map\".  I was thinking about a \"map\" like I would a \"function\" in a program. In this analogy I had interpreted \"domain\" as my \"input type\" and \"codomain\" as \"output type\". The flaw in this reasoning is that I was allowing \"functions\" to \"error\", which is not true under the definitions of \"map\" and \"domain\" that were presented. If the map produced something \"undefined\", it would be inaccurate to include in the domain of to begin with.  This means that the generalized formula I came up with earlier is \"off by 1\", and the corrected formula should be as follows:   Under these revised definitions, the answers to excercises 2-5 should be as follows:     Excercise  Size of domain  Size of codomain  Expression  Result    2  3  2  2^3  8    3  3  3  3^3  27    4  2  3  3^2  9    5  2  2  2^2  4     I can see why these definitions simplify the process of talking about \"bookkeeping\" for the number maps. It's much easier to count the maps if we limit ourselves to the ones that are well-formed to start with. I'm left wondering if there's a situation where having an \"undefined\" output token like I used might be a useful construct, but the costs seem to far outweigh the benefits.  I can also see some programming parallels here between the \"switch\" statement in C-like languages and the \"match\" statement in Rust. The Rust compiler goes an extra step to verify that every possible outcome has been handled before even attempting to complile the code you give it. This provides an extra level of assurance that these functions will behave as expected.   "
},
{
  "id": "sec-session2",
  "level": "1",
  "url": "sec-session2.html",
  "type": "Section",
  "number": "2.2",
  "title": "Session 2",
  "body": " Session 2  It feels kind of silly to post solutions to a problem set that includes the answers already, but this seems like a good opportunity to validate my generalization from last week.   Problems on the number of maps from one set to another   How many maps...    We have answers here, so let's confirm the results of the generalization from Article 1:     #    Expression  Result  Correct    1  4  1   1  YES    2  1  4   4  YES    3  0  4   1  YES    4  4  0   0  YES    5  0  0   \"it depends\"  \"mostly\"     The generalization seems to hold up, provided we define our exponential operator in such a way that . This is a common practice, but I've also seen situations where is left undefined instead. In this context, the answer of 1 to problem 5 makes more sense than than the alternative. In programming terms, it seems perfectly reasonable to think of \"no op\" as a \"function\" so there should be an analogous \"null map\" that maps from nothing to nothing.    "
},
{
  "id": "sec-session2-3",
  "level": "2",
  "url": "sec-session2.html#sec-session2-3",
  "type": "Example",
  "number": "2.2.1",
  "title": "Problems on the number of maps from one set to another.",
  "body": " Problems on the number of maps from one set to another   How many maps...    We have answers here, so let's confirm the results of the generalization from Article 1:     #    Expression  Result  Correct    1  4  1   1  YES    2  1  4   4  YES    3  0  4   1  YES    4  4  0   0  YES    5  0  0   \"it depends\"  \"mostly\"     The generalization seems to hold up, provided we define our exponential operator in such a way that . This is a common practice, but I've also seen situations where is left undefined instead. In this context, the answer of 1 to problem 5 makes more sense than than the alternative. In programming terms, it seems perfectly reasonable to think of \"no op\" as a \"function\" so there should be an analogous \"null map\" that maps from nothing to nothing.   "
},
{
  "id": "sec-session3",
  "level": "1",
  "url": "sec-session3.html",
  "type": "Section",
  "number": "2.3",
  "title": "Session 3",
  "body": " Session 3  This week's reading basically confirmed my generalization from Article 1. I found it somewhat interesting how I instictively happened to use a \"vector norm\" notation, , for the size of domain and codomain while L&S goes through both \"number sign\", , and \"absolute value\", . It seems so natural to want a symbol for \"number of elements\".  For present, I suppose I'll follow the book's convention and save myself two extra characters. It does leave me wondering what kind of distance metrics might be useful for talking about the \"sameness\" of two maps.   Exercise 1   ...Two of the expressions make sense...    So the trick with the map composition is to evaluate them from \"right to left\". The expression for (a) of could be translated into a sequence of steps as follows:   Apply map  Apply map  Apply map  Apply map   Notice how the codomain of each step matches the domain of the following step. Our composite map follows a path from , so it's domain is the \"source\" and codomain is the \"destination\" . Alternatively written, .  Moving on to (b), something interesting happens when we attempt to list out the steps of :   Apply map  Apply map  Apply map   Notice how the codomain for step 2 of is not the same as the domain of in step 3. This map composition is not well defined because the map will not have a valid input to work with.  Having already identified the one that \"doesn't make sense\", let's move directly onto identifying the domain and codomain of the final composition (c) . Applied from right to left, this gives us:   As expected, the domains and codomains link up correctly at each step. This means that the domain of is (same as the domain of the first map applied, ) and the codomain is (same as the codomain of the last map applied, ).     Exercise 2   ...follow the arrows in the diagram with your finger...    Let's start by recreating the source diagram:   Recreation of diagram used in L&S Session 3 Exercise 2      For composition (a), the path would look like this:   Recreation of finger tracing steps for L&S Session 3 Exercise 2 Part (a)      For composition (b) we can only trace out the first two steps. The final map fails because the arrow is pointing the wrong direction.   Recreation of finger tracing steps for L&S Session 3 Exercise 2 Part (b)      Our final composition is interesting in that takes us through map twice.   Recreation of finger tracing steps for L&S Session 3 Exercise 2 Part (c)        "
},
{
  "id": "sec-session3-4",
  "level": "2",
  "url": "sec-session3.html#sec-session3-4",
  "type": "Example",
  "number": "2.3.1",
  "title": "Exercise 1.",
  "body": " Exercise 1   ...Two of the expressions make sense...    So the trick with the map composition is to evaluate them from \"right to left\". The expression for (a) of could be translated into a sequence of steps as follows:   Apply map  Apply map  Apply map  Apply map   Notice how the codomain of each step matches the domain of the following step. Our composite map follows a path from , so it's domain is the \"source\" and codomain is the \"destination\" . Alternatively written, .  Moving on to (b), something interesting happens when we attempt to list out the steps of :   Apply map  Apply map  Apply map   Notice how the codomain for step 2 of is not the same as the domain of in step 3. This map composition is not well defined because the map will not have a valid input to work with.  Having already identified the one that \"doesn't make sense\", let's move directly onto identifying the domain and codomain of the final composition (c) . Applied from right to left, this gives us:   As expected, the domains and codomains link up correctly at each step. This means that the domain of is (same as the domain of the first map applied, ) and the codomain is (same as the codomain of the last map applied, ).   "
},
{
  "id": "sec-session3-5",
  "level": "2",
  "url": "sec-session3.html#sec-session3-5",
  "type": "Example",
  "number": "2.3.2",
  "title": "Exercise 2.",
  "body": " Exercise 2   ...follow the arrows in the diagram with your finger...    Let's start by recreating the source diagram:   Recreation of diagram used in L&S Session 3 Exercise 2      For composition (a), the path would look like this:   Recreation of finger tracing steps for L&S Session 3 Exercise 2 Part (a)      For composition (b) we can only trace out the first two steps. The final map fails because the arrow is pointing the wrong direction.   Recreation of finger tracing steps for L&S Session 3 Exercise 2 Part (b)      Our final composition is interesting in that takes us through map twice.   Recreation of finger tracing steps for L&S Session 3 Exercise 2 Part (c)       "
},
{
  "id": "article2",
  "level": "1",
  "url": "article2.html",
  "type": "Section",
  "number": "3.1",
  "title": "Article 2: Isomorphisms, Part 1",
  "body": " Article 2: Isomorphisms, Part 1  Time to undo things! I think I'm coming into this section with a decent grasp of what an isomorphism is already, but this idea that there are two inverses instead of just one still feels a little weird to me. I find myself reminding myself that this something I already do, but now I'm just being more specific with my language.  If teaching has taught me anything, it's that people sometimes have very different ideas about what is meant by seemingly simple phrases like \"the opposite of two\". It's often too easy to fall into a trap in assuming that since I'm thinking of two as a position on the number line and the opposite of that is defined relative to the origin, but \"negative two\" is really only one possible answer. If the question \"what's the oppositve of two?\" had beem asked in the kitchen instead of a math class, there's a case to be made that \"one half\" is actually the more appropriate response. The opposite of doubling a recipe is halving one. There might even be situations where it may be helpful to think of \"opposite\" as both the reciprocal and negation, as you would with slopes of perpendicular lines.  For now, I think I need to be paying attention to the domains and codomains of the maps because that's where I was getting tripped up earlier.   Exercise 1   Show that...is an isomorphism.    For the reflexive property (R), we can note that acts as it's own inverse. Since it leaves every object in place, applying it a second time would also do nothing so . If we define and , then the statements and hold true and is an isomorphism.  For the symmetric property (S), we're given that is an isomorphism with inverse . By the definition of inverse, we know and . These are precisely the two statements that define as the inverse of , just with the order reversed. By including both possible composition orders in the definition, it guarantees that is the inverse of if and only if is the inverse of .  For the transitive property, we're given that and are both isomorphisms. Let be the inverse of such that and , and let be the inverse of such that and . Consider the composition :   Consider . By the associative property, we have . Since , it follows that .  Consider . By the associative property, we have . Since , it follows that   Given and , we can then conclude that is an isomorphism with an inverse of .      Exercise 2   Suppose and are both inverses...    By definition, being an inverse implies and . Likewise, being an inverse implies and .  Suppose that . There would need to exist some with . Denote these values and for some with .  Consider the point: . Since , we must have . However, since we can also write this as . By the associative property, . Having shown that and , this contradicts our earlier assumption that and completes our proof that by contradiction.     Exercise 3   If has an inverse, then satistfies the two cancellation laws...    Part (a) is given in the text, so lets focus on (b). If , it follows that .  By the associative property, and . Thus, . By similar reasoning, .  It follows that if and only if which completes our proof.     Exercise 4   For each of the five maps above, decide whether it is invertable...    Let's break it down one map at time.    with has a well-defined inverse of .   with has a well-defined inverse of .   with does not have a well-defined inverse. We can't ever recover the negative values after squaring them.   with also does not have a well-defined inverse. Limiting the codomain to the produced outputs doesn't change the fact that we're losing sign information through the map.   with feels like a trick question. For most intents and purposes, we should have but the domain and codomain don't look right here. Specifically, we have a problem where is undefined and another problem where for . Based on these observations, I'd have to conclude that is not invertable.   Having still not entirely convinced myself these are correct, I thought it might be helpful to look at the graphs. I started with the first pair to make sure its what I expected.   Comparison of graphs for Article II, Exercise 4.1      One of the way's I think of my inverse function is as \"a reflection over the line \". This works nicely for a visual confirmation because I can tell that this relationship will hold for the rest of the lines. My confidence in being invertible is very high.  Now let's take a look at the relation between and :   Comparison of graphs for Article II, Exercise 4.2-4.4      Notice how the inverse function only replicates half of the parabola when reflected over the diagonal. My justification for thinking that (2) is an isomorphism but (3) and (4) are not is that every point in the domain needs to have an inverse that these can be matched up with a point in the codomain (both \"onto\" and \"one-to-one\"). By including negative numbers in our domain, we're essentially allowing un-invertable points to be passed in.  Now let's take a look at the final functions:   Comparison of graphs for Article II, Exercise 4.5      On the surface, this looks like precisely the function we're looking for. It looks like a pretty good \"mirror image\". The problem comes when consider the domain and codomain. The map is only valid for positive values, so let's crop and zoom in our previous graph.   Cropped and zoomed graph for Article II, Exercise 4.5      Notice how the graph of seemingly has an asymptote at and gets \"cut-off\" when it hits the x-axis. For us to consider this as an inverse map, the domain of the inverse should match the codomain of the map and vice versa. Even though these maps meet my reflection criteria, the fact that is undefined for and when domain and codomain are supposed to both be disqualifies it from being considered an inverse to the map .  Perhaps what I should really be doing is looking at the compositions. We can express as or we can express as . These expressions both simplify to just , but the holes left in the map when we divide by zero at or don't just disappear.    While I'm in the process of undo-ing things, I need to work on undo-ing my tendancy to rush things like this. I need to remind myself that learing this stuff isn't a race. I'm going to use the subdivisions in Article II to break this up into smaller sections so I can give it more time to sink in.  "
},
{
  "id": "article2-5",
  "level": "2",
  "url": "article2.html#article2-5",
  "type": "Example",
  "number": "3.1.1",
  "title": "Exercise 1.",
  "body": " Exercise 1   Show that...is an isomorphism.    For the reflexive property (R), we can note that acts as it's own inverse. Since it leaves every object in place, applying it a second time would also do nothing so . If we define and , then the statements and hold true and is an isomorphism.  For the symmetric property (S), we're given that is an isomorphism with inverse . By the definition of inverse, we know and . These are precisely the two statements that define as the inverse of , just with the order reversed. By including both possible composition orders in the definition, it guarantees that is the inverse of if and only if is the inverse of .  For the transitive property, we're given that and are both isomorphisms. Let be the inverse of such that and , and let be the inverse of such that and . Consider the composition :   Consider . By the associative property, we have . Since , it follows that .  Consider . By the associative property, we have . Since , it follows that   Given and , we can then conclude that is an isomorphism with an inverse of .    "
},
{
  "id": "article2-6",
  "level": "2",
  "url": "article2.html#article2-6",
  "type": "Example",
  "number": "3.1.2",
  "title": "Exercise 2.",
  "body": " Exercise 2   Suppose and are both inverses...    By definition, being an inverse implies and . Likewise, being an inverse implies and .  Suppose that . There would need to exist some with . Denote these values and for some with .  Consider the point: . Since , we must have . However, since we can also write this as . By the associative property, . Having shown that and , this contradicts our earlier assumption that and completes our proof that by contradiction.   "
},
{
  "id": "article2-7",
  "level": "2",
  "url": "article2.html#article2-7",
  "type": "Example",
  "number": "3.1.3",
  "title": "Exercise 3.",
  "body": " Exercise 3   If has an inverse, then satistfies the two cancellation laws...    Part (a) is given in the text, so lets focus on (b). If , it follows that .  By the associative property, and . Thus, . By similar reasoning, .  It follows that if and only if which completes our proof.   "
},
{
  "id": "article2-8",
  "level": "2",
  "url": "article2.html#article2-8",
  "type": "Example",
  "number": "3.1.4",
  "title": "Exercise 4.",
  "body": " Exercise 4   For each of the five maps above, decide whether it is invertable...    Let's break it down one map at time.    with has a well-defined inverse of .   with has a well-defined inverse of .   with does not have a well-defined inverse. We can't ever recover the negative values after squaring them.   with also does not have a well-defined inverse. Limiting the codomain to the produced outputs doesn't change the fact that we're losing sign information through the map.   with feels like a trick question. For most intents and purposes, we should have but the domain and codomain don't look right here. Specifically, we have a problem where is undefined and another problem where for . Based on these observations, I'd have to conclude that is not invertable.   Having still not entirely convinced myself these are correct, I thought it might be helpful to look at the graphs. I started with the first pair to make sure its what I expected.   Comparison of graphs for Article II, Exercise 4.1      One of the way's I think of my inverse function is as \"a reflection over the line \". This works nicely for a visual confirmation because I can tell that this relationship will hold for the rest of the lines. My confidence in being invertible is very high.  Now let's take a look at the relation between and :   Comparison of graphs for Article II, Exercise 4.2-4.4      Notice how the inverse function only replicates half of the parabola when reflected over the diagonal. My justification for thinking that (2) is an isomorphism but (3) and (4) are not is that every point in the domain needs to have an inverse that these can be matched up with a point in the codomain (both \"onto\" and \"one-to-one\"). By including negative numbers in our domain, we're essentially allowing un-invertable points to be passed in.  Now let's take a look at the final functions:   Comparison of graphs for Article II, Exercise 4.5      On the surface, this looks like precisely the function we're looking for. It looks like a pretty good \"mirror image\". The problem comes when consider the domain and codomain. The map is only valid for positive values, so let's crop and zoom in our previous graph.   Cropped and zoomed graph for Article II, Exercise 4.5      Notice how the graph of seemingly has an asymptote at and gets \"cut-off\" when it hits the x-axis. For us to consider this as an inverse map, the domain of the inverse should match the codomain of the map and vice versa. Even though these maps meet my reflection criteria, the fact that is undefined for and when domain and codomain are supposed to both be disqualifies it from being considered an inverse to the map .  Perhaps what I should really be doing is looking at the compositions. We can express as or we can express as . These expressions both simplify to just , but the holes left in the map when we divide by zero at or don't just disappear.   "
},
{
  "id": "article2-p2",
  "level": "1",
  "url": "article2-p2.html",
  "type": "Section",
  "number": "3.2",
  "title": "Article 2: Isomorphisms, Part 2",
  "body": " Article 2: Isomorphisms, Part 2  Choosing to break this article into subsections means that I can take my time with the only excercise. With that in mind, I'm going to use the opportunity to work on improving my latex skills by attempting to enumerate the diagrams of these solutions instead of just counting them. Sounds like fun, huh?   Exercise 5   ...how many maps are there with ?...    Let's begin by reproducing the internal diagram of :   Recreation of diagram from Article II, Exercise 5      Since I want , I know that needs to send each element of to something that will return to that value after applying . It seems reasonable to assume that the \"possible arrows\" for must come from the reversed arrows of as shown here:   Diagram from Article II, Exercise 5 but with reversed arrows      Since there are three options for where sends , two options for where it sends , and these choices are independent of each other, the total number of possibilities is the product: . This lends them nicely to a 3x2 grid where the column is the choice of where to send and row is the choice of where to send .   Grid of potential solutions for in Article II, Exercise 5      Now, that we've drawn all possible choices for , let's choose one and see how many options we might have for with the same property . I'll start by taking a single one:   One possible solution to from Article II, Exercise 5      Like before, I know my map must contain the reverse of the arrows from my chosen map , but fixing those arrows still leaves 3 points that are unaccounted for in the map. For each of those 3 possible sources, there are two possible destinations.   Possible choices for given a choice of      Since those choices are independent of each other, that means the total number of combinations is .   Grid of potential maps for given my chosen      With that, we've completed the exercise (and then some).    "
},
{
  "id": "article2-p2-3",
  "level": "2",
  "url": "article2-p2.html#article2-p2-3",
  "type": "Example",
  "number": "3.2.1",
  "title": "Exercise 5.",
  "body": " Exercise 5   ...how many maps are there with ?...    Let's begin by reproducing the internal diagram of :   Recreation of diagram from Article II, Exercise 5      Since I want , I know that needs to send each element of to something that will return to that value after applying . It seems reasonable to assume that the \"possible arrows\" for must come from the reversed arrows of as shown here:   Diagram from Article II, Exercise 5 but with reversed arrows      Since there are three options for where sends , two options for where it sends , and these choices are independent of each other, the total number of possibilities is the product: . This lends them nicely to a 3x2 grid where the column is the choice of where to send and row is the choice of where to send .   Grid of potential solutions for in Article II, Exercise 5      Now, that we've drawn all possible choices for , let's choose one and see how many options we might have for with the same property . I'll start by taking a single one:   One possible solution to from Article II, Exercise 5      Like before, I know my map must contain the reverse of the arrows from my chosen map , but fixing those arrows still leaves 3 points that are unaccounted for in the map. For each of those 3 possible sources, there are two possible destinations.   Possible choices for given a choice of      Since those choices are independent of each other, that means the total number of combinations is .   Grid of potential maps for given my chosen      With that, we've completed the exercise (and then some).   "
},
{
  "id": "article2-p3",
  "level": "1",
  "url": "article2-p3.html",
  "type": "Section",
  "number": "3.3",
  "title": "Article 2: Isomorphisms, Part 3",
  "body": " Article 2: Isomorphisms, Part 3  As I wrap up Article 2, I keep thinking back to the last expression in Exercise 4 and wonder if there's a better way of articulating what I saw. I'm starting to see more of the connection with the injective (one-to-one) and surjective (onto) properties I typically associate with isomorphisms are effectively guaranteed by the definitions of retraction and section.  I also find the symbol choice of in this part of Article 2 somewhat curious. The programmer in me wants to associate with a \"type\" or \"template\", while the mathematician in me is quietly screaming \"TOPOLOGY!\". I suppose I'll have to keep going to find out who's right-er.   Exercise 6   If the map has a retraction, ...    Essentially the argument is the same as the preceeding proof with minor substitutions. We're given that has a retraction, so we have some with the property .   Possible compositions given has a retraction.      This external diagram implies that we can define a map by using the composition . All that remains is to verify that it satistfies the required equation:   And that completes the proof.     Exercise 7   Suppose the map has a section, ...    Let's get our bearings straight with a diagram. We know has a section satisfying . We also have a set with a pair of maps and .   External diagram of given information in Article 2 Exercise 7.      Now lets further assume that , so that we have some such that . Consider the point defined by . If , then it must also hold true that for all . If we expand this, we get the following:       This contradicts our earlier assumption that and completes the proof. It's a little easier to see what's going on if we rearrange the diagram some:   Diagram of compositions induced by assumptions of Article 2 Exercise 7.      As long as , then . Since we've defined as a section of , it means that . Therefore, holds if and only if .     Exercise 8   ...the composite of two maps, each having sections, ...    Suppose we have composable maps and with respective sections and . By definition, and .  Based on this information, the composition has a section determined by the reversed composition of the sections . All we need to do is to show that .       It's easy to see why this order reversal is necessary by examining a diagram:   External diagram of given information in Article 2 Exercise 8.         Exercise 9   Suppose is a retraction of ...    Knowing that is a retraction of tells us that . If we define the map , we can prove that through the use of the associative property.      That completes the proof that is idempotent.  If we further assume that is an isomorphism, then we have some inverse function such that and . Since this inverse is unique, it follows that . Consequently, .     Exercise 10   If are both isomorphisms...    I think this one is a little easier to see with a diagram.   External diagram of given information in Article 2 Exercise 10.      Basically, to go backward to from , the order of inverses needs to also be reversed. We can prove this algebraically also.  Since is an isomorphism, it follows that and . Likewise, being an isomorphism implies and . The composition can be shown to sasify the conditions for being the inverse of .  First, we must demonstrate that :     Second, we must demonstrate that :     This complete our proof that      Exercise 11   If ...    Any that maps each element in to a unique element in should do the trick here.   Hypothetical for Article 2 Exercise 11      This has a unique inverse that reverses each of these arrows:   Corresponding for Article 2 Exercise 11      If we have , we'd be unable to define an isomorphism from because we don't have enough points to match them up one by one. One of those points in will have two arrows leading in and cause us to lose information about where we came from in the process:   Illustration of invertability problem with         Exercise 12   How many isomorphisms are there...    Essentially, the number of isomorphisms is a permutation problem. If we decide on a fixed order of elements in , each choice uses up the respective point in that it gets matched to. Therefore, we have 3 choices for Fatima, 2 choices for Omer, and 1 choice for Alysia, or possible choices all together.  The number of automorphisms should be the same, namely 6. It doesn't matter if we're assigning Fatima to or , it's precisely the same number of choices.  The number 27 in this context is the total number of possible maps from a set of 3 elements to another set of 3 elements: . This is the formula we arrived at after Article 1. Clearly \"the number of invertable maps\" should be less than \"the total number of maps\" because not every map will be invertable.    "
},
{
  "id": "article2-p3-4",
  "level": "2",
  "url": "article2-p3.html#article2-p3-4",
  "type": "Example",
  "number": "3.3.1",
  "title": "Exercise 6.",
  "body": " Exercise 6   If the map has a retraction, ...    Essentially the argument is the same as the preceeding proof with minor substitutions. We're given that has a retraction, so we have some with the property .   Possible compositions given has a retraction.      This external diagram implies that we can define a map by using the composition . All that remains is to verify that it satistfies the required equation:   And that completes the proof.   "
},
{
  "id": "article2-p3-5",
  "level": "2",
  "url": "article2-p3.html#article2-p3-5",
  "type": "Example",
  "number": "3.3.3",
  "title": "Exercise 7.",
  "body": " Exercise 7   Suppose the map has a section, ...    Let's get our bearings straight with a diagram. We know has a section satisfying . We also have a set with a pair of maps and .   External diagram of given information in Article 2 Exercise 7.      Now lets further assume that , so that we have some such that . Consider the point defined by . If , then it must also hold true that for all . If we expand this, we get the following:       This contradicts our earlier assumption that and completes the proof. It's a little easier to see what's going on if we rearrange the diagram some:   Diagram of compositions induced by assumptions of Article 2 Exercise 7.      As long as , then . Since we've defined as a section of , it means that . Therefore, holds if and only if .   "
},
{
  "id": "article2-p3-6",
  "level": "2",
  "url": "article2-p3.html#article2-p3-6",
  "type": "Example",
  "number": "3.3.6",
  "title": "Exercise 8.",
  "body": " Exercise 8   ...the composite of two maps, each having sections, ...    Suppose we have composable maps and with respective sections and . By definition, and .  Based on this information, the composition has a section determined by the reversed composition of the sections . All we need to do is to show that .       It's easy to see why this order reversal is necessary by examining a diagram:   External diagram of given information in Article 2 Exercise 8.       "
},
{
  "id": "article2-p3-7",
  "level": "2",
  "url": "article2-p3.html#article2-p3-7",
  "type": "Example",
  "number": "3.3.8",
  "title": "Exercise 9.",
  "body": " Exercise 9   Suppose is a retraction of ...    Knowing that is a retraction of tells us that . If we define the map , we can prove that through the use of the associative property.      That completes the proof that is idempotent.  If we further assume that is an isomorphism, then we have some inverse function such that and . Since this inverse is unique, it follows that . Consequently, .   "
},
{
  "id": "article2-p3-8",
  "level": "2",
  "url": "article2-p3.html#article2-p3-8",
  "type": "Example",
  "number": "3.3.9",
  "title": "Exercise 10.",
  "body": " Exercise 10   If are both isomorphisms...    I think this one is a little easier to see with a diagram.   External diagram of given information in Article 2 Exercise 10.      Basically, to go backward to from , the order of inverses needs to also be reversed. We can prove this algebraically also.  Since is an isomorphism, it follows that and . Likewise, being an isomorphism implies and . The composition can be shown to sasify the conditions for being the inverse of .  First, we must demonstrate that :     Second, we must demonstrate that :     This complete our proof that    "
},
{
  "id": "article2-p3-9",
  "level": "2",
  "url": "article2-p3.html#article2-p3-9",
  "type": "Example",
  "number": "3.3.11",
  "title": "Exercise 11.",
  "body": " Exercise 11   If ...    Any that maps each element in to a unique element in should do the trick here.   Hypothetical for Article 2 Exercise 11      This has a unique inverse that reverses each of these arrows:   Corresponding for Article 2 Exercise 11      If we have , we'd be unable to define an isomorphism from because we don't have enough points to match them up one by one. One of those points in will have two arrows leading in and cause us to lose information about where we came from in the process:   Illustration of invertability problem with       "
},
{
  "id": "article2-p3-10",
  "level": "2",
  "url": "article2-p3.html#article2-p3-10",
  "type": "Example",
  "number": "3.3.15",
  "title": "Exercise 12.",
  "body": " Exercise 12   How many isomorphisms are there...    Essentially, the number of isomorphisms is a permutation problem. If we decide on a fixed order of elements in , each choice uses up the respective point in that it gets matched to. Therefore, we have 3 choices for Fatima, 2 choices for Omer, and 1 choice for Alysia, or possible choices all together.  The number of automorphisms should be the same, namely 6. It doesn't matter if we're assigning Fatima to or , it's precisely the same number of choices.  The number 27 in this context is the total number of possible maps from a set of 3 elements to another set of 3 elements: . This is the formula we arrived at after Article 1. Clearly \"the number of invertable maps\" should be less than \"the total number of maps\" because not every map will be invertable.   "
},
{
  "id": "session4",
  "level": "1",
  "url": "session4.html",
  "type": "Section",
  "number": "3.4",
  "title": "Session 4: Division of maps: Isomorphisms",
  "body": " Session 4: Division of maps: Isomorphisms  While reading this section, I appreciated the fact that \"just reverse the arrows\" was the official description of isomorphisms on sets. It makes me feel like my answers to Article 2 are at least on the right track. I think my main goal for this week is to better understand what \"respects the combining-rules\" really means.   Exercise 1   Finish checking that is an isomorphism...    Let's start with first. The composition is applied from right to left, which means we double first then halve.   Next we check , where we halve first and double after:   This proof seems kind of trivial since multiplication on is commutative.     Exercise 2   Find an isomorphism ...    Let's start by organizing some data. Perhaps a table of each map will reveal some insight into the structure.   Function table for     even  odd    even  even  odd    odd  odd  even      Function table for     positive  negative    positive  positive  negative    negative  negative  positive     These two tables mirror each other quite nicely, which suggests that ordering of options shown here is probably the correct choice of . Let's go ahead and define as follows:   Internal diagram of our potential isomorphism      In order for us to show that this respects the combining rules, we need to verify that for all .   Combining rule validation table for    For even, even:      Confirmed     For odd, even:      Confirmed       For even, odd:      Confirmed     For odd, odd:      Confirmed       Suppose instead we had used the map given by the alternative assignment:   Internal diagram of alternative map choice      When and are both even, but . Thus, this map fails to preserve the combining rule .     Exercise 3   ...Unmask the imposters...    Let's start with (a): given by .  While it seems like \"subtract one\" would be a reasonable inverse, this is not an isomorphism because it fails to respect the combining-rule . Consider the case where and . We have and so . However, this is not the same as , which evaluates to instead.  The map in (b) and the map in (c) are both closely related because they share a common definition of , but differ in the domain and codomain.  Again there's an obvious inverse function of \"square root\", but the domains and codomains are what concern me. Notable about (b) is that it fails to map \"onto\" the entire codomain, because the map never produces any negative numbers as an output. The map in (c) resolves this by limiting the codomain to non-negative values, but it still fails to \"one-to-one\" because both 1 and -1 produce an output of 1.  The map in (d) and (e) likewise have similar definitions.  The map defined by the given expression acts as its own inverse: . Where (d) and (e) differ is in the \"combining-rule\". If we have , then a little algebra can show that . This means that both the identity rules and the combining-rules are satisfied for (d), making it the only genuine isomorphism in the list. The map in (e) fails to uphold the combining rule because . In the case where and , we have but .  Finally we have the map (f), which isn't even a map with the specified domain and codomain because the cube of a negative number is still negative. Had the map been defined with the correct codomain, , then we'd potentially be able to define an inverse map by using the \"cube root\" function.    As I was proof reading this session, I noticed a couple small errors in the 3rd exercise. One of these was a misread problem, but the other was a little more subtle. In an effort to get the most out of this as a learning experience, I thought it might be valuable to talk about what I learned from my mistakes.   Meta-Exercise   As I was proof reading, I noticed an error in Exercise 3 Part (e). It was a simple case of me not reading the question as precisely as needed. I think I was so excited to show (d) was an isomorphism that I didn't give (e) the amount of skepticism it deserved. I mistakely read the domain as instead of which made finding a counter-example trivial relative to the actual problem.  As I was looking over my solution to fix this, I noticed something else kind of odd. My solution began with \"Let's go one at a time\" but I had addressed some of the problems in pairs. There's something that felt natural about approaching them this way, but it also seemed kind of ironic that I had failed to produce a isomorphism between my problems and solutions in a section that was all about matching things up.  All of this started to get my thinking about the solutions to these problems as a map . Obviously this map is not invertable, but it made me wonder if the \"Hints\" to this section provided sufficient information about the functions to identify each one. Is there some set of descriptions that would establish a one-to-one relationship with these problems?    The first hint tells us that only one of these maps is a \"genuine isomorphism\", which I concluded was (d). The last hint says that one is \"not even a map\", which I concluded is (f). The hint that \"[s]ome... dont respect the combining rules\" explains why I rejected (a) and (e). It also seems natural to ask \"does it have a section?\" and \"does it have a retraction?\".   Table of selected map properties for Exercise 3    Item  is a map?  has a section?  has a retraction?  respects combining rules?    (a)  Yes  Yes  Yes  No    (b)  Yes  No  No  N\/A    (c)  Yes  Yes  No  N\/A    (d)  Yes  Yes  Yes  Yes    (e)  Yes  Yes  Yes  No    (f)  No  N\/A  N\/A  N\/A     These four questions are almost enough to identify every problem except for distinguishing between (a) and (e). The best description of the difference is that (a) fails to preserve the combining-rules in every case while (e) might pass or fail the combining-rules depending on its input. This is a very subtle difference that I probably would have overlooked had I not made the mistake that I did.    "
},
{
  "id": "session4-3",
  "level": "2",
  "url": "session4.html#session4-3",
  "type": "Example",
  "number": "3.4.1",
  "title": "Exercise 1.",
  "body": " Exercise 1   Finish checking that is an isomorphism...    Let's start with first. The composition is applied from right to left, which means we double first then halve.   Next we check , where we halve first and double after:   This proof seems kind of trivial since multiplication on is commutative.   "
},
{
  "id": "session4-4",
  "level": "2",
  "url": "session4.html#session4-4",
  "type": "Example",
  "number": "3.4.2",
  "title": "Exercise 2.",
  "body": " Exercise 2   Find an isomorphism ...    Let's start by organizing some data. Perhaps a table of each map will reveal some insight into the structure.   Function table for     even  odd    even  even  odd    odd  odd  even      Function table for     positive  negative    positive  positive  negative    negative  negative  positive     These two tables mirror each other quite nicely, which suggests that ordering of options shown here is probably the correct choice of . Let's go ahead and define as follows:   Internal diagram of our potential isomorphism      In order for us to show that this respects the combining rules, we need to verify that for all .   Combining rule validation table for    For even, even:      Confirmed     For odd, even:      Confirmed       For even, odd:      Confirmed     For odd, odd:      Confirmed       Suppose instead we had used the map given by the alternative assignment:   Internal diagram of alternative map choice      When and are both even, but . Thus, this map fails to preserve the combining rule .   "
},
{
  "id": "session4-5",
  "level": "2",
  "url": "session4.html#session4-5",
  "type": "Example",
  "number": "3.4.8",
  "title": "Exercise 3.",
  "body": " Exercise 3   ...Unmask the imposters...    Let's start with (a): given by .  While it seems like \"subtract one\" would be a reasonable inverse, this is not an isomorphism because it fails to respect the combining-rule . Consider the case where and . We have and so . However, this is not the same as , which evaluates to instead.  The map in (b) and the map in (c) are both closely related because they share a common definition of , but differ in the domain and codomain.  Again there's an obvious inverse function of \"square root\", but the domains and codomains are what concern me. Notable about (b) is that it fails to map \"onto\" the entire codomain, because the map never produces any negative numbers as an output. The map in (c) resolves this by limiting the codomain to non-negative values, but it still fails to \"one-to-one\" because both 1 and -1 produce an output of 1.  The map in (d) and (e) likewise have similar definitions.  The map defined by the given expression acts as its own inverse: . Where (d) and (e) differ is in the \"combining-rule\". If we have , then a little algebra can show that . This means that both the identity rules and the combining-rules are satisfied for (d), making it the only genuine isomorphism in the list. The map in (e) fails to uphold the combining rule because . In the case where and , we have but .  Finally we have the map (f), which isn't even a map with the specified domain and codomain because the cube of a negative number is still negative. Had the map been defined with the correct codomain, , then we'd potentially be able to define an inverse map by using the \"cube root\" function.   "
},
{
  "id": "session4-7",
  "level": "2",
  "url": "session4.html#session4-7",
  "type": "Example",
  "number": "3.4.9",
  "title": "Meta-Exercise.",
  "body": " Meta-Exercise   As I was proof reading, I noticed an error in Exercise 3 Part (e). It was a simple case of me not reading the question as precisely as needed. I think I was so excited to show (d) was an isomorphism that I didn't give (e) the amount of skepticism it deserved. I mistakely read the domain as instead of which made finding a counter-example trivial relative to the actual problem.  As I was looking over my solution to fix this, I noticed something else kind of odd. My solution began with \"Let's go one at a time\" but I had addressed some of the problems in pairs. There's something that felt natural about approaching them this way, but it also seemed kind of ironic that I had failed to produce a isomorphism between my problems and solutions in a section that was all about matching things up.  All of this started to get my thinking about the solutions to these problems as a map . Obviously this map is not invertable, but it made me wonder if the \"Hints\" to this section provided sufficient information about the functions to identify each one. Is there some set of descriptions that would establish a one-to-one relationship with these problems?    The first hint tells us that only one of these maps is a \"genuine isomorphism\", which I concluded was (d). The last hint says that one is \"not even a map\", which I concluded is (f). The hint that \"[s]ome... dont respect the combining rules\" explains why I rejected (a) and (e). It also seems natural to ask \"does it have a section?\" and \"does it have a retraction?\".   Table of selected map properties for Exercise 3    Item  is a map?  has a section?  has a retraction?  respects combining rules?    (a)  Yes  Yes  Yes  No    (b)  Yes  No  No  N\/A    (c)  Yes  Yes  No  N\/A    (d)  Yes  Yes  Yes  Yes    (e)  Yes  Yes  Yes  No    (f)  No  N\/A  N\/A  N\/A     These four questions are almost enough to identify every problem except for distinguishing between (a) and (e). The best description of the difference is that (a) fails to preserve the combining-rules in every case while (e) might pass or fail the combining-rules depending on its input. This is a very subtle difference that I probably would have overlooked had I not made the mistake that I did.   "
},
{
  "id": "session5",
  "level": "1",
  "url": "session5.html",
  "type": "Section",
  "number": "3.5",
  "title": "Session 5: Division of maps: Sections and retractions",
  "body": " Session 5: Division of maps: Sections and retractions  Determine some witty remark to put here later.   Exercise 1   Show that... if then ...    For part (a), the hint suggests contradiction might be a good approach. Let's assume that and there exists some pair of points such that but .   Diagram of determination problem (a) in Session 5 Exercise 1      In this situation, there's no possible map here with because can't send possibly send to two different destinations ( and ).  Now let's consider the converse relationship in (b) where we know that for all .   Diagram of determination problem (b) in Session 5 Exercise 1      In this situation, we can construct a map that has our desired property . I'd imagine it like taking an image of the maps and over the set and defining as by the collection of arrows that have an origin at and destination .  Obviously defining in this way will potentially leave the possibility of arrows having duplicates, but the property ensures that if any two arrows share the same origin they must share the same destination.  From a meta-perspective, it makes sense that the converse holds true for use to this practically as a definition. When we say \" is determined by \", we want it to be true if and only if it satisfies the properties we've defined it to have.     Exercise 2   Show that... there is at least one in for which ...    I think the key idea in part (a) here is that the point precisely satisfies the properties we want for establishing the existence of . As long as there is some map with then we can define and it follows directly that .  Proving the converse in (b) seems a little trickier. I think I'd want to approach this like I did with \"Exercise 1\" and consider making an image by applying to each element .  If we already know that for each there is at least one such that , we can begin to construct a map by creating a collection of arrows with origin and destination .   Diagram of problem in Session 5 Exercise 2      The above definition of given by should satisfy the property since . We can rest assured we're not missing any origin points in because we've already assumed that each each corresponds to at least one , and we can safely assume that no has more than one destination in because we found them by iterating over to begin with.     Exercise 3   Draw... all the sections of .    Let's start here by reproducing the diagram of :   Internal diagram of map in Session 5 Exercise 3      Since there's only two points in , we're need to have two arrows with one originating at each. The left arrow needs to have one of four possible destinations, since there are four points in A that get mapped there by . The right arrow needs to have one of two possible destination from the points stacked above it. Since these choices are independent, we're looking for a total of maps.   Possible sections of in Session 5 Exercise 3        Upon finishing the exercises, I've chosen to not to retract my sarcastic pun above.  Okay, yeah, that's partly because I'm lazy, but I think it's also a good metaphor for what I learned about this week. Writing these posts is a multi-stage process that resembles a sequence of map compositions. I read (at least some of) the section, work out the exercises, then come back and revise. What you see at the end is the composition, but not necessarily each step along the way. At the same time, some qualities of the end product itself may restrict the process leading to it but others leave flexibility.  This week's reading seemed to be about exactly how flexible these maps could be before they start to lose information.  I could have removed the remark at the start of this and replaced it with something else. Yet, the fact that I'm now discussing it means it must be there.  This seems exceptionally well fitting to how my proofs this week worked. I'm essentially arguing that these maps exists because I can describe a set of rules to construct them. Whether you believe me or not, well, that's another story...  "
},
{
  "id": "session5-3",
  "level": "2",
  "url": "session5.html#session5-3",
  "type": "Example",
  "number": "3.5.1",
  "title": "Exercise 1.",
  "body": " Exercise 1   Show that... if then ...    For part (a), the hint suggests contradiction might be a good approach. Let's assume that and there exists some pair of points such that but .   Diagram of determination problem (a) in Session 5 Exercise 1      In this situation, there's no possible map here with because can't send possibly send to two different destinations ( and ).  Now let's consider the converse relationship in (b) where we know that for all .   Diagram of determination problem (b) in Session 5 Exercise 1      In this situation, we can construct a map that has our desired property . I'd imagine it like taking an image of the maps and over the set and defining as by the collection of arrows that have an origin at and destination .  Obviously defining in this way will potentially leave the possibility of arrows having duplicates, but the property ensures that if any two arrows share the same origin they must share the same destination.  From a meta-perspective, it makes sense that the converse holds true for use to this practically as a definition. When we say \" is determined by \", we want it to be true if and only if it satisfies the properties we've defined it to have.   "
},
{
  "id": "session5-4",
  "level": "2",
  "url": "session5.html#session5-4",
  "type": "Example",
  "number": "3.5.4",
  "title": "Exercise 2.",
  "body": " Exercise 2   Show that... there is at least one in for which ...    I think the key idea in part (a) here is that the point precisely satisfies the properties we want for establishing the existence of . As long as there is some map with then we can define and it follows directly that .  Proving the converse in (b) seems a little trickier. I think I'd want to approach this like I did with \"Exercise 1\" and consider making an image by applying to each element .  If we already know that for each there is at least one such that , we can begin to construct a map by creating a collection of arrows with origin and destination .   Diagram of problem in Session 5 Exercise 2      The above definition of given by should satisfy the property since . We can rest assured we're not missing any origin points in because we've already assumed that each each corresponds to at least one , and we can safely assume that no has more than one destination in because we found them by iterating over to begin with.   "
},
{
  "id": "session5-5",
  "level": "2",
  "url": "session5.html#session5-5",
  "type": "Example",
  "number": "3.5.6",
  "title": "Exercise 3.",
  "body": " Exercise 3   Draw... all the sections of .    Let's start here by reproducing the diagram of :   Internal diagram of map in Session 5 Exercise 3      Since there's only two points in , we're need to have two arrows with one originating at each. The left arrow needs to have one of four possible destinations, since there are four points in A that get mapped there by . The right arrow needs to have one of two possible destination from the points stacked above it. Since these choices are independent, we're looking for a total of maps.   Possible sections of in Session 5 Exercise 3       "
},
{
  "id": "session6",
  "level": "1",
  "url": "session6.html",
  "type": "Section",
  "number": "3.6",
  "title": "Session 6: Two general aspects or uses of maps",
  "body": " Session 6: Two general aspects or uses of maps  This week's reading didn't have any official exercises in it, but it also seemed important so I wanted to make sure I gave it the same level of attention as the others. I find that I need to continually reminding myself that math is not a race and that I should take advantage of current privilege to truly take things slow here. My purpose isn't to get through the excercises in this book; it's to understand the deeper ideas behind it.  This session is filled with beautiful mathematical writing.  I think math courses need more content like this. At the same time, both the student and teacher in me recognize that this is one of the first things that would be cut from the syllabus if the class ran short on time. It makes me sad that our system's focus on measurable learning objectives means that philosophical discussions are treated as dispensible.  In much the same way as the authors describe science as maps being used to understand reality, the education system uses assessments to understand what's going on inside a student's head. Since we can't observe someone's state of mind, we alter their environment stimuli and see how they respond. This presents problems when we're using map composition to turn one of many complex mental models down to a multiple choice question for the exam. As long as a student could distinguish between \"sort\" and \"partition\" by the end of this unit, we don't really care how it impacted their broader understanding of world around them.  I think there's a hidden exercise in this session. I'll mark it as an example here so you can avoid spoilers if desired.   Session 6 Hidden Exercise   What do you notice? What do you wonder?    After reading through this session, I noticed something very interesting about the last diagram. I'll recreate it here for reference.   The last diagram in L&S Session 6      What struck me as interesting about this map was how closely it described a book . There's only a finite number of \"words\" in the \"language\" that the book is written using, and we can index them with positive integers describing their sequence in the book.  This observation struck me as interesting because my reading of this book works the same as the sampling process. You could generate a map from time to the index of the word that I'm reading at the time, and compose this map with the book map to find out what word I'm reading. This would reveal my non-linear path through the book, rereading sections as needed to answer the problems I'm working on.  It makes me wonder if this session is actually an exercise in meta-mathematics . Maybe the reason the authors intended to sow seeds of curiousity about their ommission and for me look at the book as a system that can be studied using category theory itself. The chapters of the book act as a sort for the exercises, but the fact that this chapter doesn't exercises have any means it's not a partition .  I think it's kind of funny that this section of the book about sections would be a counter-example to the book's exercises having a section.    "
},
{
  "id": "session6-7",
  "level": "2",
  "url": "session6.html#session6-7",
  "type": "Example",
  "number": "3.6.1",
  "title": "Session 6 Hidden Exercise.",
  "body": " Session 6 Hidden Exercise   What do you notice? What do you wonder?    After reading through this session, I noticed something very interesting about the last diagram. I'll recreate it here for reference.   The last diagram in L&S Session 6      What struck me as interesting about this map was how closely it described a book . There's only a finite number of \"words\" in the \"language\" that the book is written using, and we can index them with positive integers describing their sequence in the book.  This observation struck me as interesting because my reading of this book works the same as the sampling process. You could generate a map from time to the index of the word that I'm reading at the time, and compose this map with the book map to find out what word I'm reading. This would reveal my non-linear path through the book, rereading sections as needed to answer the problems I'm working on.  It makes me wonder if this session is actually an exercise in meta-mathematics . Maybe the reason the authors intended to sow seeds of curiousity about their ommission and for me look at the book as a system that can be studied using category theory itself. The chapters of the book act as a sort for the exercises, but the fact that this chapter doesn't exercises have any means it's not a partition .  I think it's kind of funny that this section of the book about sections would be a counter-example to the book's exercises having a section.   "
},
{
  "id": "session7",
  "level": "1",
  "url": "session7.html",
  "type": "Section",
  "number": "3.7",
  "title": "Session 7: Isomorphisms and coordinates",
  "body": " Session 7: Isomorphisms and coordinates  It turns out that last week's lack of exercises wasn't as much of an anomaly as I thought it was. After realizing that this week's session didn't have any exercises either, I scanned ahead and noticed that there are several sessions like this before eventually reaching a \"Quiz\" and \"Test\". I'm not sure how I plan to handle those yet, but I think I'm going to keep with my chill pace for now. This session did include several side questions throughout that I can treat as I would the exercises.   Aside 1   What, approximately, is for the point in the picture?    I took a modern approach and used technology to provide a more accurate estimation.    I began by holding the page as flat as I could while taking a photo with my phone and uploaded to the cloud.    I downloaded this photo from my PC and opened it in GIMP .    I used the cursor to identify the following coordinates in pixels: , , , .    Next I calculated the distances from to and from to . Specifically, and .    With this information in hand, I can set up a ratio to determine . Solving results in a solution of .    This seems like a reasonable estimate based on the diagram.     Aside 2   What are the choice of origin, positive direction, and unit of 'distance' involved in specifying this isomorphism?...    Oooh this is a fun one! Let's presume we meet some alien species and are trying to sync up our timelines. We're going to need both space and time coordinates if we really want to do this right. One possibility is for both parties to use \"the big bang\" as a point of origin and \"the light cone\" for a direction and magnitude. This choice makes converting easy, but potentially imprecise because of the sheer size of those values.  A much more practical approach would be to use the meeting time and location as a point of origin, use physical constants to communicate SI units, then work backwards to calculate the local time for each party using a Lorentz transformation. We'd just need to where they came from and how fast they traveled to convert their home civilization's time to their current time.  I think the point that the authors were trying to communicate was that our choice of units and magnitude for \"time\" are very specific to our origin on planet Earth. If we're talking about units of \"years\" as being \"one orbit around the Sun\" and the origin as a socially defined \"common era\", then an alien race from another plant would likely have totally different system of dating then us. However, most SI units are based on physical properties of our universe. Even if this species chose a different set of base units than us, we could match up measurements of certain elements to develop an isomorphism between our two systems.     Aside 3   ...rational explanation for the curious bracketing...    The first thing that jumps out at me about the bracket is that the sums of the adjacent ranks are constant:   8 Player Bracket from L&S Session 7      In other words, the best player is alway paired with the worst player, the next best with the next worst, and so on until all pairs have been assigned. However, the fun doesn't stop there.  The bracket also appears to balance \"skill gap\" between the top half and the bottom half. The winner of the match-up with the highest rank differential goes on to face the winner of the match with the lowest differential in the next round. Those differentials sum to a constant much like the ranks did.   8 player bracket with rank differentials      Between those two conditions, that should be enough to determine the 4 and 16 player brackets. The four player one is easy, since it's essentially embeeded in the original.   4 player bracket      To make the 16 player bracket, I'm going to start by pairing off players based on rank: The player in rank 1 should be paired with the player in rank 16, rank 2 with rank 15, rank 3 with rank 14, and so on until all 8 pairs have been assigned. Since these pairings go from largest score differential to smallest, we can assign the pairs to each of the \"ranks\" in the 8 player bracket to extend it further.   16 player bracket      This works out nicely because if the top 8 players all win their match-ups in the first round of the 16-player bracket, they'd wind up in a bracket that is basically identical to their placement in the 8-player bracket. Likewise, if the top four players continue to win then we end up in a situation identical to the 4-player bracket. It has a nice recursively defined structure.    "
},
{
  "id": "session7-3",
  "level": "2",
  "url": "session7.html#session7-3",
  "type": "Example",
  "number": "3.7.1",
  "title": "Aside 1.",
  "body": " Aside 1   What, approximately, is for the point in the picture?    I took a modern approach and used technology to provide a more accurate estimation.    I began by holding the page as flat as I could while taking a photo with my phone and uploaded to the cloud.    I downloaded this photo from my PC and opened it in GIMP .    I used the cursor to identify the following coordinates in pixels: , , , .    Next I calculated the distances from to and from to . Specifically, and .    With this information in hand, I can set up a ratio to determine . Solving results in a solution of .    This seems like a reasonable estimate based on the diagram.   "
},
{
  "id": "session7-4",
  "level": "2",
  "url": "session7.html#session7-4",
  "type": "Example",
  "number": "3.7.2",
  "title": "Aside 2.",
  "body": " Aside 2   What are the choice of origin, positive direction, and unit of 'distance' involved in specifying this isomorphism?...    Oooh this is a fun one! Let's presume we meet some alien species and are trying to sync up our timelines. We're going to need both space and time coordinates if we really want to do this right. One possibility is for both parties to use \"the big bang\" as a point of origin and \"the light cone\" for a direction and magnitude. This choice makes converting easy, but potentially imprecise because of the sheer size of those values.  A much more practical approach would be to use the meeting time and location as a point of origin, use physical constants to communicate SI units, then work backwards to calculate the local time for each party using a Lorentz transformation. We'd just need to where they came from and how fast they traveled to convert their home civilization's time to their current time.  I think the point that the authors were trying to communicate was that our choice of units and magnitude for \"time\" are very specific to our origin on planet Earth. If we're talking about units of \"years\" as being \"one orbit around the Sun\" and the origin as a socially defined \"common era\", then an alien race from another plant would likely have totally different system of dating then us. However, most SI units are based on physical properties of our universe. Even if this species chose a different set of base units than us, we could match up measurements of certain elements to develop an isomorphism between our two systems.   "
},
{
  "id": "session7-5",
  "level": "2",
  "url": "session7.html#session7-5",
  "type": "Example",
  "number": "3.7.3",
  "title": "Aside 3.",
  "body": " Aside 3   ...rational explanation for the curious bracketing...    The first thing that jumps out at me about the bracket is that the sums of the adjacent ranks are constant:   8 Player Bracket from L&S Session 7      In other words, the best player is alway paired with the worst player, the next best with the next worst, and so on until all pairs have been assigned. However, the fun doesn't stop there.  The bracket also appears to balance \"skill gap\" between the top half and the bottom half. The winner of the match-up with the highest rank differential goes on to face the winner of the match with the lowest differential in the next round. Those differentials sum to a constant much like the ranks did.   8 player bracket with rank differentials      Between those two conditions, that should be enough to determine the 4 and 16 player brackets. The four player one is easy, since it's essentially embeeded in the original.   4 player bracket      To make the 16 player bracket, I'm going to start by pairing off players based on rank: The player in rank 1 should be paired with the player in rank 16, rank 2 with rank 15, rank 3 with rank 14, and so on until all 8 pairs have been assigned. Since these pairings go from largest score differential to smallest, we can assign the pairs to each of the \"ranks\" in the 8 player bracket to extend it further.   16 player bracket      This works out nicely because if the top 8 players all win their match-ups in the first round of the 16-player bracket, they'd wind up in a bracket that is basically identical to their placement in the 8-player bracket. Likewise, if the top four players continue to win then we end up in a situation identical to the 4-player bracket. It has a nice recursively defined structure.   "
},
{
  "id": "session8",
  "level": "1",
  "url": "session8.html",
  "type": "Section",
  "number": "3.8",
  "title": "Session 8: Pictures of a map",
  "body": " Session 8: Pictures of a map  Rather than having exercises of its own, this session was focused on solving the exercises from Article II. Since I'd already worked out these problems, all that remains for this week is to proofread.   Article II, Exercise 5 Proofreading  (Add the rest of the arrows yourself.)   My diagram of all 6 sections from earlier matchs up with this incomplete diagram perfectly:   Likewise, I correctly arrived at a count of 8 retractions and drew those too:   If there's something to be critical about myself here, it would be that I was perhaps a little lax in assuming the domains and codomains of my maps were the same. I jumped right into diagrams of without specifying what it was. In my defense, this information was implicit in the diagrams themselves but the authors took an extra effort to explicitly articulate the qualities they were checking for in the map.     Article II, Exercise 8 Proofreading  Prove that the composite of two maps that have sections has a section.   I must admit, it took me several attempts to verify that my solution was equivalent to the book's with direct substitutions. I had used instead of the respective .   I think I actually prefer my notation here over the authors because it makes the connection between the functions and sections more clear. I kept forgetting whether or matched up with or . Using the notation makes the reversed composition ordering of the sections more readily apparent.    Based on what I saw in this session, I think I was on the right track with my solutions to the exercises from Article II. It's nice to have this little checkpoint to validate my earlier work. I'm usually the type that likes to try to solve the exercises in my head just to see if I can, but then I miss out on moments for reflection like this.  "
},
{
  "id": "session8-3",
  "level": "2",
  "url": "session8.html#session8-3",
  "type": "Example",
  "number": "3.8.1",
  "title": "Article II, Exercise 5 Proofreading.",
  "body": " Article II, Exercise 5 Proofreading  (Add the rest of the arrows yourself.)   My diagram of all 6 sections from earlier matchs up with this incomplete diagram perfectly:   Likewise, I correctly arrived at a count of 8 retractions and drew those too:   If there's something to be critical about myself here, it would be that I was perhaps a little lax in assuming the domains and codomains of my maps were the same. I jumped right into diagrams of without specifying what it was. In my defense, this information was implicit in the diagrams themselves but the authors took an extra effort to explicitly articulate the qualities they were checking for in the map.   "
},
{
  "id": "session8-4",
  "level": "2",
  "url": "session8.html#session8-4",
  "type": "Example",
  "number": "3.8.2",
  "title": "Article II, Exercise 8 Proofreading.",
  "body": " Article II, Exercise 8 Proofreading  Prove that the composite of two maps that have sections has a section.   I must admit, it took me several attempts to verify that my solution was equivalent to the book's with direct substitutions. I had used instead of the respective .   I think I actually prefer my notation here over the authors because it makes the connection between the functions and sections more clear. I kept forgetting whether or matched up with or . Using the notation makes the reversed composition ordering of the sections more readily apparent.   "
},
{
  "id": "session9",
  "level": "1",
  "url": "session9.html",
  "type": "Section",
  "number": "3.9",
  "title": "Session 9: Retracts and idempotents",
  "body": " Session 9: Retracts and idempotents  At last! The exercises have returned!  The reading this week was interesting in how it approached the relationship between \"size of sets\" and \"properties of maps\". The art of counting without counting seemed to be a recurring theme.   Exercise 1:   ...unless the set has a point and has none...    So means that there exists some map . In the category of sets, we know that the number of possible maps from is related to the size of the sets by a formula we arrived at in Session 2: . The only time when this expression for number of maps evaluates to 0 is when and .  Another way of looking at this might to consider the contrapositive of this statement. If we know that there does not exist a map from to , that means there must be some origin point in for the map to act on but no destination point in to send it to. Not having a place to send the point to directly implies . If we also had then we'd have a \"null map\", so the non-existance of a map also implies must be non-empty.     Exercise 2:   ...Show that (R) ... [and] (T) ...    Let's start with the reflexive property (R): . This notation indicates that there exist maps such that with . Clearly the map already mets both these conditions since .  To prove the transitive property (T), we can construct a retraction for the composition of the functions using a composition of their retractions. If , then there exist maps such that with . Likewise, , then there exist maps such that with .  Given these , we can define and define . Note that can be evaluated as follows using the associative property:     This completes the proof that .     Exercise 3:   ... Use these maps to construct an isomorphism .    So we're given that both and \"split the same idempotent\" .  The definition of \"splitting an idempotent\" tells us that with and . Given these maps, we're trying to establish a composition that goes from to using as a step in between. To get from to we can use map , and then to get from to we can use map .  Let us define by . This map should be a well-defined isomorphism with the inverse map given by . To prove this, we must show that and .  By the associative property, the first expression can be simplified as follows:        Likewise, the second expression can be similarly simplified:        These two conditions are sufficient to demonstrate that is an isomorphism.    "
},
{
  "id": "session9-4",
  "level": "2",
  "url": "session9.html#session9-4",
  "type": "Example",
  "number": "3.9.1",
  "title": "Exercise 1:.",
  "body": " Exercise 1:   ...unless the set has a point and has none...    So means that there exists some map . In the category of sets, we know that the number of possible maps from is related to the size of the sets by a formula we arrived at in Session 2: . The only time when this expression for number of maps evaluates to 0 is when and .  Another way of looking at this might to consider the contrapositive of this statement. If we know that there does not exist a map from to , that means there must be some origin point in for the map to act on but no destination point in to send it to. Not having a place to send the point to directly implies . If we also had then we'd have a \"null map\", so the non-existance of a map also implies must be non-empty.   "
},
{
  "id": "session9-5",
  "level": "2",
  "url": "session9.html#session9-5",
  "type": "Example",
  "number": "3.9.2",
  "title": "Exercise 2:.",
  "body": " Exercise 2:   ...Show that (R) ... [and] (T) ...    Let's start with the reflexive property (R): . This notation indicates that there exist maps such that with . Clearly the map already mets both these conditions since .  To prove the transitive property (T), we can construct a retraction for the composition of the functions using a composition of their retractions. If , then there exist maps such that with . Likewise, , then there exist maps such that with .  Given these , we can define and define . Note that can be evaluated as follows using the associative property:     This completes the proof that .   "
},
{
  "id": "session9-6",
  "level": "2",
  "url": "session9.html#session9-6",
  "type": "Example",
  "number": "3.9.3",
  "title": "Exercise 3:.",
  "body": " Exercise 3:   ... Use these maps to construct an isomorphism .    So we're given that both and \"split the same idempotent\" .  The definition of \"splitting an idempotent\" tells us that with and . Given these maps, we're trying to establish a composition that goes from to using as a step in between. To get from to we can use map , and then to get from to we can use map .  Let us define by . This map should be a well-defined isomorphism with the inverse map given by . To prove this, we must show that and .  By the associative property, the first expression can be simplified as follows:        Likewise, the second expression can be similarly simplified:        These two conditions are sufficient to demonstrate that is an isomorphism.   "
},
{
  "id": "quiz1",
  "level": "1",
  "url": "quiz1.html",
  "type": "Section",
  "number": "3.10",
  "title": "Quiz",
  "body": " Quiz  Since the following section is entitled \"How to solve the quiz problems\", I'm interpreting that as a sign that answering these problems publicly like this is acceptable use. My time as a teacher has taught me that the primary distinction betweeen formatitve and summative assessments lies in how you use them, and this quiz seems to be treated like the former. The goal is to provide students with a self-check on important concepts before the first \"test\".  As I'm still trying to force myself to slow down, my plan for time being is to take the quiz this week and self-grade my own work next week before attempting the \"test\" the week after. I feel as though posting test solutions online would be poor form, so I think I'm going to put my test solutions in a separate PretextBook that can be shared on a per person basis to anyone that's willing to help determine the correctness of my work. We'll see how that goes in the future, but for now we focus on the problems at hand.   Problem 1   Give an example of two explicit sets...    I know this may be a little regressive of me, but I found it easier to think of this problems in terms of \"onto\" and \"one-to-one\". Since I'm looking for a map that \"has a section but not a retraction\", that effectively means the map is \"one-to-one but not onto\". My insticts about functions tell me that this occurs when my \"output space\" is bigger than my \"input space\".  Consider the sets and , and define by the following internal diagram:   Internal diagram of our potential map      To demonstrate that this map has the required properties, let's start by identifying the retraction :   Internal diagram of retraction to our potential map      Proving this is a retraction requires that we show . Fortunately this proof is trivial since there's only one element in for us to test. Since is the only possible input, the fact that is sufficient to satisfy the condition . Thus, is a retraction of .  Note that this map does not function as a section because . This can be easily observed by applying the composition to point : . In order for a map to be a section of , it needs to send point to something other than , but there isn't anywhere else for it to go!   Internal diagram demonstrating the lack of section for our potential map      Since we lose an element when mapping from , there's no way to reconstruct it afterwards. It follows that cannot possibly have a section satisfying . This completes the proof that satistfies the desired properties.     Problem 2   If satisfy ...    Recall that a map is \"idempotent\" if . Thus, we'll take the maps defined in (a) and (b) and see how they might be simplified after being applied twice.  Let's start with (a): . Composing this map with itself gives us , which can be simplified using the associative property:     Having demonstrated that , we can safely conlude that the map in part (a) is idempotent.  We can apply the same strategy in (b) with the expression :     Since , we can conclude that the map in (b) is idempotent as well.     Problem 2*   ...use the given maps and to devise a map satisfying both...    My gut instict tells me because that's the simpliest map I can construct that will have the requisite domain and codomain. Let's check to see if it has the desired properties.  First, we'll look at (a) by seeing if . Using only the associative property, we can simplify the left hand side as follows:      That confirms property (a). We can use a similar method to demonstrate property (b): .        Thus, our choice of has both of the required properties.     Problem 1*   Same as Problem 1 at top of page, except...    Upon reading this problem, it sounded very similar to one of the situations in the \"zoo\" from Session 4. Specifically, I was thinking of the map in Exercise 3 Item (c) where is given by . On closer inspection, my notes from that section indicate that this had a section but no retraction -- which is the reverse of what I'm looking for here. I played around with item (a) from the zoo for a bit, but I wasn't quite happy with how the domains and codomains weren't aligning. This got me thinking about a clue at the end of Session 9. Specifically, the authors mention \"Georg Cantor\" by name.  With the realization that I could use infinite sets of varying sizes, I decided that I could combine this notion with the ideas behind the set sizes in Problem 1 by making a map from a \"countably infinite set\" to an \"uncountably infinite set\". In this situation, I could theoretically use Cantor's diagonalization argument to prove the non-existance of my section.  I decided to use a \"binary representation\" map that takes each positive integer and turns it into a binary representation of a real number between 0 and 1 by prepending \"0.\" to the reversed binary representation of the integer. Like so:     x in base 10  x in base 2  f(x) in base 2    1  1  0.1    2  10  0.01    3  11  0.11    4  100  0.001    ...  ...  ...     We can construct a map that iterates along the digits of the input and sums up the product of that digit with the respective powers of 2. For example, could be evaluated as follows:    Assuming we started with some positive integer and applied to it, it would be in the table above and this map will return the number we started with. Thus we have a well defined retraction becaues . However, Cantor's diagonal argument suggest that there still exists at least one real number in the interval (0,1) for which there is no inverse. Consider the real number constructed by taking a single \"bit\" from each line of the table following the diagonal and flipping it while adding trailing zeroes to the right as needed:     x in base 10  x in base 2  f(x) in base 2  \"flipped\" bit    1  1  0. 1  0    2  10  0.0 1  0    3  11  0.11 0  1    4  100  0.001 0  1    ...  ...  ...     By concatenating all these flipped bits together we can constuct a number given by the binary expansion \"0.0011...\" as defined above. This number doesn't have a corresponding value in the table for because it differs from every output by at least one bit. Since is undefined, we have . The uniqueness of the inverses we proved in Article 2 implies that the section couldn't be anything other than the retraction , so we must conlude that does not have section.    "
},
{
  "id": "quiz1-4",
  "level": "2",
  "url": "quiz1.html#quiz1-4",
  "type": "Example",
  "number": "3.10.1",
  "title": "Problem 1.",
  "body": " Problem 1   Give an example of two explicit sets...    I know this may be a little regressive of me, but I found it easier to think of this problems in terms of \"onto\" and \"one-to-one\". Since I'm looking for a map that \"has a section but not a retraction\", that effectively means the map is \"one-to-one but not onto\". My insticts about functions tell me that this occurs when my \"output space\" is bigger than my \"input space\".  Consider the sets and , and define by the following internal diagram:   Internal diagram of our potential map      To demonstrate that this map has the required properties, let's start by identifying the retraction :   Internal diagram of retraction to our potential map      Proving this is a retraction requires that we show . Fortunately this proof is trivial since there's only one element in for us to test. Since is the only possible input, the fact that is sufficient to satisfy the condition . Thus, is a retraction of .  Note that this map does not function as a section because . This can be easily observed by applying the composition to point : . In order for a map to be a section of , it needs to send point to something other than , but there isn't anywhere else for it to go!   Internal diagram demonstrating the lack of section for our potential map      Since we lose an element when mapping from , there's no way to reconstruct it afterwards. It follows that cannot possibly have a section satisfying . This completes the proof that satistfies the desired properties.   "
},
{
  "id": "quiz1-5",
  "level": "2",
  "url": "quiz1.html#quiz1-5",
  "type": "Example",
  "number": "3.10.5",
  "title": "Problem 2.",
  "body": " Problem 2   If satisfy ...    Recall that a map is \"idempotent\" if . Thus, we'll take the maps defined in (a) and (b) and see how they might be simplified after being applied twice.  Let's start with (a): . Composing this map with itself gives us , which can be simplified using the associative property:     Having demonstrated that , we can safely conlude that the map in part (a) is idempotent.  We can apply the same strategy in (b) with the expression :     Since , we can conclude that the map in (b) is idempotent as well.   "
},
{
  "id": "quiz1-6",
  "level": "2",
  "url": "quiz1.html#quiz1-6",
  "type": "Example",
  "number": "3.10.6",
  "title": "Problem 2*.",
  "body": " Problem 2*   ...use the given maps and to devise a map satisfying both...    My gut instict tells me because that's the simpliest map I can construct that will have the requisite domain and codomain. Let's check to see if it has the desired properties.  First, we'll look at (a) by seeing if . Using only the associative property, we can simplify the left hand side as follows:      That confirms property (a). We can use a similar method to demonstrate property (b): .        Thus, our choice of has both of the required properties.   "
},
{
  "id": "quiz1-7",
  "level": "2",
  "url": "quiz1.html#quiz1-7",
  "type": "Example",
  "number": "3.10.7",
  "title": "Problem 1*.",
  "body": " Problem 1*   Same as Problem 1 at top of page, except...    Upon reading this problem, it sounded very similar to one of the situations in the \"zoo\" from Session 4. Specifically, I was thinking of the map in Exercise 3 Item (c) where is given by . On closer inspection, my notes from that section indicate that this had a section but no retraction -- which is the reverse of what I'm looking for here. I played around with item (a) from the zoo for a bit, but I wasn't quite happy with how the domains and codomains weren't aligning. This got me thinking about a clue at the end of Session 9. Specifically, the authors mention \"Georg Cantor\" by name.  With the realization that I could use infinite sets of varying sizes, I decided that I could combine this notion with the ideas behind the set sizes in Problem 1 by making a map from a \"countably infinite set\" to an \"uncountably infinite set\". In this situation, I could theoretically use Cantor's diagonalization argument to prove the non-existance of my section.  I decided to use a \"binary representation\" map that takes each positive integer and turns it into a binary representation of a real number between 0 and 1 by prepending \"0.\" to the reversed binary representation of the integer. Like so:     x in base 10  x in base 2  f(x) in base 2    1  1  0.1    2  10  0.01    3  11  0.11    4  100  0.001    ...  ...  ...     We can construct a map that iterates along the digits of the input and sums up the product of that digit with the respective powers of 2. For example, could be evaluated as follows:    Assuming we started with some positive integer and applied to it, it would be in the table above and this map will return the number we started with. Thus we have a well defined retraction becaues . However, Cantor's diagonal argument suggest that there still exists at least one real number in the interval (0,1) for which there is no inverse. Consider the real number constructed by taking a single \"bit\" from each line of the table following the diagonal and flipping it while adding trailing zeroes to the right as needed:     x in base 10  x in base 2  f(x) in base 2  \"flipped\" bit    1  1  0. 1  0    2  10  0.0 1  0    3  11  0.11 0  1    4  100  0.001 0  1    ...  ...  ...     By concatenating all these flipped bits together we can constuct a number given by the binary expansion \"0.0011...\" as defined above. This number doesn't have a corresponding value in the table for because it differs from every output by at least one bit. Since is undefined, we have . The uniqueness of the inverses we proved in Article 2 implies that the section couldn't be anything other than the retraction , so we must conlude that does not have section.   "
},
{
  "id": "quiz2",
  "level": "1",
  "url": "quiz2.html",
  "type": "Section",
  "number": "3.11",
  "title": "Summary\/Quiz on Opposed Maps",
  "body": " Summary\/Quiz on Opposed Maps  After reading over the How to solve the quiz problems section, I think I was mostly on track. A \"fussy professor\" might have taken issue with me, but since I worked through these last two sections on crowded 8-hour flights I deserve to cut myself a little slack.  The authors included one more \"quiz\" before the \"test\" and I think I'm about ready for it. It seemed like the answers to this quiz were meant as more of a study-guide than anything else.   Problem 1   Given two maps...    I went with always and endomap . As long as the domain and codomain of the maps match up, there's no reason why we shouldn't be able to compose them. Once we do compose them, the resulting maps have the property that the codomain and domain are the same: and . This definition was repeated just a few pages prior.     Problem 2   If we know that ...    I went with , endomap , idempotent , and . I don't know how many times I referred back to Article II for the definitions of retraction and section on page 49 but I think it's finally starting to sink in. The notion that \"only endomaps have a chance to be idempotent \" was emphasized in the quiz solution to 2(a).     Problem 3   If we even know that ...    I went with and . One of the big results from Article II Exercise 2 was that if an inverse map exists then it must be unique. Stating that is an isomorphism is equivalent to saying that the section and retraction are uniquely defined by the inverse .     Problem 4   Going back to 0...    I chose could be different from in both cases. In the \"Composition of opposed maps\" on the previous page they use the maps and as an example. With those definitions, would be \"the father of my paternal grandmother\" which is clearly a different person than \"my father\" so . Likewise, the map would be like a relation of \"maternal grandfather\". Clearly the \"maternal grandfather of my maternal grandfather\" described by would be a different person than \"my maternal grandfather\" . Since we only need one counter-example to prove maps different, QED .    "
},
{
  "id": "quiz2-4",
  "level": "2",
  "url": "quiz2.html#quiz2-4",
  "type": "Example",
  "number": "3.11.1",
  "title": "Problem 1.",
  "body": " Problem 1   Given two maps...    I went with always and endomap . As long as the domain and codomain of the maps match up, there's no reason why we shouldn't be able to compose them. Once we do compose them, the resulting maps have the property that the codomain and domain are the same: and . This definition was repeated just a few pages prior.   "
},
{
  "id": "quiz2-5",
  "level": "2",
  "url": "quiz2.html#quiz2-5",
  "type": "Example",
  "number": "3.11.2",
  "title": "Problem 2.",
  "body": " Problem 2   If we know that ...    I went with , endomap , idempotent , and . I don't know how many times I referred back to Article II for the definitions of retraction and section on page 49 but I think it's finally starting to sink in. The notion that \"only endomaps have a chance to be idempotent \" was emphasized in the quiz solution to 2(a).   "
},
{
  "id": "quiz2-6",
  "level": "2",
  "url": "quiz2.html#quiz2-6",
  "type": "Example",
  "number": "3.11.3",
  "title": "Problem 3.",
  "body": " Problem 3   If we even know that ...    I went with and . One of the big results from Article II Exercise 2 was that if an inverse map exists then it must be unique. Stating that is an isomorphism is equivalent to saying that the section and retraction are uniquely defined by the inverse .   "
},
{
  "id": "quiz2-7",
  "level": "2",
  "url": "quiz2.html#quiz2-7",
  "type": "Example",
  "number": "3.11.4",
  "title": "Problem 4.",
  "body": " Problem 4   Going back to 0...    I chose could be different from in both cases. In the \"Composition of opposed maps\" on the previous page they use the maps and as an example. With those definitions, would be \"the father of my paternal grandmother\" which is clearly a different person than \"my father\" so . Likewise, the map would be like a relation of \"maternal grandfather\". Clearly the \"maternal grandfather of my maternal grandfather\" described by would be a different person than \"my maternal grandfather\" . Since we only need one counter-example to prove maps different, QED .   "
},
{
  "id": "session10",
  "level": "1",
  "url": "session10.html",
  "type": "Section",
  "number": "3.12",
  "title": "Session 10: Brouwers theorems",
  "body": " Session 10: Brouwer's theorems  It felt like there was a lot of new information introduce here for the session that concludes \"Part II\". This reminds me of my undergraduate research study where I had my first crash course in topology. In fact, flipping back to the start of book reveals the following warning: \"Exceptionally, Session 10 is intended to give the reader a taste of more sophisticated applications; mastery of it is not essential for the rest of the book.\"  As I was reading this week, I also felt reminded of Problem 1* from the Quiz. This idea that we can compare the size of infinite sets like and using the language of retractions seems analagous to the formalation of Brouwer's theorems. I'm expecting the proofs in this section to follow a similar format, even though this notion of a \"continuous maps\" seems a little informal at the moment.   Exercise 1:   Let be, as before, the inclusion of the circle into the disk...    We're given that we have two continuous maps and that . We want to show that there's some point such that We're also told to use the retraction theorem , and the revelevant one states that \"there is no continuous map which is a retraction for j\".  Let's suppose for a second that the opposite were true: for every . Since these two points are different, we can construct an arrow using one of them as the \"tail\" and one as the \"head\". We can define a map that follows this arrow until it reaches the boundary point on the circle like so:   Construction diagram for our map      Since we're guaranteed to have , let's see what happens when we compose with it. If we could prove , we'd have a contradiction and be done, but it's not clear that's the case quite yet. I think the key to this lies in the fact that . In the text, they proved the special case where . This is a slightly more relaxation condition to show that doesn't need to be the identity everywhere it just needs to be the identity on the edge of the disk where it meets the circle.  I'm thinking of like taking a sample from the embedding of rather than from at large. The text used the notation to show this operation. Once we've chosen that , we can apply the map to aquire our point on the edge of the disk.  Since , the rule that still applies, but if we force to be the \"head\" of the arrow then we'll have an arrow whose \"head\" lies on the boundary, which also happens to be the same point we originated from.   Construction diagram for our map      Being able to follow the points back to their origins like this essentially gives us a retraction for . However, we already know such retraction can't exist! This means that our assumption that is false, which is logically equivalent to the assertion that . QED.  I must admint, this all feels a little \"hand wavy\" still. I'm not really sure how much of Euclidean geometry I'm projecting onto the situation. I think this is also a good spot to point out the \"antipodal\" map that we'd get by swapping the head and tail of our arrow between and :   Construction diagram for our antipodal map      I'd expect this map to have some fun properties. The one situation where we'd have an endomap on the circle with no fixed points is the one that maps each point to the one opposite it, but this needs a fixed point for us to reflect over. I think this is going to be important later.     Exercise 2:   Suppose is a 'retract' of ...    Let's sort through our givens here. We know we have with . We also know that has a fixed point property: for every endomap there exists some with . We want to show that has the same property for maps from .  Let's start by having a look at the class of endomaps . Each map must have some corresponding map given by . We can apply on the left and on the right to get an equivalent expresson for in terms of :      Since this map has some fixed point such that , there must be some corresponding point in given by that has this property for . It should then follow that is a fixed point of satisfying.         Having proven that , we've established our fixed point property and I think we're done.     Exercise 3:   Use the result of the preceeding exercise, ...    Let's recap the last exercise: Given \"A is a retract of X\" ( ) and \"X has the fixed point property for maps from T\" ( such that ), it follows that \"A also has the fixed point property\" ( such that ).  In the case of theorem (1), we can assume the premise \"Let be a line segment including its endpoints ( for Interval) and suppose is a continuous endomap. Then must have a fixed point: a point in for which .\"  We're attempting to show that this is sufficient to imply the corresponding retraction theorem: \"Consider the inclusion map of the two-point set as boundary of the interval . There is no continuous map which is a retraction for j.\"  Since is a two-point set, perhaps we can use the fact that there are only four possible endomaps that can exist in that space. These are illustrated below:   Possible endomaps on two point space      Of these four maps, precisely one has the property of \"having no fixed point\". This antipodal map sends each of the points in to the \"opposite\" point. For the sake of convenience, let's can name these points . The antipodal map is equivalent to the operation , with the other maps being given by , , . This is the unique endomap on satisfying .  I'm thinking the easiest way to approach this is to assume we have some map that acts like our \"antipodal\" map sending each point to it's mirror on the other half of the interval. For us to have any notion of continuity on this interval, we'd need to be able to take an arbitrarily small step to one side of each endpoint so we should be able to take the opposite step from the other. In other words, for any , we can pair with . Using the interval and as this operation, it's easy to see that produces a fixed point in the middle at where it's equidistantant from the endpoints .  If any map on this interval was going to \"have no fixed point\", it would have needed to be an antipodal map. In order for any map to possibly satisfy , it needs to divide the points into two sections. Our map either needs to map \"0.5\" to itself or to leave it undefined altogther. If we have arrows going from 0 to 1 and arrows from 1 to 0, at some point along the way the \"heads\" of our arrows need to go past the \"tails\" coming from the opposite direction.  Perhaps this makes more sense if I step back a bit and state something \"obvious\": There is no retraction from to .  has two points while has one.  might have a section, in which case we have one of the two bottom diagrams in the possible endomaps figure above. This would be our map that takes the fixed point and sends it to itself. We can go from , but we make by going from because there simply aren't enough points to work with.  It sounds like a variation of the intermediate value theorem. If there's a path of arrows leading from 0 to 1, then we should be able to reverse it and follow the arrows from 1 to 0. When we do, either there needs to be some fixed point that connects the heads from one path to the tails from the other or we don't have a continuous path we jump!  In summary:    The only endomap on with no fixed point is the antipodal map.    The only endomap on that could potentially not have a fixed point would be the antipodal map.    The antipodal map on has a fixed point.    There is no endomap on without fixed point.    Any retract preserves fixed points.    There is no retract from to     If it sounds like I'm unsure at this point, that's because I am. Maybe attempting the second theorem will provide more insight.  For (2) we're given that any continuous endomap on the closed disk, must have a fixed point. We want to prove that there is no continuous map which is a retraction for the inclusion map of the circle into the disk.  I think we can develop a similar definition of an \"antipodal map\" on the circle by reflecting across the center of the disk. This map is a unique endomap on . It has no fixed points for the circle   and acts as it's own inverse  . We can extend this map to the disk, but it fails to provide an inverse for the point at the center which we reflected over. Our antipodal map is the only possible section of the disk's boundary, but it fails to be a retraction due to this \"missing\" point in the middle.  A similar line of reasoning should hold true for the sphere. The antipodal map reflects each point on the sphere across the center to the opposite side. It's the only possible section that doesn't fix any points on the sphere, but then any corresponding retraction on the ball would be missing the center or have a fixed point there.  After all that, I'm still a little uncertain about this. I'm not convinced my proof is correct, but I also won't find out one way or the other unless I keep moving. So, on we go.     Exercise 4:   Express the restrictions given above on my travel and yours...    Story time! I'm chilling in Buffalo on a Friday morning when I get a call from a friend and decide to take a road trip to Rochester to vist them. So at noon, I jump in the car and start heading there, but I remember I left my wallet! I bust a U and go back home to look for it. By the time I find it, my tummy is growling. I head over my favorite taqueria for a bite. It's a little out of my way, but the salsa is to die for. I finally get on the road again, but now everyone is getting out of work so I hit some nasty traffic on the way. After crawling along a snail's pace for a few hours I'm starting to get tired and need to use the restroom. I make a quick detour to a little cafe I just passed. By the time I'm back on the road again, traffic has cleared up and it's a straight shot to Rochester at 5:00pm. My trip might look something like this:   Sample map corresponding to \"my\" story      Okay, maybe I got carried away, but this is \"my\" story. It has a beginning, in Buffalo at noon and it has an end, in Rochester at 5:00pm. In the figure above, the horizontal axis is the time in hours since my departure, and the vertical axis in the distance in miles along the road. Note that in my story, I double back for tacos, which is why there's a section in the map with negative distance. \"Your\" story might be a little different, but what I do know is that you were \"somewhere on the road between Buffalo and Rochester\" for the entire duration. For now, let's suppose you just drive back a forth along some stretch of road in the middle like so:   Sample map corresponding to \"your\" story      It should be obvious in this case that our paths have to cross, but we're trying to generalize these maps as much as possible. For now, let's start giving some of these objects proper names.  Let be our start time and end time for \"endpoints\" of the trip in \"time\". Let be Buffalo and Rochester, our \"endpoints\" on the \"road\". Since both time and space are continuous, these endpoints can be included in the respective intervals and . Let's call the inclusion map on the \"time\"-line to be and the inclusion map on the \"position\"-line to be . Note that Brouwer's 1st Theorem says there can't exist any retractions for either of these maps.  My position at any given time is a map that needs to satisfy certain conditions. I know and : that at the start of my trip I'm in Buffalo and at the end I'm in Rochester. Note that since our endpoints are included: .  The premise of this thought experiment is based around the idea that if \"you\" also have a map we must necessarily meet somewhere in that \"space-time\". We're using some kind of \"freeway distance\", where my 'location' sticks to the exit I took off it when I needed to make a stop.  Maybe \"you\" lived your entire life in Buffalo such that your , our meeting place would be at the start of of my trip or some time prior! In the other extreme, maybe you've lived your entire life in Rochester and your . In this case, \"you meeting me\" is contigent on \"me deciding to make the trip\" and we \"meet\" at 5:00pm. It's also possible you've never been to either Buffalo nor Rochester but live some place along the way, or maybe have been to one but not the other. In any of these cases, we can can map your position to some sub-interval of for the entire time period .  What I'm going to argue is that if you have such a map and we never meet we can construct a continuous retraction from with no fixed point. Since Brouwer's theorem establishes that such a retraction can't exist, there must be some with the property .  First, let's rule out the \"easy maps\". Suppose I hadn't doubled back at all and moved steadily from Buffalo to Rochester so that my path is invertable I have a unique position for every time. We'd be able to use your map construct endomap on through the composition given by . Our fixed point theorem says any continuous endomap has a fixed point, so there's some with . Apply on the left side to get . We meet at time and position .  What if your map is invertable? Well, then we could use it to construct an endomap on . We compose . This implies there's some fixed point with . Note that our spaces are different, so here we meet at time and position .  There is however, one map that might have the property . Imagine my \"evil twin\". This twin starts in the opposite city and takes the opposite that I do along the way. If map is going to avoid coming into contact with me at every step in my journey, it would have to be him. He takes every step I do, but in the opposite direction! This is the composition of my map with the \"antipodal map\" on it takes every moment in my journey in reverse. If my map is continuous, so is my evil twin. If there's a sequence of arrows, we can reverse them.  We've already established that my journey is not invertable, so it stands to reason that my evil twin would also have that property. But check this out, even me and my evil twin need to meet!   My \"evil twin\" map    The composition of the antipodal map on followed my must be the same as followed by the antipodal map on . My trip needs to be reversable, but we've already shown that it can't be. The fixed point theorem says me and my evil twin have to either meet or jump over each other the map can't be continuous without the meet-up!  I'm thinking that we can use the meeting place of myself and my evil twin as an approximation for the midpoint of my journey. Your map needs to have some evil twin midpoint also. If we alternate \"halfway points\", we should be able to do something of a binary search to home in on each other's location in terms of whether we're closer in the front or back half of our respective trips. Essentially, we'd have an analogue for the mean value theorem .  I think this is about as close as I'm going to get for \"an answer\" to (a) and (b) for the week. I'm not really sure how I would generalize it further for (c) and (d). I feel like right now there's a glaring weak spot in my argument by even assuming is well-defined for the entire space. What if \"you\" were born or died sometime during my trip? Would I still necessarily \"meet\" you?  The thing that I'm left curious is about the connection between Brouwer's theorems and my notions about simplices. I'm used to this idea of going from a point , to a line segment , to a triangle , to a tetrahedra , and then generalizing to higher dimensional spaces from there. There seems like an obvious parallel to Brouwer's first theorem that says we can't have a retraction from to , or from any to with for that matter.    Having \"attempted\" all of the exercises in the session, I think I'll stop here. I feel like I could easily spend another week on this session, but since the authors explicitly state it's not important I'll take them for their word. They obviously have spent a lot more time on it than I have. I didn't even have time to proofread myself this week!  "
},
{
  "id": "session10-4",
  "level": "2",
  "url": "session10.html#session10-4",
  "type": "Example",
  "number": "3.12.1",
  "title": "Exercise 1:.",
  "body": " Exercise 1:   Let be, as before, the inclusion of the circle into the disk...    We're given that we have two continuous maps and that . We want to show that there's some point such that We're also told to use the retraction theorem , and the revelevant one states that \"there is no continuous map which is a retraction for j\".  Let's suppose for a second that the opposite were true: for every . Since these two points are different, we can construct an arrow using one of them as the \"tail\" and one as the \"head\". We can define a map that follows this arrow until it reaches the boundary point on the circle like so:   Construction diagram for our map      Since we're guaranteed to have , let's see what happens when we compose with it. If we could prove , we'd have a contradiction and be done, but it's not clear that's the case quite yet. I think the key to this lies in the fact that . In the text, they proved the special case where . This is a slightly more relaxation condition to show that doesn't need to be the identity everywhere it just needs to be the identity on the edge of the disk where it meets the circle.  I'm thinking of like taking a sample from the embedding of rather than from at large. The text used the notation to show this operation. Once we've chosen that , we can apply the map to aquire our point on the edge of the disk.  Since , the rule that still applies, but if we force to be the \"head\" of the arrow then we'll have an arrow whose \"head\" lies on the boundary, which also happens to be the same point we originated from.   Construction diagram for our map      Being able to follow the points back to their origins like this essentially gives us a retraction for . However, we already know such retraction can't exist! This means that our assumption that is false, which is logically equivalent to the assertion that . QED.  I must admint, this all feels a little \"hand wavy\" still. I'm not really sure how much of Euclidean geometry I'm projecting onto the situation. I think this is also a good spot to point out the \"antipodal\" map that we'd get by swapping the head and tail of our arrow between and :   Construction diagram for our antipodal map      I'd expect this map to have some fun properties. The one situation where we'd have an endomap on the circle with no fixed points is the one that maps each point to the one opposite it, but this needs a fixed point for us to reflect over. I think this is going to be important later.   "
},
{
  "id": "session10-5",
  "level": "2",
  "url": "session10.html#session10-5",
  "type": "Example",
  "number": "3.12.5",
  "title": "Exercise 2:.",
  "body": " Exercise 2:   Suppose is a 'retract' of ...    Let's sort through our givens here. We know we have with . We also know that has a fixed point property: for every endomap there exists some with . We want to show that has the same property for maps from .  Let's start by having a look at the class of endomaps . Each map must have some corresponding map given by . We can apply on the left and on the right to get an equivalent expresson for in terms of :      Since this map has some fixed point such that , there must be some corresponding point in given by that has this property for . It should then follow that is a fixed point of satisfying.         Having proven that , we've established our fixed point property and I think we're done.   "
},
{
  "id": "session10-6",
  "level": "2",
  "url": "session10.html#session10-6",
  "type": "Example",
  "number": "3.12.6",
  "title": "Exercise 3:.",
  "body": " Exercise 3:   Use the result of the preceeding exercise, ...    Let's recap the last exercise: Given \"A is a retract of X\" ( ) and \"X has the fixed point property for maps from T\" ( such that ), it follows that \"A also has the fixed point property\" ( such that ).  In the case of theorem (1), we can assume the premise \"Let be a line segment including its endpoints ( for Interval) and suppose is a continuous endomap. Then must have a fixed point: a point in for which .\"  We're attempting to show that this is sufficient to imply the corresponding retraction theorem: \"Consider the inclusion map of the two-point set as boundary of the interval . There is no continuous map which is a retraction for j.\"  Since is a two-point set, perhaps we can use the fact that there are only four possible endomaps that can exist in that space. These are illustrated below:   Possible endomaps on two point space      Of these four maps, precisely one has the property of \"having no fixed point\". This antipodal map sends each of the points in to the \"opposite\" point. For the sake of convenience, let's can name these points . The antipodal map is equivalent to the operation , with the other maps being given by , , . This is the unique endomap on satisfying .  I'm thinking the easiest way to approach this is to assume we have some map that acts like our \"antipodal\" map sending each point to it's mirror on the other half of the interval. For us to have any notion of continuity on this interval, we'd need to be able to take an arbitrarily small step to one side of each endpoint so we should be able to take the opposite step from the other. In other words, for any , we can pair with . Using the interval and as this operation, it's easy to see that produces a fixed point in the middle at where it's equidistantant from the endpoints .  If any map on this interval was going to \"have no fixed point\", it would have needed to be an antipodal map. In order for any map to possibly satisfy , it needs to divide the points into two sections. Our map either needs to map \"0.5\" to itself or to leave it undefined altogther. If we have arrows going from 0 to 1 and arrows from 1 to 0, at some point along the way the \"heads\" of our arrows need to go past the \"tails\" coming from the opposite direction.  Perhaps this makes more sense if I step back a bit and state something \"obvious\": There is no retraction from to .  has two points while has one.  might have a section, in which case we have one of the two bottom diagrams in the possible endomaps figure above. This would be our map that takes the fixed point and sends it to itself. We can go from , but we make by going from because there simply aren't enough points to work with.  It sounds like a variation of the intermediate value theorem. If there's a path of arrows leading from 0 to 1, then we should be able to reverse it and follow the arrows from 1 to 0. When we do, either there needs to be some fixed point that connects the heads from one path to the tails from the other or we don't have a continuous path we jump!  In summary:    The only endomap on with no fixed point is the antipodal map.    The only endomap on that could potentially not have a fixed point would be the antipodal map.    The antipodal map on has a fixed point.    There is no endomap on without fixed point.    Any retract preserves fixed points.    There is no retract from to     If it sounds like I'm unsure at this point, that's because I am. Maybe attempting the second theorem will provide more insight.  For (2) we're given that any continuous endomap on the closed disk, must have a fixed point. We want to prove that there is no continuous map which is a retraction for the inclusion map of the circle into the disk.  I think we can develop a similar definition of an \"antipodal map\" on the circle by reflecting across the center of the disk. This map is a unique endomap on . It has no fixed points for the circle   and acts as it's own inverse  . We can extend this map to the disk, but it fails to provide an inverse for the point at the center which we reflected over. Our antipodal map is the only possible section of the disk's boundary, but it fails to be a retraction due to this \"missing\" point in the middle.  A similar line of reasoning should hold true for the sphere. The antipodal map reflects each point on the sphere across the center to the opposite side. It's the only possible section that doesn't fix any points on the sphere, but then any corresponding retraction on the ball would be missing the center or have a fixed point there.  After all that, I'm still a little uncertain about this. I'm not convinced my proof is correct, but I also won't find out one way or the other unless I keep moving. So, on we go.   "
},
{
  "id": "session10-7",
  "level": "2",
  "url": "session10.html#session10-7",
  "type": "Example",
  "number": "3.12.8",
  "title": "Exercise 4:.",
  "body": " Exercise 4:   Express the restrictions given above on my travel and yours...    Story time! I'm chilling in Buffalo on a Friday morning when I get a call from a friend and decide to take a road trip to Rochester to vist them. So at noon, I jump in the car and start heading there, but I remember I left my wallet! I bust a U and go back home to look for it. By the time I find it, my tummy is growling. I head over my favorite taqueria for a bite. It's a little out of my way, but the salsa is to die for. I finally get on the road again, but now everyone is getting out of work so I hit some nasty traffic on the way. After crawling along a snail's pace for a few hours I'm starting to get tired and need to use the restroom. I make a quick detour to a little cafe I just passed. By the time I'm back on the road again, traffic has cleared up and it's a straight shot to Rochester at 5:00pm. My trip might look something like this:   Sample map corresponding to \"my\" story      Okay, maybe I got carried away, but this is \"my\" story. It has a beginning, in Buffalo at noon and it has an end, in Rochester at 5:00pm. In the figure above, the horizontal axis is the time in hours since my departure, and the vertical axis in the distance in miles along the road. Note that in my story, I double back for tacos, which is why there's a section in the map with negative distance. \"Your\" story might be a little different, but what I do know is that you were \"somewhere on the road between Buffalo and Rochester\" for the entire duration. For now, let's suppose you just drive back a forth along some stretch of road in the middle like so:   Sample map corresponding to \"your\" story      It should be obvious in this case that our paths have to cross, but we're trying to generalize these maps as much as possible. For now, let's start giving some of these objects proper names.  Let be our start time and end time for \"endpoints\" of the trip in \"time\". Let be Buffalo and Rochester, our \"endpoints\" on the \"road\". Since both time and space are continuous, these endpoints can be included in the respective intervals and . Let's call the inclusion map on the \"time\"-line to be and the inclusion map on the \"position\"-line to be . Note that Brouwer's 1st Theorem says there can't exist any retractions for either of these maps.  My position at any given time is a map that needs to satisfy certain conditions. I know and : that at the start of my trip I'm in Buffalo and at the end I'm in Rochester. Note that since our endpoints are included: .  The premise of this thought experiment is based around the idea that if \"you\" also have a map we must necessarily meet somewhere in that \"space-time\". We're using some kind of \"freeway distance\", where my 'location' sticks to the exit I took off it when I needed to make a stop.  Maybe \"you\" lived your entire life in Buffalo such that your , our meeting place would be at the start of of my trip or some time prior! In the other extreme, maybe you've lived your entire life in Rochester and your . In this case, \"you meeting me\" is contigent on \"me deciding to make the trip\" and we \"meet\" at 5:00pm. It's also possible you've never been to either Buffalo nor Rochester but live some place along the way, or maybe have been to one but not the other. In any of these cases, we can can map your position to some sub-interval of for the entire time period .  What I'm going to argue is that if you have such a map and we never meet we can construct a continuous retraction from with no fixed point. Since Brouwer's theorem establishes that such a retraction can't exist, there must be some with the property .  First, let's rule out the \"easy maps\". Suppose I hadn't doubled back at all and moved steadily from Buffalo to Rochester so that my path is invertable I have a unique position for every time. We'd be able to use your map construct endomap on through the composition given by . Our fixed point theorem says any continuous endomap has a fixed point, so there's some with . Apply on the left side to get . We meet at time and position .  What if your map is invertable? Well, then we could use it to construct an endomap on . We compose . This implies there's some fixed point with . Note that our spaces are different, so here we meet at time and position .  There is however, one map that might have the property . Imagine my \"evil twin\". This twin starts in the opposite city and takes the opposite that I do along the way. If map is going to avoid coming into contact with me at every step in my journey, it would have to be him. He takes every step I do, but in the opposite direction! This is the composition of my map with the \"antipodal map\" on it takes every moment in my journey in reverse. If my map is continuous, so is my evil twin. If there's a sequence of arrows, we can reverse them.  We've already established that my journey is not invertable, so it stands to reason that my evil twin would also have that property. But check this out, even me and my evil twin need to meet!   My \"evil twin\" map    The composition of the antipodal map on followed my must be the same as followed by the antipodal map on . My trip needs to be reversable, but we've already shown that it can't be. The fixed point theorem says me and my evil twin have to either meet or jump over each other the map can't be continuous without the meet-up!  I'm thinking that we can use the meeting place of myself and my evil twin as an approximation for the midpoint of my journey. Your map needs to have some evil twin midpoint also. If we alternate \"halfway points\", we should be able to do something of a binary search to home in on each other's location in terms of whether we're closer in the front or back half of our respective trips. Essentially, we'd have an analogue for the mean value theorem .  I think this is about as close as I'm going to get for \"an answer\" to (a) and (b) for the week. I'm not really sure how I would generalize it further for (c) and (d). I feel like right now there's a glaring weak spot in my argument by even assuming is well-defined for the entire space. What if \"you\" were born or died sometime during my trip? Would I still necessarily \"meet\" you?  The thing that I'm left curious is about the connection between Brouwer's theorems and my notions about simplices. I'm used to this idea of going from a point , to a line segment , to a triangle , to a tetrahedra , and then generalizing to higher dimensional spaces from there. There seems like an obvious parallel to Brouwer's first theorem that says we can't have a retraction from to , or from any to with for that matter.   "
},
{
  "id": "article3",
  "level": "1",
  "url": "article3.html",
  "type": "Section",
  "number": "4.1",
  "title": "Article 3: Examples of Categories, Part 1",
  "body": " Article 3: Examples of Categories, Part 1  I think this is about where I started getting lost the first time through this text, but I feel like I'm coming into it with a better foundation this time around. There's also 30 exercises over the course of Article 3, so I already anticipate a need to break it up into parts. I want to make sure I take my time here and really understand what's going on.   Exercise 1:   Show that if both as above and also...    Our basic idea here is that \"respects the structure\" of our category . That is:   Satisifies for all endomaps and .  Now suppose we have another map with    We can then compose these maps to produce a composition :   This map should preserve structure also if we can prove that . This should be fairly straight forward to show using the associative property and our previous assumptions:      And that completes the exercise.     Exercise 2:   What can you prove...    Recall that an endomap is \"idempotent\" if . If is a \"retraction\" for , that implies .  Watch what happens when if we apply on the right of both sides to :     Essentially, a retraction preserves the fixed point proprerty. Since fixes every point it touches and this retraction can restore each value afterwards, that can only happen if .     Exercise 3:   A finite set has an even number of elements iff...    I'm not really sure what the question is, so I'm assuming this is a \"prove it\" problem. I think this is essentially the approach I tried to take with Brouwer's theorems lasts.  If we define as set being \"even\" iff there is an involution with no fixed points. This is like the \"antipodal map\" I explored earlier that pairs up each point in a space with it's \"opposite\". When we're working with an antipodal map on the interval, we either we have a point in the middle that maps to itself or we \"jump\" over it. The fixed point property becomes a proxy for whether or not the map is continuous because we forced the interval to be \"odd\". The only problem with using this idea here is that the interval had a natural order to it while the set may not, so our involution isn't necessarily unique.  Maybe it might help to think of taking a map applying and taking an \"image\" of it for every . Either we find some point or we don't, but we can use this to classify each point as \"fixed\" or \"not\". Essentially this process defines map that returns if a point is fixed by or if it doesn't. However, since is known to be an involution with then there needs to be at least as many points in as there are in which ensures that .  Framing the problem like this allows us to ask if there exists a section of which permits a retraction on . More specifically, we're looking for a map with . If then , and consequently would be undefined. If has no fixed points then , and consequently would be undefined. In order for this map to exist, must have at least one fixed point and one non-fixed point. That is, for some we have and some such that with and .  The problem with this is that such a map can't exist without having at least three points: , , . It's impossible for a composition of the any form to ever produce an identity map. If a retraction for existed it would need to be the same as the section, so clearly the fixed point property on means that no map is a retraction from to .  I feel like I'm starting to talk in circles now, so I'll just add that I think there's some parallels to be made with the \"split idempotent\" exercise from Session 9.  If all points in are fixed, that implies a splitting of by . If no points in are fixed, that also implies a splitting of by . If has both fixed and non-fixed points, that implies a splitting of by . Since there is no isomorphism between and , we use the result of Session 9 Exercise 3 to infer that can't be split by both of them simultaneously. If our has both fixed and non-fixed points, the set of fixed points would preserve an isomorphism with  meaning that the point fixed by would necessarily be unique. Likewise, each non-fixed point needs to exists as part of a pair with some to preserve the isomorphism between and .  I'm not sure if I'm using this concept of \"splitting by \" correctly here, but it seems like it might be a reasonable analogy of \"division by two\" for generic maps.     Exercise 4:   If is considered as an endomap of ...    This would be characterized as an \"involution\" since implies . It has a fixed point at since . It's not idempotent since for any .     Exercise 5:   ..if instead ...    This would be characterized as an \"idempotent\" since implies . It has an infinite number of fixed points, since such that we have . It is not an involution since for any .     Exercise 6:   ...defined by the formula ...    The previous page defines \"automorphism\" as an \"endomap which is also an isomorphism\", so I'm going to have to say \"yes\". We can define the inverse by . It follows that and , satisfying the definition for an isomorphism. This map is neither idempotent nor an involution, and has no fixed points.     Exercise 7:   ... ...    Conceptually, we can loosely define an inverse by . However, this will not meet the definition for an automorphism. It mights the criteria for a \"section\" since , but it's not a \"retraction\" since for any which is not a multiple of 5. This map is neither idempotent nor an involution, but does have fixed point at 0.     Exercise 9:   In , consider the endomap ...    We're given an internal diagram for , and I took the liberty of naming our three points as follows:   Internal diagram of our map      Clearly the above diagram of is fully described by the relations , , and .  In order to demonstrate that , we just need to show it holds for all three points: that , , and . Let's verify these one at a time:     Having established that holds for all three values, let's next address idempotency by checking if . It's pretty clear that this fails for . but , so .  Finally, we need to check whether or not is an involution. Since an involution would imply , the case of serves as a counter-example to this expression.    Seeing that we move on to a new category after this exercise, I think this might be a good place to stop for the week. With the extra time, I managed to write a blog post about joining the Fediverse . Maybe my stream of cat pics will encourage others to have fun with cat theory.  "
},
{
  "id": "article3-3",
  "level": "2",
  "url": "article3.html#article3-3",
  "type": "Example",
  "number": "4.1.1",
  "title": "Exercise 1:.",
  "body": " Exercise 1:   Show that if both as above and also...    Our basic idea here is that \"respects the structure\" of our category . That is:   Satisifies for all endomaps and .  Now suppose we have another map with    We can then compose these maps to produce a composition :   This map should preserve structure also if we can prove that . This should be fairly straight forward to show using the associative property and our previous assumptions:      And that completes the exercise.   "
},
{
  "id": "article3-4",
  "level": "2",
  "url": "article3.html#article3-4",
  "type": "Example",
  "number": "4.1.2",
  "title": "Exercise 2:.",
  "body": " Exercise 2:   What can you prove...    Recall that an endomap is \"idempotent\" if . If is a \"retraction\" for , that implies .  Watch what happens when if we apply on the right of both sides to :     Essentially, a retraction preserves the fixed point proprerty. Since fixes every point it touches and this retraction can restore each value afterwards, that can only happen if .   "
},
{
  "id": "article3-5",
  "level": "2",
  "url": "article3.html#article3-5",
  "type": "Example",
  "number": "4.1.3",
  "title": "Exercise 3:.",
  "body": " Exercise 3:   A finite set has an even number of elements iff...    I'm not really sure what the question is, so I'm assuming this is a \"prove it\" problem. I think this is essentially the approach I tried to take with Brouwer's theorems lasts.  If we define as set being \"even\" iff there is an involution with no fixed points. This is like the \"antipodal map\" I explored earlier that pairs up each point in a space with it's \"opposite\". When we're working with an antipodal map on the interval, we either we have a point in the middle that maps to itself or we \"jump\" over it. The fixed point property becomes a proxy for whether or not the map is continuous because we forced the interval to be \"odd\". The only problem with using this idea here is that the interval had a natural order to it while the set may not, so our involution isn't necessarily unique.  Maybe it might help to think of taking a map applying and taking an \"image\" of it for every . Either we find some point or we don't, but we can use this to classify each point as \"fixed\" or \"not\". Essentially this process defines map that returns if a point is fixed by or if it doesn't. However, since is known to be an involution with then there needs to be at least as many points in as there are in which ensures that .  Framing the problem like this allows us to ask if there exists a section of which permits a retraction on . More specifically, we're looking for a map with . If then , and consequently would be undefined. If has no fixed points then , and consequently would be undefined. In order for this map to exist, must have at least one fixed point and one non-fixed point. That is, for some we have and some such that with and .  The problem with this is that such a map can't exist without having at least three points: , , . It's impossible for a composition of the any form to ever produce an identity map. If a retraction for existed it would need to be the same as the section, so clearly the fixed point property on means that no map is a retraction from to .  I feel like I'm starting to talk in circles now, so I'll just add that I think there's some parallels to be made with the \"split idempotent\" exercise from Session 9.  If all points in are fixed, that implies a splitting of by . If no points in are fixed, that also implies a splitting of by . If has both fixed and non-fixed points, that implies a splitting of by . Since there is no isomorphism between and , we use the result of Session 9 Exercise 3 to infer that can't be split by both of them simultaneously. If our has both fixed and non-fixed points, the set of fixed points would preserve an isomorphism with  meaning that the point fixed by would necessarily be unique. Likewise, each non-fixed point needs to exists as part of a pair with some to preserve the isomorphism between and .  I'm not sure if I'm using this concept of \"splitting by \" correctly here, but it seems like it might be a reasonable analogy of \"division by two\" for generic maps.   "
},
{
  "id": "article3-6",
  "level": "2",
  "url": "article3.html#article3-6",
  "type": "Example",
  "number": "4.1.4",
  "title": "Exercise 4:.",
  "body": " Exercise 4:   If is considered as an endomap of ...    This would be characterized as an \"involution\" since implies . It has a fixed point at since . It's not idempotent since for any .   "
},
{
  "id": "article3-7",
  "level": "2",
  "url": "article3.html#article3-7",
  "type": "Example",
  "number": "4.1.5",
  "title": "Exercise 5:.",
  "body": " Exercise 5:   ..if instead ...    This would be characterized as an \"idempotent\" since implies . It has an infinite number of fixed points, since such that we have . It is not an involution since for any .   "
},
{
  "id": "article3-8",
  "level": "2",
  "url": "article3.html#article3-8",
  "type": "Example",
  "number": "4.1.6",
  "title": "Exercise 6:.",
  "body": " Exercise 6:   ...defined by the formula ...    The previous page defines \"automorphism\" as an \"endomap which is also an isomorphism\", so I'm going to have to say \"yes\". We can define the inverse by . It follows that and , satisfying the definition for an isomorphism. This map is neither idempotent nor an involution, and has no fixed points.   "
},
{
  "id": "article3-9",
  "level": "2",
  "url": "article3.html#article3-9",
  "type": "Example",
  "number": "4.1.7",
  "title": "Exercise 7:.",
  "body": " Exercise 7:   ... ...    Conceptually, we can loosely define an inverse by . However, this will not meet the definition for an automorphism. It mights the criteria for a \"section\" since , but it's not a \"retraction\" since for any which is not a multiple of 5. This map is neither idempotent nor an involution, but does have fixed point at 0.   "
},
{
  "id": "article3-10",
  "level": "2",
  "url": "article3.html#article3-10",
  "type": "Example",
  "number": "4.1.8",
  "title": "Exercise 9:.",
  "body": " Exercise 9:   In , consider the endomap ...    We're given an internal diagram for , and I took the liberty of naming our three points as follows:   Internal diagram of our map      Clearly the above diagram of is fully described by the relations , , and .  In order to demonstrate that , we just need to show it holds for all three points: that , , and . Let's verify these one at a time:     Having established that holds for all three values, let's next address idempotency by checking if . It's pretty clear that this fails for . but , so .  Finally, we need to check whether or not is an involution. Since an involution would imply , the case of serves as a counter-example to this expression.   "
},
{
  "id": "article3-p2",
  "level": "1",
  "url": "article3-p2.html",
  "type": "Section",
  "number": "4.2",
  "title": "Article 3: Examples of Categories, Part 2",
  "body": " Article 3: Examples of Categories, Part 2  It's really interesting to the use of formalized abstraction here. We looked at some simple examples in and now we're embedding that in this broader category of directed graphs in a way that preserves the properties we used. It feels like we're \"stepping out of the box\" in a very deliberate fashion so what we can take what we know \"outside\" and apply it to solve problems \"inside\".   Exercise 10:   Complete the specification...    Okay my first step here is to reproduce our diagram:   Directed graph for Article 3 Exercise 10      While creating the diagram, there's some obvious structural patterns. In order to draw this, I started by placing the six points in . The other objects are the arrows, namely . Our maps and represent the source and target of each arrow. For me, it seemed natural to structure this information into a table:                                    Based on this table, the questions become fairly straight forward. The input has the same output points for and , specifically . There is no element with .  I'm thinking these sub-questions are important because they show that these arrow maps have neither \"retraction\" nor \"sections\". Unless we're very specific about the qualities of our maps, our source and target maps will likely be non-invertable. I find arrows and particularly interesting because they are two different arrows with the same source and same target . I feel like I'm fighting a natural tendancy to assume that \"having the same source and target\" makes them \"the same arrow\" but that equivalency may not necessarily hold true in a broader category.     Exercise 11:   If as above and...    Let's begin with a recap of what we know about :   Definition of for Article 3 Exercise 11      We're told that \"preserves source and target relations\", which is defined by having a pair of maps and satisfying and .  Consider another map with the same property:   Definition of for Article 3 Exercise 11      In order to preserve source and target relations, there would need to exist and with and .  We can form a composition of maps and as shown below:   Composition diagram for Article 3 Exercise 11      In order to show that the composition preserves source and target relations, we'd need to demonstrate that both and .  By the associative property, . Using the substition gives us , and allows us to the perform a subsitution using to show . It follows that .  We can apply a similar process on . The associative property gives us , which allows us to use the substition to get . Next we use our property that to perform another subsitution resulting in . It follows that .  Having established the source and target preservation properties, we can conclude that is an well defined -map:   Definition of for Article 3 Exercise 11         Exercise 12:   If we denote the result of the above process by ...    We want to show that . Or, \"the composition of embeddings is the same as the embedding of the composition\".  Our embedding of can be illustrated by the following diagram:   Diagram of for Article 3 Exercise 12      In order to preserve structure, the -map is required to preserve the relations and . The former is a trivial result of the identity map, while the later is a property inherits from being an object in .  Similarly, our embedding of can be illustrated as follows:   Diagram of for Article 3 Exercise 12      Like before, this preserves the properties and .  The embedding of our composition also should have similar structure:   Diagram of for Article 3 Exercise 12      This needs to satisfy and . The former is again a trivial result of the identity map. The latter is implied by the fact that since and are both objects in that we must also have . This establishes the relation .  Finally, let's compose these embeddings together and verify everything still holds:   Composition diagram of for Article 3 Exercise 12      It's easy to see how the embedding illustrations above are composed together together to produce an embedding of the compositions. The identity property ensures that . The structure inherited from the endomaps ensures that .  Having shown that these properties are preserved, I think we've sufficiently demonstrated that .     Exercise 13:   (Fullness) Show that...    We're given an -morphism that comes via the insertion that we used previously:   The source preservation property of implies that , but since and are identity maps we can just say . Since the target preservation property says , we can substitute to get . This property establishes that exists and is a valid -morphism: .     Exercise 14:   Give an example of of two endomaps...    To be honest, I wasn't quite sure how to start this one at first so I just started exploring small endomaps. I explored too many to review them all, but in the process I learned some things.  I think I had conceptually confused and at first. I was under the impression that \"produced an arrow\" and \"produced a dot\", but a closer reading of the book stated that \"operates on arrows\" and \"operates on dots\". Eventually I made a mental shift to the Spanish (before) and (after) because it helped me remember the relationship with the endomaps.  I found tables to be a nice way of organizing all the information about my \"arrows\" and \"dots\". Having my information organized reminded me of Exercise 10. Looking back over my notes, I had noticed earlier that the diagram included a pair of two different arrows with the same source and destination. I took this as a hint.  I also found myself repeatedly going back to the map in Example 9 as a reference. There was something about the way the endomap removes an element that seemed like it might be important. I labeled the arrows in addition to the points to help keep track of what I was working with:   Internal diagram of map from Exercise 9      I had a hunch that might help establish that . My idea revolved around the idea that if I could somehow make , , and by composing with itself multiple times that I could set up a situation where they balance out.  I think I also was confused about the inclusion and the property that the \"source and target structures are the same map\". I wasn't sure if I needed to enforce this restriction on that all arrows in my endomaps were loops or not. I started to wonder how much of this ambiguity was intentional, and if looser of a definition of \"loop\" might be in order.  A flash of insight came as I was trying to pick out a cat photo for the week and see Alphonse nuzzling Konshu:   Alphonse nuzzles a statuette of Konshu.   A brown tabby lays in a blue cat bed and nuzzles a small figure depicting the Egyptian deity Konshu.    I started to think about Moon Knight and the relation between the depiction of Konshu in the comic books versus the mythological depiction of the same character. I wondered how my mental model of Konshu might vary depending on which version I encountered first. To appease my \"fussy professor\", I'm going to define my set to be the set of \"Konshu Models\" and endomap to be the \"influences\" acting on those models.   Defining and on \"Konshu models\"      I reasoned that the Moon Knight from the comics used the mythology around Konshu to develop the character, but as more people read the comic they start to project qualities from the comic character back to the deity. Whether those projections align with the mythology will impact the design of later comics, forming a sort of feedback loop. Prior to seeing the Netflix show, my model of Konshu isn't really impacted by either I'm just off in my own little world.  Now let's denote to be a map describing how my metal model might change after exposure to new ideas. Maybe seeing the Netflix show prompts me to read a bunch of comics or mythology. In either case, it forms a feedback loop between my model of the comic Konshu and my model of the myth Konshu. Let's call this our set and endomap :   Defining and on mental models.      Now let's consider or maps and . Let's say that is the case where I learn about Konshu mythos before watching the Netflix show and to be the case where I'm exposed to the mythology after. For the sake of convenience, I'm going to relabel the points in the as and the points in as :   Defining and on \"Konshu models\"      Since and , clearly . However, we can also show that by evaluting them over the entire codomain:   Exploring outputs of compositions                                     In the table above, notice that the columns for and are equivalent for all three points. Thus, we have with .  I'm thinking that the moral of the story here is these endomaps contain more than self-loops, but our insertion fails to enforce that condition. If the endomap contains only self loops it has an insertion that makes a commutative diagram, but just because we have a commutative diagram like this doesn't mean it came from that insertion.    "
},
{
  "id": "article3-p2-3",
  "level": "2",
  "url": "article3-p2.html#article3-p2-3",
  "type": "Example",
  "number": "4.2.1",
  "title": "Exercise 10:.",
  "body": " Exercise 10:   Complete the specification...    Okay my first step here is to reproduce our diagram:   Directed graph for Article 3 Exercise 10      While creating the diagram, there's some obvious structural patterns. In order to draw this, I started by placing the six points in . The other objects are the arrows, namely . Our maps and represent the source and target of each arrow. For me, it seemed natural to structure this information into a table:                                    Based on this table, the questions become fairly straight forward. The input has the same output points for and , specifically . There is no element with .  I'm thinking these sub-questions are important because they show that these arrow maps have neither \"retraction\" nor \"sections\". Unless we're very specific about the qualities of our maps, our source and target maps will likely be non-invertable. I find arrows and particularly interesting because they are two different arrows with the same source and same target . I feel like I'm fighting a natural tendancy to assume that \"having the same source and target\" makes them \"the same arrow\" but that equivalency may not necessarily hold true in a broader category.   "
},
{
  "id": "article3-p2-4",
  "level": "2",
  "url": "article3-p2.html#article3-p2-4",
  "type": "Example",
  "number": "4.2.4",
  "title": "Exercise 11:.",
  "body": " Exercise 11:   If as above and...    Let's begin with a recap of what we know about :   Definition of for Article 3 Exercise 11      We're told that \"preserves source and target relations\", which is defined by having a pair of maps and satisfying and .  Consider another map with the same property:   Definition of for Article 3 Exercise 11      In order to preserve source and target relations, there would need to exist and with and .  We can form a composition of maps and as shown below:   Composition diagram for Article 3 Exercise 11      In order to show that the composition preserves source and target relations, we'd need to demonstrate that both and .  By the associative property, . Using the substition gives us , and allows us to the perform a subsitution using to show . It follows that .  We can apply a similar process on . The associative property gives us , which allows us to use the substition to get . Next we use our property that to perform another subsitution resulting in . It follows that .  Having established the source and target preservation properties, we can conclude that is an well defined -map:   Definition of for Article 3 Exercise 11       "
},
{
  "id": "article3-p2-5",
  "level": "2",
  "url": "article3-p2.html#article3-p2-5",
  "type": "Example",
  "number": "4.2.9",
  "title": "Exercise 12:.",
  "body": " Exercise 12:   If we denote the result of the above process by ...    We want to show that . Or, \"the composition of embeddings is the same as the embedding of the composition\".  Our embedding of can be illustrated by the following diagram:   Diagram of for Article 3 Exercise 12      In order to preserve structure, the -map is required to preserve the relations and . The former is a trivial result of the identity map, while the later is a property inherits from being an object in .  Similarly, our embedding of can be illustrated as follows:   Diagram of for Article 3 Exercise 12      Like before, this preserves the properties and .  The embedding of our composition also should have similar structure:   Diagram of for Article 3 Exercise 12      This needs to satisfy and . The former is again a trivial result of the identity map. The latter is implied by the fact that since and are both objects in that we must also have . This establishes the relation .  Finally, let's compose these embeddings together and verify everything still holds:   Composition diagram of for Article 3 Exercise 12      It's easy to see how the embedding illustrations above are composed together together to produce an embedding of the compositions. The identity property ensures that . The structure inherited from the endomaps ensures that .  Having shown that these properties are preserved, I think we've sufficiently demonstrated that .   "
},
{
  "id": "article3-p2-6",
  "level": "2",
  "url": "article3-p2.html#article3-p2-6",
  "type": "Example",
  "number": "4.2.14",
  "title": "Exercise 13:.",
  "body": " Exercise 13:   (Fullness) Show that...    We're given an -morphism that comes via the insertion that we used previously:   The source preservation property of implies that , but since and are identity maps we can just say . Since the target preservation property says , we can substitute to get . This property establishes that exists and is a valid -morphism: .   "
},
{
  "id": "article3-p2-7",
  "level": "2",
  "url": "article3-p2.html#article3-p2-7",
  "type": "Example",
  "number": "4.2.15",
  "title": "Exercise 14:.",
  "body": " Exercise 14:   Give an example of of two endomaps...    To be honest, I wasn't quite sure how to start this one at first so I just started exploring small endomaps. I explored too many to review them all, but in the process I learned some things.  I think I had conceptually confused and at first. I was under the impression that \"produced an arrow\" and \"produced a dot\", but a closer reading of the book stated that \"operates on arrows\" and \"operates on dots\". Eventually I made a mental shift to the Spanish (before) and (after) because it helped me remember the relationship with the endomaps.  I found tables to be a nice way of organizing all the information about my \"arrows\" and \"dots\". Having my information organized reminded me of Exercise 10. Looking back over my notes, I had noticed earlier that the diagram included a pair of two different arrows with the same source and destination. I took this as a hint.  I also found myself repeatedly going back to the map in Example 9 as a reference. There was something about the way the endomap removes an element that seemed like it might be important. I labeled the arrows in addition to the points to help keep track of what I was working with:   Internal diagram of map from Exercise 9      I had a hunch that might help establish that . My idea revolved around the idea that if I could somehow make , , and by composing with itself multiple times that I could set up a situation where they balance out.  I think I also was confused about the inclusion and the property that the \"source and target structures are the same map\". I wasn't sure if I needed to enforce this restriction on that all arrows in my endomaps were loops or not. I started to wonder how much of this ambiguity was intentional, and if looser of a definition of \"loop\" might be in order.  A flash of insight came as I was trying to pick out a cat photo for the week and see Alphonse nuzzling Konshu:   Alphonse nuzzles a statuette of Konshu.   A brown tabby lays in a blue cat bed and nuzzles a small figure depicting the Egyptian deity Konshu.    I started to think about Moon Knight and the relation between the depiction of Konshu in the comic books versus the mythological depiction of the same character. I wondered how my mental model of Konshu might vary depending on which version I encountered first. To appease my \"fussy professor\", I'm going to define my set to be the set of \"Konshu Models\" and endomap to be the \"influences\" acting on those models.   Defining and on \"Konshu models\"      I reasoned that the Moon Knight from the comics used the mythology around Konshu to develop the character, but as more people read the comic they start to project qualities from the comic character back to the deity. Whether those projections align with the mythology will impact the design of later comics, forming a sort of feedback loop. Prior to seeing the Netflix show, my model of Konshu isn't really impacted by either I'm just off in my own little world.  Now let's denote to be a map describing how my metal model might change after exposure to new ideas. Maybe seeing the Netflix show prompts me to read a bunch of comics or mythology. In either case, it forms a feedback loop between my model of the comic Konshu and my model of the myth Konshu. Let's call this our set and endomap :   Defining and on mental models.      Now let's consider or maps and . Let's say that is the case where I learn about Konshu mythos before watching the Netflix show and to be the case where I'm exposed to the mythology after. For the sake of convenience, I'm going to relabel the points in the as and the points in as :   Defining and on \"Konshu models\"      Since and , clearly . However, we can also show that by evaluting them over the entire codomain:   Exploring outputs of compositions                                     In the table above, notice that the columns for and are equivalent for all three points. Thus, we have with .  I'm thinking that the moral of the story here is these endomaps contain more than self-loops, but our insertion fails to enforce that condition. If the endomap contains only self loops it has an insertion that makes a commutative diagram, but just because we have a commutative diagram like this doesn't mean it came from that insertion.   "
},
{
  "id": "article3-p3",
  "level": "1",
  "url": "article3-p3.html",
  "type": "Section",
  "number": "4.3",
  "title": "Article 3: Examples of Categories, Part 3",
  "body": " Article 3: Examples of Categories, Part 3  Another week, another category. This time we're working with \"Reflexive Graphs\". Let's get to it!   Exercise 15   In a reflexive graph...    Let's start with our definition:   Definition of \"reflexive graph\"      Given this, we want to show and satisfy for . Since there's only four cases, it shouldn't be too much effort to list them all out:                        Conceptually, these properties would seem to imply that every point in serves as both source and target for some arrow in .     Exercise 16:   Show that... is determined by    First, let's formulate our definition with a diagram:   Structure preserving maps on reflexive graphs?      Where this gets interesting is when we look at all possible paths we can follow between and in addition to the ones between and . To follow the pattern of the previous categories, we'd need to enforce all 3 of the following:                   The order of that last one seems a little bit tricky since our retraction is heading in the opposite direction. At the same time, this map is presicely what allows us to \"solve\" for in terms of . In Exercise 15, we saw that this only works if there's an arrow forming a \"self-loop\" at each point. All our map needs to do is match up the self-looping arrows on each point in with the corresponding self-looping arrows on .  Let's suppose we use the common section on a point to produce some arrow . It follows that this arrow needs to form a self-loop such that , since and imply and respectively. We can then pair that point with a corresponding self-looping arrow with . We know such a loop needs to exist because and would need to satisfy . Finally, we can put this all together to define over all possible points in .  I feel like there's probably an easier way to demonstrate this using contradiction.  Suppose for a minute that there did exist some point which satistfies . You could use the structure preserving criteria of to establish that . Since we also know , that previous equation simplifies down to , which directly contradicts the identity property of . Our assumption must therefore be false and . QED .     Exercise 17:   Consider a structure...    Let's lay out the structure we're examining:   Map structure for Article 3 Exercise 17      If we're going to build a map between two such structures, we'll need to include a pair of maps like so:   Paired structures for Article 3 Exercise 17      At a glance, the structure of this combined diagram resembles a composition of two -morphisms with another yet-to-be named structure that's resembles our reflexive graph. I feel like it deserves some cool symbol like .  Let's start with the more familiar structures. I'd want this map to preserve the behavior of the endomaps and on each set. I'd want the maps to behave like -morphisms here. Specifically, means that I'd want and means that I'd want .  With the remaining four maps, , we can form multiple paths from to and to . We'd want this map to preserve those relations as well: and   Having a set of four equations to go with four pairs of maps seems consistent we what we saw for the other maps.     Exercise 18:   If has a retraction...    To prove is injective, we'll need the provided definition:   External diagram to define injectivity      We're given that has a retraction such that . To prove is injective, we need to demonstrate that for any and it follows that .  Let's approach this through contradiction. Suppose we had some that satisfy . Compose on the left of both sides:     This contradicts our assumption that , which means that no such exist. It follows that and is injective.     Exercise 19:   ... in .    Our maps here are defined by the following diagram:   Diagram showing definitions of      To show in , we'll need to demonstrate that over the entire domain . We're given both and , so these are fairly trivial:        Since those are the only points we have, we can safely conclude that .     Exercise 20:   ... is injective.    Since is only defined for two points, any and such that would directly imply that these two points are in fact the complete set . Since , it follows that so clearly .     Exercise 21:   ... exactly two retractions .    Essentially, the retractions must contain the reversed arrows of , but that leaves two possible places for it to send the third point which didn't already have an origin defined:   Diagram showing possible retractions      For any retraction , we'd be forced to have and in order to have . As a map , needs to do something with the point and there are only two choices. Let's call them such that and .     Exercise 22:   ... has no retraction in .    As in the previous exercise, our only possible retractions are and , depending on where they send . For to be a valid -map, it needs to have the property . We'll test each of our two possiblities for in turn.  For , we'd have and . Since , is not a valid -map.  For , we'd have and . Since , is not a valid -map.  Having exhausted both possible retractions of , we're forced to conlude that no retraction exists in .     Exercise 23:   How many of the eight maps...    I'm going to start by sketching out the eight possible maps :   Grid of possible maps      In order for to be an -map, it needs to satisfy . Let's go through those maps again, but this time produce tables of those values for each of    Grid of possible maps      It appears that there are precisely two possible -maps. The one that sends everything to 0 and the one that sends everything to 0 but which it instead sends to . These two maps make sense when considering the behavior of the endomap which always returns 0.     Exercise 24:   ...in the 'looser' category .    Let's diagram the insertion for our present maps:   Commutative square of maps for      Suppose is a retraction for in such that . We saw in Exercise 21 that there are precisely two possible maps could be. We know and . The only question was if or .  However, for to be a member of this category, it needs to satisfy the equation on the following commutative square:   Commutative square of maps for      In Exercise 23, our exhaustive search of maps revealed only two maps for which . However, neither of those maps match up with the only two possible retractions for . We're forced to conclude that can't exist a map meeting these conditions.    I think this is a good stopping point for the week. Despite being in the middle of \"Retractions and injectivity\", I want to be able to take my time with Exercise 25. Page breaks are breaks too!  "
},
{
  "id": "article3-p3-3",
  "level": "2",
  "url": "article3-p3.html#article3-p3-3",
  "type": "Example",
  "number": "4.3.1",
  "title": "Exercise 15.",
  "body": " Exercise 15   In a reflexive graph...    Let's start with our definition:   Definition of \"reflexive graph\"      Given this, we want to show and satisfy for . Since there's only four cases, it shouldn't be too much effort to list them all out:                        Conceptually, these properties would seem to imply that every point in serves as both source and target for some arrow in .   "
},
{
  "id": "article3-p3-4",
  "level": "2",
  "url": "article3-p3.html#article3-p3-4",
  "type": "Example",
  "number": "4.3.3",
  "title": "Exercise 16:.",
  "body": " Exercise 16:   Show that... is determined by    First, let's formulate our definition with a diagram:   Structure preserving maps on reflexive graphs?      Where this gets interesting is when we look at all possible paths we can follow between and in addition to the ones between and . To follow the pattern of the previous categories, we'd need to enforce all 3 of the following:                   The order of that last one seems a little bit tricky since our retraction is heading in the opposite direction. At the same time, this map is presicely what allows us to \"solve\" for in terms of . In Exercise 15, we saw that this only works if there's an arrow forming a \"self-loop\" at each point. All our map needs to do is match up the self-looping arrows on each point in with the corresponding self-looping arrows on .  Let's suppose we use the common section on a point to produce some arrow . It follows that this arrow needs to form a self-loop such that , since and imply and respectively. We can then pair that point with a corresponding self-looping arrow with . We know such a loop needs to exist because and would need to satisfy . Finally, we can put this all together to define over all possible points in .  I feel like there's probably an easier way to demonstrate this using contradiction.  Suppose for a minute that there did exist some point which satistfies . You could use the structure preserving criteria of to establish that . Since we also know , that previous equation simplifies down to , which directly contradicts the identity property of . Our assumption must therefore be false and . QED .   "
},
{
  "id": "article3-p3-5",
  "level": "2",
  "url": "article3-p3.html#article3-p3-5",
  "type": "Example",
  "number": "4.3.5",
  "title": "Exercise 17:.",
  "body": " Exercise 17:   Consider a structure...    Let's lay out the structure we're examining:   Map structure for Article 3 Exercise 17      If we're going to build a map between two such structures, we'll need to include a pair of maps like so:   Paired structures for Article 3 Exercise 17      At a glance, the structure of this combined diagram resembles a composition of two -morphisms with another yet-to-be named structure that's resembles our reflexive graph. I feel like it deserves some cool symbol like .  Let's start with the more familiar structures. I'd want this map to preserve the behavior of the endomaps and on each set. I'd want the maps to behave like -morphisms here. Specifically, means that I'd want and means that I'd want .  With the remaining four maps, , we can form multiple paths from to and to . We'd want this map to preserve those relations as well: and   Having a set of four equations to go with four pairs of maps seems consistent we what we saw for the other maps.   "
},
{
  "id": "article3-p3-6",
  "level": "2",
  "url": "article3-p3.html#article3-p3-6",
  "type": "Example",
  "number": "4.3.8",
  "title": "Exercise 18:.",
  "body": " Exercise 18:   If has a retraction...    To prove is injective, we'll need the provided definition:   External diagram to define injectivity      We're given that has a retraction such that . To prove is injective, we need to demonstrate that for any and it follows that .  Let's approach this through contradiction. Suppose we had some that satisfy . Compose on the left of both sides:     This contradicts our assumption that , which means that no such exist. It follows that and is injective.   "
},
{
  "id": "article3-p3-7",
  "level": "2",
  "url": "article3-p3.html#article3-p3-7",
  "type": "Example",
  "number": "4.3.10",
  "title": "Exercise 19:.",
  "body": " Exercise 19:   ... in .    Our maps here are defined by the following diagram:   Diagram showing definitions of      To show in , we'll need to demonstrate that over the entire domain . We're given both and , so these are fairly trivial:        Since those are the only points we have, we can safely conclude that .   "
},
{
  "id": "article3-p3-8",
  "level": "2",
  "url": "article3-p3.html#article3-p3-8",
  "type": "Example",
  "number": "4.3.12",
  "title": "Exercise 20:.",
  "body": " Exercise 20:   ... is injective.    Since is only defined for two points, any and such that would directly imply that these two points are in fact the complete set . Since , it follows that so clearly .   "
},
{
  "id": "article3-p3-9",
  "level": "2",
  "url": "article3-p3.html#article3-p3-9",
  "type": "Example",
  "number": "4.3.13",
  "title": "Exercise 21:.",
  "body": " Exercise 21:   ... exactly two retractions .    Essentially, the retractions must contain the reversed arrows of , but that leaves two possible places for it to send the third point which didn't already have an origin defined:   Diagram showing possible retractions      For any retraction , we'd be forced to have and in order to have . As a map , needs to do something with the point and there are only two choices. Let's call them such that and .   "
},
{
  "id": "article3-p3-10",
  "level": "2",
  "url": "article3-p3.html#article3-p3-10",
  "type": "Example",
  "number": "4.3.15",
  "title": "Exercise 22:.",
  "body": " Exercise 22:   ... has no retraction in .    As in the previous exercise, our only possible retractions are and , depending on where they send . For to be a valid -map, it needs to have the property . We'll test each of our two possiblities for in turn.  For , we'd have and . Since , is not a valid -map.  For , we'd have and . Since , is not a valid -map.  Having exhausted both possible retractions of , we're forced to conlude that no retraction exists in .   "
},
{
  "id": "article3-p3-11",
  "level": "2",
  "url": "article3-p3.html#article3-p3-11",
  "type": "Example",
  "number": "4.3.16",
  "title": "Exercise 23:.",
  "body": " Exercise 23:   How many of the eight maps...    I'm going to start by sketching out the eight possible maps :   Grid of possible maps      In order for to be an -map, it needs to satisfy . Let's go through those maps again, but this time produce tables of those values for each of    Grid of possible maps      It appears that there are precisely two possible -maps. The one that sends everything to 0 and the one that sends everything to 0 but which it instead sends to . These two maps make sense when considering the behavior of the endomap which always returns 0.   "
},
{
  "id": "article3-p3-12",
  "level": "2",
  "url": "article3-p3.html#article3-p3-12",
  "type": "Example",
  "number": "4.3.19",
  "title": "Exercise 24:.",
  "body": " Exercise 24:   ...in the 'looser' category .    Let's diagram the insertion for our present maps:   Commutative square of maps for      Suppose is a retraction for in such that . We saw in Exercise 21 that there are precisely two possible maps could be. We know and . The only question was if or .  However, for to be a member of this category, it needs to satisfy the equation on the following commutative square:   Commutative square of maps for      In Exercise 23, our exhaustive search of maps revealed only two maps for which . However, neither of those maps match up with the only two possible retractions for . We're forced to conclude that can't exist a map meeting these conditions.   "
},
{
  "id": "article3-p4",
  "level": "1",
  "url": "article3-p4.html",
  "type": "Section",
  "number": "4.4",
  "title": "Article 3: Examples of Categories, Part 4",
  "body": " Article 3: Examples of Categories, Part 4  The end of the Article 3 is within sight! I'm starting to feel a little bit better about my solution to Exercise 14 earlier and I'm glad I explored some small permutations in advance of Exercise 26. Let's see if we can formalize a notion of loops to wrap up this Article.   Exercise 25:   Show that for any two graphs...    Given a -map between two graphs, we want to show can only be true when maps every arrow in to a loop in . Our external diagram is reproduced below:   Definition of -map      Thinking back to Exercises 9, the looping behavior of our endomap was based on the property that . I'm going to suggest that we can define an n-loop by the existence of endomap such that over some subspace with that many elements. Then each 1-loop would be a fixed point for the endomap and a 2-loop would be an antipodal endomap on two points.  So what would these loops look like here? An n-loop in would need to be some sequence of where .  I think the key to is that the equation is essentially identifying a fixed point where both the source and target of an arrow from wind up at the same point in after the transformation. Our category enforces that and , so it follows that this equation is equivalent to the expression . In other words, any for which would directly correspond with a loop such that .  Clearly, any self-loop in must get matched up with a self-loop in . If for any we have , it follows naturally that both and .  Suppose we have some arrow in satisfying but for which . This needs to map to an arrow which would need to satisfy the condition that . It follows that which forms another self-loop. So whether or not we start with a self-loop in , we must wind up with one in .  This result seems almost too simple. I was expecting to need to work with loops of varying lengths, but it turns out the 1-loops were the only ones I needed. I may need to come back to this later.     Exercise 26:   There is an 'inclusion' map...    I'm thinking that the map is the same as the one we used in Exercise 7. Previously we showed that \"multiplying by 5\" was not an invertable operation on the integers because the reverse operation of \"dividing by 5\" is not defined on the same domain. Now it looks like we're planning to sidestep that issue by inserting our map in instead.  Let's consider a trivial insertion of where we simply define . I guess more specifically, we assign each integer to the rational number . In order for this to be a valid -map, then we'd need to satisfy the equation . This follows directly from commutative property of multiplication: .  Since we've already established that we're working with an endomap on , to show that is an \"automorphism\" we just need to show it has an inverse. The inverse function would be given by the map . For any , we have . It follows that since is both an endomap and invertable, it meets the definition of an automorphism.  All that's left is to prove our map is injective . For any pair and such that , our choice of implies this statement is equivalent to .  Another way to think of this would be that is injective when it has a retraction . In this case, the map given by meets this condition. For any , so .     Exercise 27   Consider our standard idempotent...    Given the standard idempotent   Definition of standard idempotent      and an automorphism , we want to show any -map must be non-injective. Our \"hint\" is that the map must send both elements of to the same fixed point in .  It follows from the definition of -map that . However, is given as an automorphism which means it must have some inverse map such that . Apply this map to the left sides of our earlier expression to get .  Since there's literally only two elements in , let's call them and denote the behavior of by for . It follows from that is a \"fixed point\" in since . It also follows that returns the same fixed point. Having shown that for some , we've demonstrated that is non-injective.     Exercise 28:   If is any object of ...    Given that we have an injective map , it must also have some retraction such that . We're also given that is an automorphism, which guarantees it has an inverse .  We want to prove that itself must be injective. It suffices to show there exists a retraction . I'm going to claim that the map should have this desired property.  We can use this definition to expand the expression :   As a -map, we know :     And there we have it!     Exercise 29:  Every map in ...   There's an awful lot to unpack here so lets start with a category . We know we have some sets of objects or and maps which obey the identity and associative properties over the domain and codomain.  Over the course of the article, we've seen that there's a natural insertion of this map into the category . For each pair of object and such that , we can think of the map as a collection of \"arrows\" with a source at which we indicate and a target object at which we indicate .  From what I gather, our supplements this insertion with an arbitrary number of additional properties . Each individual property gets a corresponding map that returns the value of the property with that name. For any property map , we can either access this property before we apply the map or after . This provides natural defintion of preserving the structure of each property so that as follows:   Definition of structure preservation in .      Our -figures must satisfy these conditions for every property. If that's the case, then we can embed our -map representation of by treating our maps and as \"just another property\" in an -figure. Perhaps this might be diagrammed as follows:   Insertion of -map into .      The -structure would preserves the the source and targets of our map . Essentially, each map can be expressed as an -structure with two components if we let be our \"source\" map and be our \"target\" map.  I'm not entirely sure, but I think the existence of such an embedding would reasonably demonstrate this notion of \"giving rise to a map in the category\".    I know there's only one problem left here, but it's already Caturday and I want to give it the time it deserves. Until next time!  "
},
{
  "id": "article3-p4-3",
  "level": "2",
  "url": "article3-p4.html#article3-p4-3",
  "type": "Example",
  "number": "4.4.1",
  "title": "Exercise 25:.",
  "body": " Exercise 25:   Show that for any two graphs...    Given a -map between two graphs, we want to show can only be true when maps every arrow in to a loop in . Our external diagram is reproduced below:   Definition of -map      Thinking back to Exercises 9, the looping behavior of our endomap was based on the property that . I'm going to suggest that we can define an n-loop by the existence of endomap such that over some subspace with that many elements. Then each 1-loop would be a fixed point for the endomap and a 2-loop would be an antipodal endomap on two points.  So what would these loops look like here? An n-loop in would need to be some sequence of where .  I think the key to is that the equation is essentially identifying a fixed point where both the source and target of an arrow from wind up at the same point in after the transformation. Our category enforces that and , so it follows that this equation is equivalent to the expression . In other words, any for which would directly correspond with a loop such that .  Clearly, any self-loop in must get matched up with a self-loop in . If for any we have , it follows naturally that both and .  Suppose we have some arrow in satisfying but for which . This needs to map to an arrow which would need to satisfy the condition that . It follows that which forms another self-loop. So whether or not we start with a self-loop in , we must wind up with one in .  This result seems almost too simple. I was expecting to need to work with loops of varying lengths, but it turns out the 1-loops were the only ones I needed. I may need to come back to this later.   "
},
{
  "id": "article3-p4-4",
  "level": "2",
  "url": "article3-p4.html#article3-p4-4",
  "type": "Example",
  "number": "4.4.3",
  "title": "Exercise 26:.",
  "body": " Exercise 26:   There is an 'inclusion' map...    I'm thinking that the map is the same as the one we used in Exercise 7. Previously we showed that \"multiplying by 5\" was not an invertable operation on the integers because the reverse operation of \"dividing by 5\" is not defined on the same domain. Now it looks like we're planning to sidestep that issue by inserting our map in instead.  Let's consider a trivial insertion of where we simply define . I guess more specifically, we assign each integer to the rational number . In order for this to be a valid -map, then we'd need to satisfy the equation . This follows directly from commutative property of multiplication: .  Since we've already established that we're working with an endomap on , to show that is an \"automorphism\" we just need to show it has an inverse. The inverse function would be given by the map . For any , we have . It follows that since is both an endomap and invertable, it meets the definition of an automorphism.  All that's left is to prove our map is injective . For any pair and such that , our choice of implies this statement is equivalent to .  Another way to think of this would be that is injective when it has a retraction . In this case, the map given by meets this condition. For any , so .   "
},
{
  "id": "article3-p4-5",
  "level": "2",
  "url": "article3-p4.html#article3-p4-5",
  "type": "Example",
  "number": "4.4.4",
  "title": "Exercise 27.",
  "body": " Exercise 27   Consider our standard idempotent...    Given the standard idempotent   Definition of standard idempotent      and an automorphism , we want to show any -map must be non-injective. Our \"hint\" is that the map must send both elements of to the same fixed point in .  It follows from the definition of -map that . However, is given as an automorphism which means it must have some inverse map such that . Apply this map to the left sides of our earlier expression to get .  Since there's literally only two elements in , let's call them and denote the behavior of by for . It follows from that is a \"fixed point\" in since . It also follows that returns the same fixed point. Having shown that for some , we've demonstrated that is non-injective.   "
},
{
  "id": "article3-p4-6",
  "level": "2",
  "url": "article3-p4.html#article3-p4-6",
  "type": "Example",
  "number": "4.4.6",
  "title": "Exercise 28:.",
  "body": " Exercise 28:   If is any object of ...    Given that we have an injective map , it must also have some retraction such that . We're also given that is an automorphism, which guarantees it has an inverse .  We want to prove that itself must be injective. It suffices to show there exists a retraction . I'm going to claim that the map should have this desired property.  We can use this definition to expand the expression :   As a -map, we know :     And there we have it!   "
},
{
  "id": "article3-p4-7",
  "level": "2",
  "url": "article3-p4.html#article3-p4-7",
  "type": "Example",
  "number": "4.4.7",
  "title": "Exercise 29:.",
  "body": " Exercise 29:  Every map in ...   There's an awful lot to unpack here so lets start with a category . We know we have some sets of objects or and maps which obey the identity and associative properties over the domain and codomain.  Over the course of the article, we've seen that there's a natural insertion of this map into the category . For each pair of object and such that , we can think of the map as a collection of \"arrows\" with a source at which we indicate and a target object at which we indicate .  From what I gather, our supplements this insertion with an arbitrary number of additional properties . Each individual property gets a corresponding map that returns the value of the property with that name. For any property map , we can either access this property before we apply the map or after . This provides natural defintion of preserving the structure of each property so that as follows:   Definition of structure preservation in .      Our -figures must satisfy these conditions for every property. If that's the case, then we can embed our -map representation of by treating our maps and as \"just another property\" in an -figure. Perhaps this might be diagrammed as follows:   Insertion of -map into .      The -structure would preserves the the source and targets of our map . Essentially, each map can be expressed as an -structure with two components if we let be our \"source\" map and be our \"target\" map.  I'm not entirely sure, but I think the existence of such an embedding would reasonably demonstrate this notion of \"giving rise to a map in the category\".   "
},
{
  "id": "article3-p5",
  "level": "1",
  "url": "article3-p5.html",
  "type": "Section",
  "number": "4.5",
  "title": "Article 3: Examples of Categories, Part 5",
  "body": " Article 3: Examples of Categories, Part 5  Alright, last problem of the Article.   Exercise 30:   If is a given bipointed object...    There's a lot to unpack here. Let's start with the \"bipointed object\" in a category :   Definition of bipointed object.      Our goal is to demonstrate that \"the graph of ' fields' on is actually a reflexive graph\". Before I get there, I think I want to try to break down the \"tempature field\" situation to get my bearings.  My conventual notion of a \"tempature field\" would be like a map from some 3D-space such as describing the position to a 1D-line such as describing the temperature at each point in Kelvins. Or at least that's the basic idea that I'm trying to generalize. Maybe my space is the 2D image of a camera and my temperature line is an interval of temperatures it can detect.  I think this notion of a \"heat map\" produced by a digital camera is my best lead to go on. Years of programming have taught me to think of this as \"an array of bytes\". My input space is confined by the height and width of my image and my output space is limited by the precision of the image. Let's consider a super simple camera that only samples a 4x4 region and has only a 4 temperature resolution.   Trivial thermal camera as map      The key feature that strikes me about this image is that despite this map being non-invertable we still must have a 1-1 correspondance between points in with the \"arrows\" of the map. If we were able to \"step out\" of the map and look at it from a higher dimensional space we could think about the map as a collection of points with 3 component properties defined by some maps which describe the position and temperature .  It's incredible unlikely that our temperature alone is going to have an inverse map because neighboring points are likely to have similar temperatures. However, if we have two objects which match for the whole map-triple  such that , , and  that would necessarily imply that they're the same object .  By looking at my \"camera\" in the higher dimensional space I can think of it as an \"endomap\". There's only one detail which needs to be worked out, and that's the fact that my original map had 16 arrows to go with each of the \"dots\", we've now added in the 4 additional dots from our temperature space . For us to have a well-defined endmap, these dots would need to have arrows also. It seems natural that I'd want these new arrows to \"loop\".   Trivial thermal camera as endomap      Maybe it's not so much a question of if these arrows \"should\" loop because the properties of our category imply they \"must\" loop. The fact that any must preserve source and target for our bipointed object can be expressed as the equations and as per the the following commutative diagram.   Commutative diagram of source and target preservation      Our \"bipointed object\" contains 3 arrows, which I'll call , and 3 dots, which I'll call . Let's further specify that sources of our arrows are given by and , while the destinations are and .   Labeled bipointed object      What strikes me as special about our bipointed object here is that it provides a one-to-one correspondence between \"dots\" and \"arrows\". We know we can't have a retraction from to because there's no retraction from a 2-point space to a 1-point space, but we can start building a common section. Let's call this map and define it such that . The existence of this common section establishes that we have a reflexive graph . In Exercise 16, we proved that in a reflexive graph is both determined by and implies that there's an arrow forming a \"self-loop\" at each point.  Conceptually this makes sense for finite sets. If I know I have at least one arrow at each point, then I should be able to follow them. If I have some set of arrows and some set of dots describing a map , then there can't be more dots in the image of than there were arrows in the source space.  There's precisely one possible endomap on the space and that's the identity map. In order for some to preserve the structure of this endomap, we'd necessarily need to have . As a result of our category's structure preservation, it follows that which our result in Exercise 25 showed to imply that maps every arrow in to a loop in .  At this point I feel like I'm starting to talk myself in circles, so I'll take that a clue to move on to the next Session and hope that it helps clear up some of the details. I feel like I can at least see how the the preceeding Exercises were leading up to this problem, which gives me a bit of encouragement moving forward.    "
},
{
  "id": "article3-p5-3",
  "level": "2",
  "url": "article3-p5.html#article3-p5-3",
  "type": "Example",
  "number": "4.5.1",
  "title": "Exercise 30:.",
  "body": " Exercise 30:   If is a given bipointed object...    There's a lot to unpack here. Let's start with the \"bipointed object\" in a category :   Definition of bipointed object.      Our goal is to demonstrate that \"the graph of ' fields' on is actually a reflexive graph\". Before I get there, I think I want to try to break down the \"tempature field\" situation to get my bearings.  My conventual notion of a \"tempature field\" would be like a map from some 3D-space such as describing the position to a 1D-line such as describing the temperature at each point in Kelvins. Or at least that's the basic idea that I'm trying to generalize. Maybe my space is the 2D image of a camera and my temperature line is an interval of temperatures it can detect.  I think this notion of a \"heat map\" produced by a digital camera is my best lead to go on. Years of programming have taught me to think of this as \"an array of bytes\". My input space is confined by the height and width of my image and my output space is limited by the precision of the image. Let's consider a super simple camera that only samples a 4x4 region and has only a 4 temperature resolution.   Trivial thermal camera as map      The key feature that strikes me about this image is that despite this map being non-invertable we still must have a 1-1 correspondance between points in with the \"arrows\" of the map. If we were able to \"step out\" of the map and look at it from a higher dimensional space we could think about the map as a collection of points with 3 component properties defined by some maps which describe the position and temperature .  It's incredible unlikely that our temperature alone is going to have an inverse map because neighboring points are likely to have similar temperatures. However, if we have two objects which match for the whole map-triple  such that , , and  that would necessarily imply that they're the same object .  By looking at my \"camera\" in the higher dimensional space I can think of it as an \"endomap\". There's only one detail which needs to be worked out, and that's the fact that my original map had 16 arrows to go with each of the \"dots\", we've now added in the 4 additional dots from our temperature space . For us to have a well-defined endmap, these dots would need to have arrows also. It seems natural that I'd want these new arrows to \"loop\".   Trivial thermal camera as endomap      Maybe it's not so much a question of if these arrows \"should\" loop because the properties of our category imply they \"must\" loop. The fact that any must preserve source and target for our bipointed object can be expressed as the equations and as per the the following commutative diagram.   Commutative diagram of source and target preservation      Our \"bipointed object\" contains 3 arrows, which I'll call , and 3 dots, which I'll call . Let's further specify that sources of our arrows are given by and , while the destinations are and .   Labeled bipointed object      What strikes me as special about our bipointed object here is that it provides a one-to-one correspondence between \"dots\" and \"arrows\". We know we can't have a retraction from to because there's no retraction from a 2-point space to a 1-point space, but we can start building a common section. Let's call this map and define it such that . The existence of this common section establishes that we have a reflexive graph . In Exercise 16, we proved that in a reflexive graph is both determined by and implies that there's an arrow forming a \"self-loop\" at each point.  Conceptually this makes sense for finite sets. If I know I have at least one arrow at each point, then I should be able to follow them. If I have some set of arrows and some set of dots describing a map , then there can't be more dots in the image of than there were arrows in the source space.  There's precisely one possible endomap on the space and that's the identity map. In order for some to preserve the structure of this endomap, we'd necessarily need to have . As a result of our category's structure preservation, it follows that which our result in Exercise 25 showed to imply that maps every arrow in to a loop in .  At this point I feel like I'm starting to talk myself in circles, so I'll take that a clue to move on to the next Session and hope that it helps clear up some of the details. I feel like I can at least see how the the preceeding Exercises were leading up to this problem, which gives me a bit of encouragement moving forward.   "
},
{
  "id": "session11",
  "level": "1",
  "url": "session11.html",
  "type": "Section",
  "number": "4.6",
  "title": "Session 11: Ascending to categories of richer structures",
  "body": " Session 11: Ascending to categories of richer structures  I've finally reached the point marked by my old bookmark! I can kind of see why I got stuck here before and I'm defininately finding it convenient to have all my solutions to the previous exercises nicely organized. I find myself referring back to earlier problems to use as steps increasingly often.  In particular, I found myself seeing a lot of connections between this Sesssion and Sessions 9 and 10. I think I'm still a little uncertain about how to use the split idempotent result and it's relation to the fixed point theorem. While I made it through the section, I get this sneaking suspicion that I'm overlooking a more obvious solution to Exercise 8.  I also had this idea about \"counting arrows in and out\" that seemed extremely helpful this week but also very informal. I wonder if there's a way to formalize that approach a little better to determine whether or not graphs are isomorphic.   Exercise 1:   How many maps...    Let's start by replicating our diagram.   Provided diagram for Session 11 Exercise 1      It's clear from the diagram that the loop of 3 points in the source on could be matched up with a similar loop of 3 in the destination.   Matched up loops shown in dashed arrows      If we include any of the points outside the loop or attempt to alter the order the resulting map would fail to preserve the structure of our endomap. That means there are a total of 3 possible maps, each being a permutation of the loop.   [EDIT: I now know this solution to be incorrect. See Session 25 Part 3 for details.]      Exercise 2:   Find an isomorphism...    I think there's a typo in the diagram here and it should really say instead of as so:   Given diagram for Session 11 Exercise 2      As in Exercise 1, I think we have exactly 3 isomorphisms here. If we choose a point of origin (say ) and a target point (say ) then the remaining assignments are determined by our endomaps. Once we assign some to some , we're forced to map to and to .  Since we're mapping each point in to a unique point in our map is \"1-1\". Since every value in is covered by some input in our map is \"onto\". Being both, it would be an isomorphism. All that remains it to show it preserves the structure of .  Knowing that is invertable, we can apply to the left and right of . This gives us which can be simplified to which demonstrates that is a valid -map.     Exercise 3:   Prove that there is no isomorphism...    We're given the following structures of domain and codomain:   Given diagram for Session 11 Exercise 3      Suppose we did have some isomorphism preserving the relation . We provided in the previous exercise that the inverse must also preserve structure, namely that satisfies . I felt it was helpful to view the relations as an external diagram:   External diagram of endomaps in Session 11 Exercise 3      If our isomorphism existed, the structure preserving equations provide alternative representations of the endomaps and . Apply to both sides of from both sides. On the left we get and the right we get . However, there's a problem with this. The map is idempotent with while the map is an automorphism with .  Since we can express in terms of using , then we can also express as . The associative property allows us to regroup these terms as . Using the identity property this simplifies to , but since we can further simplify to . However, this is a contradiction to our observation eariler that . It follows that our assumption about the existence of is false and no such map exists.  I think the key here is that an isomorphism between endomaps must preserve the number of paths into and out of each point. Consider the following labeled diagram with the number of arrows in and out at each point:   Labeled version of diagram for Session 11 Exercise 3      Note that is invertable so it needs to have precisely one arrow in and one arrow at each point. The map is clearly not invertable. There is no arrow leading into so it's not \"onto\" and the two leading into implies it's also not one-to-one. Consider the table of values:   Table of values for and                                        Note that our might vary depending on how we choose our map , but there are 4 distict values in the column for and only 3 distinct values in the column for . Even if were allowed to be non-invertable, there will never be any map that could possibly makes those two columns equal.     Exercise 4:   ... Show is automatically a map in .    I think I actually used this as part of my solution to Exercise 2. We're given in and know that \"as sets\" . We can take the structure preserving property of to establish , then apply before and after to get . Use the identity property to get which establishes as a valid -map.     Exercise 5:   ... Is ismorphic to ?...    We're given in and in . We want to find out if there's an isomorphism .  In order for this to preserve structure, we'd need . This is equivalent to saying that . Expanding our definitions of gives us .  I'm going to claim the map has this desired property. Making this substitution to both sides of our previous experession gives us and . Since both sides are equivalent, this preserves structure.  To establish that is invertable, we can define . Since and it follows that this is a valid inverse for . As in the previous exercise, it follows that applying on the left and right of gives us which establishes structure preservation for .  Having shown that the inverse exists and preserves structure I think we're done here.     Exercise 6:   Each of the following graphs is isomorphic...    I think there's an obvious solution that matches the top row with the bottom row from left to right. To verify this, I'm going to label the \"in\" and \"out\" counts at each point like I did in Exercise 3:   Labeled version of diagram for Session 11 Exercise 6      It's pretty clear that this is the only possible pairing of points that keeps the number of arrows in and out the same. Thus, our graph pairs are (a) with (d), (b) with (e) and (c) with (f).     Exercise 7:   If these two graphs are isomorphic...    My strategy of labeling counts of arrows in and out seems to be working well so far, so I'll apply it here also:   Labeled diagram for Session 11 Exercise 7      Labeling my counts in this way makes it clear that this diagram has been flipped vertically and shuffled arround a bit. Any isomorphism will need to map to and to to preserve the in\/out arrow counts at each point.  The remaining 3 points all have 1 arrow in and 1 arrow out. However, the left diagram has 2 paths leading up and 1 leading down while the right diagram has 2 paths leading down and 1 leading up. Knowing that we've flipped the diagram vertically, we'd need to match the path down in the left diagram with the path up it the right diagram pairing point with . The remaining two points from each figure can be matched up either way without altering the structure.  It follows that there are precisely 2 isomorphisms from to . Both maps necessirly have , , and . Where they differ is how they handle and : and while and .     Exercise 8:   (Impossible journeys) ...    We're given any graph with two dots , and the graph as diagrammed below:   Graph for Session 11 Exercise 8      For (a), we're given a map of graphs with and . We want to show that there is no path in G that begins at and ends at .  Since produces both points in it must be surjective, having a section such that . This map is determined by and . We can then use this map to build an endomap by composing and in the reverse order: . Note that and so has at least two fixed points. Further note that is idempotent since .  Suppose there was such a path from to in . We could think of this path as another \"endomap\" on some subset of the dots on our graph forming our \"path\". We can identify some with the propery that each application of map takes us one step along that path from to until we arrive and stay there. In otherwords, we have a sequence of points where is the number of nodes we traverse. We can also use this to define a reverse path by swapping the source and target of each arrow to produce an inverse map that traverses these points in the opposite order: . However, note that the arrows of might not necessarily exist in the original graph .  Consider what happens when we apply to these points in the path. For to preserve structure, we need to have . But since , we have which implies for all points in our path. In otherwords, any point accessible from must get mapped to .  I imagine this process to be something like \"coloring the graph\". We can start at point and paint it \"blue\", then follow each arrow leading out of and paint those points \"blue\" as well. At the same time, we can start at point and paint it \"red\" but this time we take the arrows with a target of and paint the point at the source \"red\". If we repeating the process as many times as we're able we'll eventually get a \"purple\" point or arrow if the paths do in fact connect.  To get a feel for this, let's try it with the example graph on the same page:   Sample graph to illustrate path coloring      Coloring the figure like this is a lot of work, but having done so makes it clear that there is no possible path between and in this diagram. The dashed arrows show edges that were neither transversed forward from nor backwards from . Both of these paths formed closed loops. We're unable to connect the two loops without an arrow with a red source and blue destination.  Consider the commutative diagram of our endomap on the subset of points forming our path . Since must preserve structure, we want for any endomap .   Commutative diagram of endomaps determined by      In this situation, there are only two possible endomaps that can exist using the arrows and dots from . Our map can either be the identity map or the standard idempotented with for any . Knowing that , consider what happens in each situation. If then implies which contradicts our assumption that . If , then implies for all which contradicts .  I see a lot of similarity here with the Brouwer's Theorems indroduced earlier. Essentially, by thinking of the path as an endomap we need to have a \"fixed point\" or we can't have a \"retraction at the boundary\".  For (b) we need to prove the converse. Suppose we have some path from to in . If we think of that path as an endomap as described above, then that endomap must have a fixed point *somewhere*. That point obviously can't be because contradicts our notion of a path. Likewise, it couldn't fix any along the path either, so the only reasonable fixed point would be . As before, would need to preserve the structure of both possible endomaps on . If then implies which contradicts . If , then that contradicts our condition that since but .  In other words, the existence of an intermediate point in this path prevents us from having a retraction at the boundary because we know there's we can't possibly have retraction to a map from a 3-point space to a two point space. It follows that the endomap describing our path must have a fixed point, but we can't have a fixed point in the path or we'll never reach our destination.    "
},
{
  "id": "session11-5",
  "level": "2",
  "url": "session11.html#session11-5",
  "type": "Example",
  "number": "4.6.1",
  "title": "Exercise 1:.",
  "body": " Exercise 1:   How many maps...    Let's start by replicating our diagram.   Provided diagram for Session 11 Exercise 1      It's clear from the diagram that the loop of 3 points in the source on could be matched up with a similar loop of 3 in the destination.   Matched up loops shown in dashed arrows      If we include any of the points outside the loop or attempt to alter the order the resulting map would fail to preserve the structure of our endomap. That means there are a total of 3 possible maps, each being a permutation of the loop.   [EDIT: I now know this solution to be incorrect. See Session 25 Part 3 for details.]    "
},
{
  "id": "session11-6",
  "level": "2",
  "url": "session11.html#session11-6",
  "type": "Example",
  "number": "4.6.4",
  "title": "Exercise 2:.",
  "body": " Exercise 2:   Find an isomorphism...    I think there's a typo in the diagram here and it should really say instead of as so:   Given diagram for Session 11 Exercise 2      As in Exercise 1, I think we have exactly 3 isomorphisms here. If we choose a point of origin (say ) and a target point (say ) then the remaining assignments are determined by our endomaps. Once we assign some to some , we're forced to map to and to .  Since we're mapping each point in to a unique point in our map is \"1-1\". Since every value in is covered by some input in our map is \"onto\". Being both, it would be an isomorphism. All that remains it to show it preserves the structure of .  Knowing that is invertable, we can apply to the left and right of . This gives us which can be simplified to which demonstrates that is a valid -map.   "
},
{
  "id": "session11-7",
  "level": "2",
  "url": "session11.html#session11-7",
  "type": "Example",
  "number": "4.6.6",
  "title": "Exercise 3:.",
  "body": " Exercise 3:   Prove that there is no isomorphism...    We're given the following structures of domain and codomain:   Given diagram for Session 11 Exercise 3      Suppose we did have some isomorphism preserving the relation . We provided in the previous exercise that the inverse must also preserve structure, namely that satisfies . I felt it was helpful to view the relations as an external diagram:   External diagram of endomaps in Session 11 Exercise 3      If our isomorphism existed, the structure preserving equations provide alternative representations of the endomaps and . Apply to both sides of from both sides. On the left we get and the right we get . However, there's a problem with this. The map is idempotent with while the map is an automorphism with .  Since we can express in terms of using , then we can also express as . The associative property allows us to regroup these terms as . Using the identity property this simplifies to , but since we can further simplify to . However, this is a contradiction to our observation eariler that . It follows that our assumption about the existence of is false and no such map exists.  I think the key here is that an isomorphism between endomaps must preserve the number of paths into and out of each point. Consider the following labeled diagram with the number of arrows in and out at each point:   Labeled version of diagram for Session 11 Exercise 3      Note that is invertable so it needs to have precisely one arrow in and one arrow at each point. The map is clearly not invertable. There is no arrow leading into so it's not \"onto\" and the two leading into implies it's also not one-to-one. Consider the table of values:   Table of values for and                                        Note that our might vary depending on how we choose our map , but there are 4 distict values in the column for and only 3 distinct values in the column for . Even if were allowed to be non-invertable, there will never be any map that could possibly makes those two columns equal.   "
},
{
  "id": "session11-8",
  "level": "2",
  "url": "session11.html#session11-8",
  "type": "Example",
  "number": "4.6.11",
  "title": "Exercise 4:.",
  "body": " Exercise 4:   ... Show is automatically a map in .    I think I actually used this as part of my solution to Exercise 2. We're given in and know that \"as sets\" . We can take the structure preserving property of to establish , then apply before and after to get . Use the identity property to get which establishes as a valid -map.   "
},
{
  "id": "session11-9",
  "level": "2",
  "url": "session11.html#session11-9",
  "type": "Example",
  "number": "4.6.12",
  "title": "Exercise 5:.",
  "body": " Exercise 5:   ... Is ismorphic to ?...    We're given in and in . We want to find out if there's an isomorphism .  In order for this to preserve structure, we'd need . This is equivalent to saying that . Expanding our definitions of gives us .  I'm going to claim the map has this desired property. Making this substitution to both sides of our previous experession gives us and . Since both sides are equivalent, this preserves structure.  To establish that is invertable, we can define . Since and it follows that this is a valid inverse for . As in the previous exercise, it follows that applying on the left and right of gives us which establishes structure preservation for .  Having shown that the inverse exists and preserves structure I think we're done here.   "
},
{
  "id": "session11-10",
  "level": "2",
  "url": "session11.html#session11-10",
  "type": "Example",
  "number": "4.6.13",
  "title": "Exercise 6:.",
  "body": " Exercise 6:   Each of the following graphs is isomorphic...    I think there's an obvious solution that matches the top row with the bottom row from left to right. To verify this, I'm going to label the \"in\" and \"out\" counts at each point like I did in Exercise 3:   Labeled version of diagram for Session 11 Exercise 6      It's pretty clear that this is the only possible pairing of points that keeps the number of arrows in and out the same. Thus, our graph pairs are (a) with (d), (b) with (e) and (c) with (f).   "
},
{
  "id": "session11-11",
  "level": "2",
  "url": "session11.html#session11-11",
  "type": "Example",
  "number": "4.6.15",
  "title": "Exercise 7:.",
  "body": " Exercise 7:   If these two graphs are isomorphic...    My strategy of labeling counts of arrows in and out seems to be working well so far, so I'll apply it here also:   Labeled diagram for Session 11 Exercise 7      Labeling my counts in this way makes it clear that this diagram has been flipped vertically and shuffled arround a bit. Any isomorphism will need to map to and to to preserve the in\/out arrow counts at each point.  The remaining 3 points all have 1 arrow in and 1 arrow out. However, the left diagram has 2 paths leading up and 1 leading down while the right diagram has 2 paths leading down and 1 leading up. Knowing that we've flipped the diagram vertically, we'd need to match the path down in the left diagram with the path up it the right diagram pairing point with . The remaining two points from each figure can be matched up either way without altering the structure.  It follows that there are precisely 2 isomorphisms from to . Both maps necessirly have , , and . Where they differ is how they handle and : and while and .   "
},
{
  "id": "session11-12",
  "level": "2",
  "url": "session11.html#session11-12",
  "type": "Example",
  "number": "4.6.17",
  "title": "Exercise 8:.",
  "body": " Exercise 8:   (Impossible journeys) ...    We're given any graph with two dots , and the graph as diagrammed below:   Graph for Session 11 Exercise 8      For (a), we're given a map of graphs with and . We want to show that there is no path in G that begins at and ends at .  Since produces both points in it must be surjective, having a section such that . This map is determined by and . We can then use this map to build an endomap by composing and in the reverse order: . Note that and so has at least two fixed points. Further note that is idempotent since .  Suppose there was such a path from to in . We could think of this path as another \"endomap\" on some subset of the dots on our graph forming our \"path\". We can identify some with the propery that each application of map takes us one step along that path from to until we arrive and stay there. In otherwords, we have a sequence of points where is the number of nodes we traverse. We can also use this to define a reverse path by swapping the source and target of each arrow to produce an inverse map that traverses these points in the opposite order: . However, note that the arrows of might not necessarily exist in the original graph .  Consider what happens when we apply to these points in the path. For to preserve structure, we need to have . But since , we have which implies for all points in our path. In otherwords, any point accessible from must get mapped to .  I imagine this process to be something like \"coloring the graph\". We can start at point and paint it \"blue\", then follow each arrow leading out of and paint those points \"blue\" as well. At the same time, we can start at point and paint it \"red\" but this time we take the arrows with a target of and paint the point at the source \"red\". If we repeating the process as many times as we're able we'll eventually get a \"purple\" point or arrow if the paths do in fact connect.  To get a feel for this, let's try it with the example graph on the same page:   Sample graph to illustrate path coloring      Coloring the figure like this is a lot of work, but having done so makes it clear that there is no possible path between and in this diagram. The dashed arrows show edges that were neither transversed forward from nor backwards from . Both of these paths formed closed loops. We're unable to connect the two loops without an arrow with a red source and blue destination.  Consider the commutative diagram of our endomap on the subset of points forming our path . Since must preserve structure, we want for any endomap .   Commutative diagram of endomaps determined by      In this situation, there are only two possible endomaps that can exist using the arrows and dots from . Our map can either be the identity map or the standard idempotented with for any . Knowing that , consider what happens in each situation. If then implies which contradicts our assumption that . If , then implies for all which contradicts .  I see a lot of similarity here with the Brouwer's Theorems indroduced earlier. Essentially, by thinking of the path as an endomap we need to have a \"fixed point\" or we can't have a \"retraction at the boundary\".  For (b) we need to prove the converse. Suppose we have some path from to in . If we think of that path as an endomap as described above, then that endomap must have a fixed point *somewhere*. That point obviously can't be because contradicts our notion of a path. Likewise, it couldn't fix any along the path either, so the only reasonable fixed point would be . As before, would need to preserve the structure of both possible endomaps on . If then implies which contradicts . If , then that contradicts our condition that since but .  In other words, the existence of an intermediate point in this path prevents us from having a retraction at the boundary because we know there's we can't possibly have retraction to a map from a 3-point space to a two point space. It follows that the endomap describing our path must have a fixed point, but we can't have a fixed point in the path or we'll never reach our destination.   "
},
{
  "id": "session12",
  "level": "1",
  "url": "session12.html",
  "type": "Section",
  "number": "4.7",
  "title": "Session 12: Categories of Diagrams",
  "body": " Session 12: Categories of Diagrams  I thought that the Session following my bookmark was going to be difficult, but this was actually a relatively easy reading this week. I'm enjoying the sessions written in this style where the association between the abstract representations and the practical uses are laid out in an imaginary classroom. It makes me feel like I'm a part of collective effort to understand this.   Exercise 1:   Suppose that ...    We're given that is a map in , which tells us that . If we know that we have some , we could sketch the external diagram as follows:   Commutative diagram of over      Knowing that and for some , we can establish that through the associative property:       Thus, .     Exercise 2:   'With age comes stability'...    Rather than just replicating the entire diagram here, I'll just focus on the relevant \"clusters\". Let's start with the set of points connected to . The pre-periodic behavior will be dashed while the periodic behavior solid black. Grey will denote paths not taken.   Observed behavior of      This endomap takes one step after then becomes periodic with a cycle length of 3 steps.  Next, let's isolate .   Observed behavior of      Beginning at point , we take 3 steps before reaching a fixed point.  Finally, let's sketch the hypthotical enodmap of a light switch that could only be lit four times.  I'm going to suggest that the first state be called . The first time we flip the switch, we'd get . Then we alternate between \"off\" and \"on\", until we have a set of 4 \"on\" states: . Following that final on, we reach a terminal state that is perpetually \"off\". Putting the whole thing together might look something like this:   Observed behavior of      The only thing that strikes me as being tricky about this was that my \"off\" and \"on\" states had to be different for each time the light was switched. Even though looking at the light buld you'd only see whether the light was on or off, there needs to be an internal state to the light bulb that tracks how many times it's been used.     Exercise 3:   ...Suppose ...    In part (a) our task is to \"[s]how that 'gender' is a map in the category from to the object [defined as below]\":   Object for Session 12 Exercise 3      Here the maps and are meant to represent \"father\" and \"mother\" relationships. Obviously \"real gender\" is more complex than this, but we'll roll with it.  We'll start by identifying our checklist for the category:    A category has objects .    A category has maps .    For each map, there is one object representing the domain and one object representing the codomain .    For any pair of maps we can form a composite map .    The category upholds the identity laws . If , then and .    The category upholds the associative law : if then .    Well, we have some objects. These include the people and properties we're looking at. We also have some maps that relate our people and and properties with each other. We're particularly concerned with a 'gender' map I'll call which takes a person and returns a gender.  We also have objects representing the domain and codomain of our map . The domain is the set of all people and the codomain is the set of genders . We'll also have two identity maps and which can satisfy .  For us to define a composition of maps, let's first identify the structures we want to preserve. Our \"people space\" came equipped with two endomaps and that take a person and return the person's \"mother\" or \"father\" respectively.  This object does something interesting here by defining it's own version of those endomaps . These maps operate on genders rather than people , but defining them this way allows us to preserve the structure. Perhaps it might be clearer if denote them separately. Let's call the endomaps on people and the endomaps on genders. We could compose maps to form the following commutative diagram:   Commutative diagram for      In order to maintain our structure, we'd want to have both and . Fortunately, and are basically constants in . For any given person (in this model), we could potentially have or , but if we compose with our endomaps we get fixed points. For any person , we can expect that their mother is female (both and ) and father is male (both and ).  I'm thinking that central idea of part (a) is to define a map in as a map satisfying the pair of equations and .  Given some other map in , with we'd need to show that our composition is also a valid -map. This should follow directly from the associative property and our structure preserving equations:    The last thing we need to verify is the associative property. Given a third map in , with , we want to show . I'm pretty sure we get this for free as being objects in the category of sets.  For part (b), we expand our structure with a \"clan\" object defined as follows:   Object for Session 12 Exercise 3      Like before, we'd want our structure to be preserved. Given a map , we'd want to enforce the conditions that and .  Since \"a child's clan is the same as that of [their] mother\", it follows that for any person we'd have . As a result, our condition that is satisfied by making .  Since \"[m]arriages within clans are forbidden\", it follows that for any person we'd have . However, we already know so it follows that . Since there's only two elements in it follows that needs the antipodal map so that .  In the last part (c), we attempt to combine \"gender\" and \"clan\" to make a cartesian product: . Essentially, there are four possible combinations of clan and gender: he-wolf, she-wolf, he-bear, and she-bear. We'll examine each in turn.  For a \"he-wolf\", his mother needs to be a \"she-wolf\" and father a \"he-bear\". For a \"she-wolf\", her mother needs to be a \"she-wolf and father a \"he-bear\". For a \"he-bear\", his mother needs to be a \"she-bear\" and father a \"he-wolf\". For a \"she-bear\", her mother needs to be a \"she-bear\" and father a \"he-wolf\".  Since we assign a \"mother arrow\" and a \"father arrow\" for each point, we can draw an endomap diagram representing the relations:   Endomaps and on       To verify that this is a valid -map, we'll examine if the structure preservation properties hold.   Break down of gender-clan compositions           he-wolf  she-wolf  he-bear  she-wolf  he-bear    she-wolf  she-wolf  he-bear  she-wolf  he-bear    he-bear  she-bear  he-wolf  she-bear  he-wolf    she-bear  she-bear  he-wolf  she-bear  he-wolf     I'm not sure if there's much else I need to do here since we inherent the rest of our needed properties from .    "
},
{
  "id": "session12-3",
  "level": "2",
  "url": "session12.html#session12-3",
  "type": "Example",
  "number": "4.7.1",
  "title": "Exercise 1:.",
  "body": " Exercise 1:   Suppose that ...    We're given that is a map in , which tells us that . If we know that we have some , we could sketch the external diagram as follows:   Commutative diagram of over      Knowing that and for some , we can establish that through the associative property:       Thus, .   "
},
{
  "id": "session12-4",
  "level": "2",
  "url": "session12.html#session12-4",
  "type": "Example",
  "number": "4.7.3",
  "title": "Exercise 2:.",
  "body": " Exercise 2:   'With age comes stability'...    Rather than just replicating the entire diagram here, I'll just focus on the relevant \"clusters\". Let's start with the set of points connected to . The pre-periodic behavior will be dashed while the periodic behavior solid black. Grey will denote paths not taken.   Observed behavior of      This endomap takes one step after then becomes periodic with a cycle length of 3 steps.  Next, let's isolate .   Observed behavior of      Beginning at point , we take 3 steps before reaching a fixed point.  Finally, let's sketch the hypthotical enodmap of a light switch that could only be lit four times.  I'm going to suggest that the first state be called . The first time we flip the switch, we'd get . Then we alternate between \"off\" and \"on\", until we have a set of 4 \"on\" states: . Following that final on, we reach a terminal state that is perpetually \"off\". Putting the whole thing together might look something like this:   Observed behavior of      The only thing that strikes me as being tricky about this was that my \"off\" and \"on\" states had to be different for each time the light was switched. Even though looking at the light buld you'd only see whether the light was on or off, there needs to be an internal state to the light bulb that tracks how many times it's been used.   "
},
{
  "id": "session12-5",
  "level": "2",
  "url": "session12.html#session12-5",
  "type": "Example",
  "number": "4.7.7",
  "title": "Exercise 3:.",
  "body": " Exercise 3:   ...Suppose ...    In part (a) our task is to \"[s]how that 'gender' is a map in the category from to the object [defined as below]\":   Object for Session 12 Exercise 3      Here the maps and are meant to represent \"father\" and \"mother\" relationships. Obviously \"real gender\" is more complex than this, but we'll roll with it.  We'll start by identifying our checklist for the category:    A category has objects .    A category has maps .    For each map, there is one object representing the domain and one object representing the codomain .    For any pair of maps we can form a composite map .    The category upholds the identity laws . If , then and .    The category upholds the associative law : if then .    Well, we have some objects. These include the people and properties we're looking at. We also have some maps that relate our people and and properties with each other. We're particularly concerned with a 'gender' map I'll call which takes a person and returns a gender.  We also have objects representing the domain and codomain of our map . The domain is the set of all people and the codomain is the set of genders . We'll also have two identity maps and which can satisfy .  For us to define a composition of maps, let's first identify the structures we want to preserve. Our \"people space\" came equipped with two endomaps and that take a person and return the person's \"mother\" or \"father\" respectively.  This object does something interesting here by defining it's own version of those endomaps . These maps operate on genders rather than people , but defining them this way allows us to preserve the structure. Perhaps it might be clearer if denote them separately. Let's call the endomaps on people and the endomaps on genders. We could compose maps to form the following commutative diagram:   Commutative diagram for      In order to maintain our structure, we'd want to have both and . Fortunately, and are basically constants in . For any given person (in this model), we could potentially have or , but if we compose with our endomaps we get fixed points. For any person , we can expect that their mother is female (both and ) and father is male (both and ).  I'm thinking that central idea of part (a) is to define a map in as a map satisfying the pair of equations and .  Given some other map in , with we'd need to show that our composition is also a valid -map. This should follow directly from the associative property and our structure preserving equations:    The last thing we need to verify is the associative property. Given a third map in , with , we want to show . I'm pretty sure we get this for free as being objects in the category of sets.  For part (b), we expand our structure with a \"clan\" object defined as follows:   Object for Session 12 Exercise 3      Like before, we'd want our structure to be preserved. Given a map , we'd want to enforce the conditions that and .  Since \"a child's clan is the same as that of [their] mother\", it follows that for any person we'd have . As a result, our condition that is satisfied by making .  Since \"[m]arriages within clans are forbidden\", it follows that for any person we'd have . However, we already know so it follows that . Since there's only two elements in it follows that needs the antipodal map so that .  In the last part (c), we attempt to combine \"gender\" and \"clan\" to make a cartesian product: . Essentially, there are four possible combinations of clan and gender: he-wolf, she-wolf, he-bear, and she-bear. We'll examine each in turn.  For a \"he-wolf\", his mother needs to be a \"she-wolf\" and father a \"he-bear\". For a \"she-wolf\", her mother needs to be a \"she-wolf and father a \"he-bear\". For a \"he-bear\", his mother needs to be a \"she-bear\" and father a \"he-wolf\". For a \"she-bear\", her mother needs to be a \"she-bear\" and father a \"he-wolf\".  Since we assign a \"mother arrow\" and a \"father arrow\" for each point, we can draw an endomap diagram representing the relations:   Endomaps and on       To verify that this is a valid -map, we'll examine if the structure preservation properties hold.   Break down of gender-clan compositions           he-wolf  she-wolf  he-bear  she-wolf  he-bear    she-wolf  she-wolf  he-bear  she-wolf  he-bear    he-bear  she-bear  he-wolf  she-bear  he-wolf    she-bear  she-bear  he-wolf  she-bear  he-wolf     I'm not sure if there's much else I need to do here since we inherent the rest of our needed properties from .   "
},
{
  "id": "session13",
  "level": "1",
  "url": "session13.html",
  "type": "Section",
  "number": "4.8",
  "title": "Session 13: Monoids",
  "body": " Session 13: Monoids  I finally learned what a monoid is! I feel like a whole new collection of math memes just opened up for me. As an added bonus, there were no exercises this week! Rather than coming up with something of my own to do, I'm planning to use this opportunity to just reflect on the definitions for a week. There seemed to be some close parallels betweeen this session and Peano's axioms, but I think I'm just going to wait to see how the authors decide to develop things further.  "
},
{
  "id": "session14",
  "level": "1",
  "url": "session14.html",
  "type": "Section",
  "number": "4.9",
  "title": "Session 14: Maps preserve positive properties",
  "body": " Session 14: Maps preserve positive properties  The authors include some of these solutions in the reading, but I'm going to try to work them all out on my own. Just because.    Exercise 1:   Let and be two points of ...    Given that and , we can apply on the left of both sides to get and . Since the structure preservation property enforces , we can subsitute into our expressions to get and . If , it follows directly that .     Exercise 2:   If instead we know that ...    Like before, if can apply on the left of and to get and . We can expand the whole thing out and apply a repeated subsitution using .        Thus and . If , then .     Exercise 3:   If ...    Knowing , just apply on the left of both sides to get . It follows that is also a 'fixed point'.     Exercise 4:   Give an example in which...    Since we're given a \"hint\" let's use it. Consider and . Our only possible map has the following diagram:   Only possible map      Here the point has the desired properties. Since , is not a fixed point in . However, and is a fixed point of . These fixed points are a \"one-way\" relationship. Since is fixed in then must be fixed in , but just because is fixed in doesn't mean is fixed in .     Exercise 5:   Show that if ...    Based on what we've seen so far, I'm thinking that these properties might be satisfied by the following map :   Map from a 4-cycle to a 2-cycle      Essentially, I'm taking the 4-cycle and splitting it in half. Perhaps the best way to illustrate that we get the desired properties is with a table:   Validation table for Session 14 Exercise 5                                        Since the last columns are equal, we know this is a valid -map. For each point in , . For each point in , . However, implies that .  I can imagine that this leads into some divisibility rules for cycles. I was only able to shrink the cycle here because 4 is evenly divisible by 2. If two cycles are relatively prime in lengths, the only cycle we'd be able to map them to (and still preserve our structure) is a \"fixed point\".    "
},
{
  "id": "session14-3",
  "level": "2",
  "url": "session14.html#session14-3",
  "type": "Example",
  "number": "4.9.1",
  "title": "Exercise 1:.",
  "body": " Exercise 1:   Let and be two points of ...    Given that and , we can apply on the left of both sides to get and . Since the structure preservation property enforces , we can subsitute into our expressions to get and . If , it follows directly that .   "
},
{
  "id": "session14-4",
  "level": "2",
  "url": "session14.html#session14-4",
  "type": "Example",
  "number": "4.9.2",
  "title": "Exercise 2:.",
  "body": " Exercise 2:   If instead we know that ...    Like before, if can apply on the left of and to get and . We can expand the whole thing out and apply a repeated subsitution using .        Thus and . If , then .   "
},
{
  "id": "session14-5",
  "level": "2",
  "url": "session14.html#session14-5",
  "type": "Example",
  "number": "4.9.3",
  "title": "Exercise 3:.",
  "body": " Exercise 3:   If ...    Knowing , just apply on the left of both sides to get . It follows that is also a 'fixed point'.   "
},
{
  "id": "session14-6",
  "level": "2",
  "url": "session14.html#session14-6",
  "type": "Example",
  "number": "4.9.4",
  "title": "Exercise 4:.",
  "body": " Exercise 4:   Give an example in which...    Since we're given a \"hint\" let's use it. Consider and . Our only possible map has the following diagram:   Only possible map      Here the point has the desired properties. Since , is not a fixed point in . However, and is a fixed point of . These fixed points are a \"one-way\" relationship. Since is fixed in then must be fixed in , but just because is fixed in doesn't mean is fixed in .   "
},
{
  "id": "session14-7",
  "level": "2",
  "url": "session14.html#session14-7",
  "type": "Example",
  "number": "4.9.6",
  "title": "Exercise 5:.",
  "body": " Exercise 5:   Show that if ...    Based on what we've seen so far, I'm thinking that these properties might be satisfied by the following map :   Map from a 4-cycle to a 2-cycle      Essentially, I'm taking the 4-cycle and splitting it in half. Perhaps the best way to illustrate that we get the desired properties is with a table:   Validation table for Session 14 Exercise 5                                        Since the last columns are equal, we know this is a valid -map. For each point in , . For each point in , . However, implies that .  I can imagine that this leads into some divisibility rules for cycles. I was only able to shrink the cycle here because 4 is evenly divisible by 2. If two cycles are relatively prime in lengths, the only cycle we'd be able to map them to (and still preserve our structure) is a \"fixed point\".   "
},
{
  "id": "session15",
  "level": "1",
  "url": "session15.html",
  "type": "Section",
  "number": "4.10",
  "title": "Session 15: Objectification of Properties",
  "body": " Session 15: Objectification of Properties  This week was an interesting development. Up until this point we've only been using numbers as a playground for exploring ideas. Now that monoids have allowed us to build a formalization of natural numbers in the category of endomaps, we've opened up a whole new means of analyzing maps.  My prediction about cycle lenths and divisibility was spot on. It was nice to have confirmation that I'm on the right track. I also found the definition of was rather intriguing. I can see this having applications to things like \"floating point\" numbers where treating infinity as a number has advantages. In fact, a lot of idea from throughout the text seem to be coming together. Slowly .   Exercise 1:   ...both period 5 and period 7...    Suppose we have some element with . Our associative property implies . However, is just so it follows that . And if that's the case, then we can also represent as either or .  In the former case, implies . In the latter, implies . Since both are equivalent to , we have established that which proves is a fixed point.     Exercise 2:   ...all maps from to ...    In order to preserve structure, the arrows need to flow in the same direction. Any map that preserve the structure of the loop. That is, whatever point we decide to send to in the cycle determines where we need to send . Once we hit we need to loop back to .  These 4 possible permutations are diagrammed below:   All maps from to         Exercise 3:   ... evaluation at 0 and iteration ...    I'm not exactly what this exercise is asking, so let's start by laying out the context.   Iteration and evaluation defined      We're told that \"'Iteration' assigns to each in the map given by \".  I think my confusion here is stemming from a little uncertainty about the domain and codomain of . The diagram I recreated above suggests that is a map , but part of me thinks I should treat as an abitrary map in the context of a broader category of . Part of me is wondering if our definition of as a monoid circumvents this question entirely by defining as an element of with the desired property in : a point that is the origin of an arrow but not a target.  In some of the earlier Sessions, I found it helpful to think about the \"image\" produced by a given map. Once we have a point we can ask whether or not produces a fixed point. This is a binary question for which the answer either needs to be \"true\" or \"false\". Let's call this space with the conventions if and if . Let's define this map as .  Obviously such map exists between sets, but the real question is whether or not  preserves structure within our category. There are precisely 4 possible endomaps on we could possibly have: an identity map, an antipodal map, and two idempotents resulting in respectively. This allows us to ask further questions, like if is has a retraction . Of the four possible endomaps on , only the identity map and the antipodal map would even qualify because we know there's no possible retraction from .  This is all still really fuzzy and I feel like I'm missing something, so I think I'm going to let this information stew for another week and come back to it..    "
},
{
  "id": "session15-4",
  "level": "2",
  "url": "session15.html#session15-4",
  "type": "Example",
  "number": "4.10.1",
  "title": "Exercise 1:.",
  "body": " Exercise 1:   ...both period 5 and period 7...    Suppose we have some element with . Our associative property implies . However, is just so it follows that . And if that's the case, then we can also represent as either or .  In the former case, implies . In the latter, implies . Since both are equivalent to , we have established that which proves is a fixed point.   "
},
{
  "id": "session15-5",
  "level": "2",
  "url": "session15.html#session15-5",
  "type": "Example",
  "number": "4.10.2",
  "title": "Exercise 2:.",
  "body": " Exercise 2:   ...all maps from to ...    In order to preserve structure, the arrows need to flow in the same direction. Any map that preserve the structure of the loop. That is, whatever point we decide to send to in the cycle determines where we need to send . Once we hit we need to loop back to .  These 4 possible permutations are diagrammed below:   All maps from to       "
},
{
  "id": "session15-6",
  "level": "2",
  "url": "session15.html#session15-6",
  "type": "Example",
  "number": "4.10.4",
  "title": "Exercise 3:.",
  "body": " Exercise 3:   ... evaluation at 0 and iteration ...    I'm not exactly what this exercise is asking, so let's start by laying out the context.   Iteration and evaluation defined      We're told that \"'Iteration' assigns to each in the map given by \".  I think my confusion here is stemming from a little uncertainty about the domain and codomain of . The diagram I recreated above suggests that is a map , but part of me thinks I should treat as an abitrary map in the context of a broader category of . Part of me is wondering if our definition of as a monoid circumvents this question entirely by defining as an element of with the desired property in : a point that is the origin of an arrow but not a target.  In some of the earlier Sessions, I found it helpful to think about the \"image\" produced by a given map. Once we have a point we can ask whether or not produces a fixed point. This is a binary question for which the answer either needs to be \"true\" or \"false\". Let's call this space with the conventions if and if . Let's define this map as .  Obviously such map exists between sets, but the real question is whether or not  preserves structure within our category. There are precisely 4 possible endomaps on we could possibly have: an identity map, an antipodal map, and two idempotents resulting in respectively. This allows us to ask further questions, like if is has a retraction . Of the four possible endomaps on , only the identity map and the antipodal map would even qualify because we know there's no possible retraction from .  This is all still really fuzzy and I feel like I'm missing something, so I think I'm going to let this information stew for another week and come back to it..   "
},
{
  "id": "session15-p2",
  "level": "1",
  "url": "session15-p2.html",
  "type": "Section",
  "number": "4.11",
  "title": "Session 15: Objectification of Properties, Part 2",
  "body": " Session 15: Objectification of Properties, Part 2  Okay, I spent a lot more time on Exercise 3 over the past week, but I think I'm starting to understand a little better. If I manage to make it through this problem this week, I'll take that as a win!   Exercise 3: (continued)   ... evaluation at 0 and iteration ...    I want to start this time by stepping back and look and assign some new names to the entities from the diagram I recreated last time.   Naming objects in \"Iteration and evaluation defined\"      My reasoning here is that labeling my objects like this will make it a little more clear on what exactly it would mean for our maps to be inverses. Given the naming used above, I'd need to prove and . What makes this tricky is that the objects in are -maps that preserve the structure from and the objects in are maps in from that don't necessarily preserve any structure.  Perhaps what I should be doing is thinking of the maps as a collection of arrows. Each arrow needs to have a source point in and a target point in . For to preserve structure, we'd need to have for every in .  Our map , basically takes advantage of the fact that any map in must be defined over the whole domain. This means that there must be an arrow originating at the point pointing to some target point in . We can then define such that for any we can define to be the map in which maps the only element in to the point in .  In contrast, our map takes a map and uses it to produce a map in . It does this by applying to zero or more times, such that for any . In the case where , the map is never applied at all. It follows that for any in , we're guaranteed to have .  These two maps both produce maps, but handle structure differently. The map takes a map which preserves the structure and uses it to produce a map which might not. The map takes a map which may not preserve structure and produces one that does. The identity basically establishes that in , but I think we still need to establish that the map is valid in .  For any given , the map needs to satisfy for every . At , and . Since holds true for , we can use induction to establish that they must be the same for every 'successor'.  Since each can be represented as , we can use that to make a subsitution. If follows that and . It also follows that and . Since we know that , we can combine these two results to establish that . Having established that and , follows by induction.  Next, let's compose these maps in the reverse order to produce the map . Suppose we have some in . It follows from our definitions that that which would imply that . Having now established that both and , it's safe to refer to these two maps as inverses.  Q.E.D.    "
},
{
  "id": "session15-p2-3",
  "level": "2",
  "url": "session15-p2.html#session15-p2-3",
  "type": "Example",
  "number": "4.11.1",
  "title": "Exercise 3: (continued).",
  "body": " Exercise 3: (continued)   ... evaluation at 0 and iteration ...    I want to start this time by stepping back and look and assign some new names to the entities from the diagram I recreated last time.   Naming objects in \"Iteration and evaluation defined\"      My reasoning here is that labeling my objects like this will make it a little more clear on what exactly it would mean for our maps to be inverses. Given the naming used above, I'd need to prove and . What makes this tricky is that the objects in are -maps that preserve the structure from and the objects in are maps in from that don't necessarily preserve any structure.  Perhaps what I should be doing is thinking of the maps as a collection of arrows. Each arrow needs to have a source point in and a target point in . For to preserve structure, we'd need to have for every in .  Our map , basically takes advantage of the fact that any map in must be defined over the whole domain. This means that there must be an arrow originating at the point pointing to some target point in . We can then define such that for any we can define to be the map in which maps the only element in to the point in .  In contrast, our map takes a map and uses it to produce a map in . It does this by applying to zero or more times, such that for any . In the case where , the map is never applied at all. It follows that for any in , we're guaranteed to have .  These two maps both produce maps, but handle structure differently. The map takes a map which preserves the structure and uses it to produce a map which might not. The map takes a map which may not preserve structure and produces one that does. The identity basically establishes that in , but I think we still need to establish that the map is valid in .  For any given , the map needs to satisfy for every . At , and . Since holds true for , we can use induction to establish that they must be the same for every 'successor'.  Since each can be represented as , we can use that to make a subsitution. If follows that and . It also follows that and . Since we know that , we can combine these two results to establish that . Having established that and , follows by induction.  Next, let's compose these maps in the reverse order to produce the map . Suppose we have some in . It follows from our definitions that that which would imply that . Having now established that both and , it's safe to refer to these two maps as inverses.  Q.E.D.   "
},
{
  "id": "session15-p3",
  "level": "1",
  "url": "session15-p3.html",
  "type": "Section",
  "number": "4.12",
  "title": "Session 15: Objectification of Properties, Part 3",
  "body": " Session 15: Objectification of Properties, Part 3  I made some more progess on Session 15 this week, but there's still much more work to be done. In some ways, my progress through the text seems to parallel the algorithm for finding a presentation of . Each section of the text is kind of like a 'generator' element. The only way for me to find out how many parts Session 15 will take is for me to keep working on it until it reaches a stable point.   Exercise 4:   ... is itself a map of dynamical systems...    We've defined the category of based on the quality of structure preservation such that for an arbitrary map we enforce the condition that . For this exercise, we're essentially considering the special case where and .  We know that is an endomap on , so we know is a valid map in . To prove that we have a well defined map we'll need to show our structure preservation property still holds. If we substitute into , we get which is obviously true.  It really feels like this is stating the obvious, but perhaps we never explicitly proved that -maps must satisfy this \"reflexive property\".     Exercise 5:   ..if corresponds to ...    I'm assuming we're using the same set-up as Exercise 3 here. Given , we know . In particular, this must be true for , establishing that . We then used induction to establish that for all .  In Exercise 4, we proved that for any , the map is itself a well defined map . It follows that defines a map . Since compositions of -maps produce -maps, our composition should be well defined map such that .  When they say \" corresponds to \", we mean that we can evaluate at 0 to get or iterate from to get using . For , we can easily evaluate to establish . However, we still need to show that .  As in Exercise 3, I think we can do this through induction. We've already established that , so we know that for . Consider the case of . Given , we can rewrite as . Subsitute to get which can be rewritten as by the associative property. This means that implies .  Having established that both and , we can use induction to establish that for the entire domain of .     Exercise 6:   ...gender map     We're provided the following diagram for :   Definition of      Here the set is the set of people, the operator is a map that returns the mother of specified person, and is the gender binary map specified above. In order to show is an , we need to establish that it is both a valid map in and upholds the structure of the endomap .  First of all, let's address the reality that this is toy model of gender. In this exercise we're implicitly assuming  is a valid -map. We're excluding the existence of non-binary people in this way. We're also assuming that we have a mother -map, , that's defined for all . This model breaks if we \"clone\" a male, effectively excluding Stormtroopers from our set of people.  There's also some ambiguity because we haven't yet named the endomap on yet. I think the reason is because the endomap on is induced by the maps and . For clarity's sake, let's define to be the corresponding endomap in the \"gender-binary space\". This map is based on an assumption that the answer to \"what gender is your mother?\" will always \"female\".  Under those contraints on , showing is an valid -map basically comes down to establishing the relation . Perhaps this is most easily shown in a table.   Table of values for gender map           \"son\"  male  \"mother\"  female  female    \"daughter\"  female  \"mother\"  female  female     Essentially, both and are constant maps. We know because we've defined them both so that they both always return \"female\". In order for us to have an \" objectification in the subjective of gender\", all we have to do is to start excluding the people that don't fit our model!  I guess the lesson here is that if you ask a \"yes\/no\" question you have to get a \"yes\/no\" response. In this case, our standard idempontent map on enables us to ask something to the effect of \"is this a yes\/no question?\" which is forced to converge to the value \"yes\".    "
},
{
  "id": "session15-p3-3",
  "level": "2",
  "url": "session15-p3.html#session15-p3-3",
  "type": "Example",
  "number": "4.12.1",
  "title": "Exercise 4:.",
  "body": " Exercise 4:   ... is itself a map of dynamical systems...    We've defined the category of based on the quality of structure preservation such that for an arbitrary map we enforce the condition that . For this exercise, we're essentially considering the special case where and .  We know that is an endomap on , so we know is a valid map in . To prove that we have a well defined map we'll need to show our structure preservation property still holds. If we substitute into , we get which is obviously true.  It really feels like this is stating the obvious, but perhaps we never explicitly proved that -maps must satisfy this \"reflexive property\".   "
},
{
  "id": "session15-p3-4",
  "level": "2",
  "url": "session15-p3.html#session15-p3-4",
  "type": "Example",
  "number": "4.12.2",
  "title": "Exercise 5:.",
  "body": " Exercise 5:   ..if corresponds to ...    I'm assuming we're using the same set-up as Exercise 3 here. Given , we know . In particular, this must be true for , establishing that . We then used induction to establish that for all .  In Exercise 4, we proved that for any , the map is itself a well defined map . It follows that defines a map . Since compositions of -maps produce -maps, our composition should be well defined map such that .  When they say \" corresponds to \", we mean that we can evaluate at 0 to get or iterate from to get using . For , we can easily evaluate to establish . However, we still need to show that .  As in Exercise 3, I think we can do this through induction. We've already established that , so we know that for . Consider the case of . Given , we can rewrite as . Subsitute to get which can be rewritten as by the associative property. This means that implies .  Having established that both and , we can use induction to establish that for the entire domain of .   "
},
{
  "id": "session15-p3-5",
  "level": "2",
  "url": "session15-p3.html#session15-p3-5",
  "type": "Example",
  "number": "4.12.3",
  "title": "Exercise 6:.",
  "body": " Exercise 6:   ...gender map     We're provided the following diagram for :   Definition of      Here the set is the set of people, the operator is a map that returns the mother of specified person, and is the gender binary map specified above. In order to show is an , we need to establish that it is both a valid map in and upholds the structure of the endomap .  First of all, let's address the reality that this is toy model of gender. In this exercise we're implicitly assuming  is a valid -map. We're excluding the existence of non-binary people in this way. We're also assuming that we have a mother -map, , that's defined for all . This model breaks if we \"clone\" a male, effectively excluding Stormtroopers from our set of people.  There's also some ambiguity because we haven't yet named the endomap on yet. I think the reason is because the endomap on is induced by the maps and . For clarity's sake, let's define to be the corresponding endomap in the \"gender-binary space\". This map is based on an assumption that the answer to \"what gender is your mother?\" will always \"female\".  Under those contraints on , showing is an valid -map basically comes down to establishing the relation . Perhaps this is most easily shown in a table.   Table of values for gender map           \"son\"  male  \"mother\"  female  female    \"daughter\"  female  \"mother\"  female  female     Essentially, both and are constant maps. We know because we've defined them both so that they both always return \"female\". In order for us to have an \" objectification in the subjective of gender\", all we have to do is to start excluding the people that don't fit our model!  I guess the lesson here is that if you ask a \"yes\/no\" question you have to get a \"yes\/no\" response. In this case, our standard idempontent map on enables us to ask something to the effect of \"is this a yes\/no question?\" which is forced to converge to the value \"yes\".   "
},
{
  "id": "session15-p4",
  "level": "1",
  "url": "session15-p4.html",
  "type": "Section",
  "number": "4.13",
  "title": "Session 15: Objectification of Properties, Part 4",
  "body": " Session 15: Objectification of Properties, Part 4  So... here's the deal. This week has been completely devoted to a single exercise. I might not even have a satisfactory solution by the end of this, but that's okay. Learning math is sometimes messy like this. Sometimes all you can do is just lay out the information you know and start asking questions, so that's what you do.   Exercise 7:    ... above to above...  Before we begin, I want to preface this with an additional spoiler. I got really stuck at 12\/14 maps. If you're stuck there also, I'd encourage you to take a break from it. I know I needed it.     Let's begin with some diagrams of our endomaps:   Definitions of and      I'm going to try to adhere to the text as closely as I can for now. Thus, has been labeled using it's presentation already with the generators given as . Our presention includes following 4 relations:                        We're looking for maps for which these generators from get assigned to points in such that for every . For now, we're not sure what assignments will make that happen so we'll just call these mystery points , , , and . Since we established that for all , we can match each of our relations on with a corresponding relation on :                        Beginning with the generator , we're going to look for a list potential points in that satisfy our first relation: . The textbook helps us out by pointing out that meet this condition but do not. Thus, we can make four possible assignments for : .  If we assign , we can apply the operator until we form a loop. If we do so, we find that , , and . Our second relation implies that , but we already know so that means that whatever we choose for must satisfy . In the diagram, the only arrows leading into point are the arrows originating at . Thus our only valid assignments for , given , are and .  Given these two choices of , we can start to narrow down our choices of as well. If we assume that implies that must have an arrow leading to point . Presicely one point has that property, namely .  Our final relation specifies that , and there's only one 2-cycle in that could satisfy this. This means that needs to be either or . Having exhausted all possibilities for maps such that , we're currently sitting on a list of 4 maps: , , , ,  Moving on, our next possible assignment is . Iterating from there gives us the following: , , and .  As before, our second relation limits our choice of . Knowing tell us that there must be an arrow from to , and the only arrow with a target of is the one originating at point . Thus, .  Testing our third relation places limits on . Since , the needs to be an arrow from point to and this is uniquely satisfied by point .  Our choices for are still independent of our choices for , specifically . This gives us two new maps, and , bringing our running total of maps to 6.  Our third option for is . If we assign , it follows that , , and . Since , it follows that must be because there's only one arrow leading into . With our third relation telling us , that tells us that our choice of must have an arrow leading to . Two such points satisfy this, namely . For each of those choices of , there are still two independent choices for . This gives us a total of 4 maps with bringing our running total to 10. Specifically, our new maps are , , , and .  Our final choice for is . Going through our algorithm again, we start be iterating to get , , and . Our must satisfy , so the only choice is . Our must satisfy , so the only choice is . Once again, our choice of is still independent with two options of . These two maps, and , bring our running total to 12.  And.... this is where I got stuck. I mean, really stuck.  After going through this algorithm 3 times and getting the same 12 maps, I decided to double check my work using Python. Both my implementation of the described algorithm and my exhaustive search both only found the same 12 maps seen here.  Once I kind of a way of quickly testing arbitrary maps for structure preservation, I was able to speed up my testing of different hypotheses about where my missing two maps could be. After several hours of unsuccessfully scouring the Internets for answers, I decided it was time for a break and cracked open a beer.  Yeah, I know that's not what you'd expect the solution to a math problem to be. But that's precisely what I needed at the time.  That beer was to my hand what the pillow was to Alphonse in Last week's #Caturday post:    A demonstration of parallels between the \"standard idempotent\" illustrated by photos of a cushion with and without a cat.    I think that I was so wrapped up in my own version of the problem. I wasn't actually reading what the authors said . The text does not state there are 14 maps, it was just \"heavily implied\".  This question is starting to feel self-referential in a way I hadn't been expecting. My current line of thinking is authors' use of the pronoun \"I\" instead of \"we\" here is done with intention, and that my two missing maps are somehow related to the way the \"null map\" and the \"identity map\" were handled in the bookkeeping rules of the broader category.  I think I'm going to let this stew for while to see if I can come up with a better solution that answers this and Exercise 9 simultaneously.  Stay tuned.    "
},
{
  "id": "session15-p4-3",
  "level": "2",
  "url": "session15-p4.html#session15-p4-3",
  "type": "Example",
  "number": "4.13.1",
  "title": "Exercise 7:.",
  "body": " Exercise 7:    ... above to above...  Before we begin, I want to preface this with an additional spoiler. I got really stuck at 12\/14 maps. If you're stuck there also, I'd encourage you to take a break from it. I know I needed it.     Let's begin with some diagrams of our endomaps:   Definitions of and      I'm going to try to adhere to the text as closely as I can for now. Thus, has been labeled using it's presentation already with the generators given as . Our presention includes following 4 relations:                        We're looking for maps for which these generators from get assigned to points in such that for every . For now, we're not sure what assignments will make that happen so we'll just call these mystery points , , , and . Since we established that for all , we can match each of our relations on with a corresponding relation on :                        Beginning with the generator , we're going to look for a list potential points in that satisfy our first relation: . The textbook helps us out by pointing out that meet this condition but do not. Thus, we can make four possible assignments for : .  If we assign , we can apply the operator until we form a loop. If we do so, we find that , , and . Our second relation implies that , but we already know so that means that whatever we choose for must satisfy . In the diagram, the only arrows leading into point are the arrows originating at . Thus our only valid assignments for , given , are and .  Given these two choices of , we can start to narrow down our choices of as well. If we assume that implies that must have an arrow leading to point . Presicely one point has that property, namely .  Our final relation specifies that , and there's only one 2-cycle in that could satisfy this. This means that needs to be either or . Having exhausted all possibilities for maps such that , we're currently sitting on a list of 4 maps: , , , ,  Moving on, our next possible assignment is . Iterating from there gives us the following: , , and .  As before, our second relation limits our choice of . Knowing tell us that there must be an arrow from to , and the only arrow with a target of is the one originating at point . Thus, .  Testing our third relation places limits on . Since , the needs to be an arrow from point to and this is uniquely satisfied by point .  Our choices for are still independent of our choices for , specifically . This gives us two new maps, and , bringing our running total of maps to 6.  Our third option for is . If we assign , it follows that , , and . Since , it follows that must be because there's only one arrow leading into . With our third relation telling us , that tells us that our choice of must have an arrow leading to . Two such points satisfy this, namely . For each of those choices of , there are still two independent choices for . This gives us a total of 4 maps with bringing our running total to 10. Specifically, our new maps are , , , and .  Our final choice for is . Going through our algorithm again, we start be iterating to get , , and . Our must satisfy , so the only choice is . Our must satisfy , so the only choice is . Once again, our choice of is still independent with two options of . These two maps, and , bring our running total to 12.  And.... this is where I got stuck. I mean, really stuck.  After going through this algorithm 3 times and getting the same 12 maps, I decided to double check my work using Python. Both my implementation of the described algorithm and my exhaustive search both only found the same 12 maps seen here.  Once I kind of a way of quickly testing arbitrary maps for structure preservation, I was able to speed up my testing of different hypotheses about where my missing two maps could be. After several hours of unsuccessfully scouring the Internets for answers, I decided it was time for a break and cracked open a beer.  Yeah, I know that's not what you'd expect the solution to a math problem to be. But that's precisely what I needed at the time.  That beer was to my hand what the pillow was to Alphonse in Last week's #Caturday post:    A demonstration of parallels between the \"standard idempotent\" illustrated by photos of a cushion with and without a cat.    I think that I was so wrapped up in my own version of the problem. I wasn't actually reading what the authors said . The text does not state there are 14 maps, it was just \"heavily implied\".  This question is starting to feel self-referential in a way I hadn't been expecting. My current line of thinking is authors' use of the pronoun \"I\" instead of \"we\" here is done with intention, and that my two missing maps are somehow related to the way the \"null map\" and the \"identity map\" were handled in the bookkeeping rules of the broader category.  I think I'm going to let this stew for while to see if I can come up with a better solution that answers this and Exercise 9 simultaneously.  Stay tuned.   "
},
{
  "id": "session15-p5",
  "level": "1",
  "url": "session15-p5.html",
  "type": "Section",
  "number": "4.14",
  "title": "Session 15: Objectification of Properties, Part 5",
  "body": " Session 15: Objectification of Properties, Part 5  Last week I stopped partway through Exercise 7 because I was struggling to find all the last 2 maps, but I had \"an idea\" about where to find them. This week the plan is work on verifying that hypothesis by using Python. I'm going to begin with Exercise 8 to get a better feel for how these \"presentations\" work.  This is going to get some what code-heavy, so see this Jupyter notebook if you want to follow along.   Exercise 8:   Draw some simple dynamical systems...    Rather than manually finding these presentations, I'm going to build a Python script that does it for me. I leveraged some common libraries, includeing NetworkX for the \"digraph\" object, NumPy for linear algebra. I used Matplotlib for visuals during development, but I'll map to latex for this document. Our endomap might be defined as follows:  import numpy as np import networkx as nx import matplotlib.pyplot as plt x_nodes = [\"X\"+str(i) for i in range(9)] x_edges = [ (x_nodes[0],x_nodes[4]), (x_nodes[1],x_nodes[5]), (x_nodes[2],x_nodes[6]), (x_nodes[3],x_nodes[8]), (x_nodes[4],x_nodes[5]), (x_nodes[5],x_nodes[6]), (x_nodes[6],x_nodes[7]), (x_nodes[7],x_nodes[5]), (x_nodes[8],x_nodes[3]) ] XG = nx.DiGraph() XG.add_nodes_from(x_nodes) XG.add_edges_from(x_edges)  Since this directed graph represents an endomap, each node should have precisely one \"successor\". We can use this property to implent our endomap as a function on the graph:  def follow_endomap(G,n): return list(G.successors(n))[0]  We can then use the algorithm described in the text to produce a \"presentation\" from a given endomap. I tried  def make_presentation(G): G_nodes = list(G.nodes()) ones_G = np.full((len(G_nodes),),1) GA = nx.adjacency_matrix(G) G_arrows_in = np.matmul(ones_G,GA.toarray()) G_arrows_by_node = sorted(zip(range(len(G_nodes)),G_arrows_in), key=lambda x: x[1]) G_presentation = {} G_relations = {} for k,v in G_arrows_by_node: print(f\"Checking node {k} with {v} arrows in\") if v == 0: print(f\"Adding root generator {G_nodes[k]}\") G_presentation[G_nodes[k]] = (G_nodes[k],v) next_node = follow_endomap(G,G_nodes[k]) steps = 1 while not next_node in G_presentation: print(f\"Adding follow up node {next_node}: {steps} from {G_nodes[k]}\") G_presentation[next_node] = (G_nodes[k],steps) next_node = follow_endomap(G,next_node) steps += 1 print(f\"next node {next_node} already has presentation\") G_relations[G_nodes[k]] = ((G_nodes[k],steps),G_presentation[next_node]) elif v == 1: print(f\"Only 1 way into node {k}\") if G_nodes[k] in G_presentation: print(\"already has a presentation\") else: print(\"Found potential loop\") G_presentation[G_nodes[k]] = (G_nodes[k],0) next_node = follow_endomap(G,G_nodes[k]) steps = 1 while not next_node in G_presentation: print(f\"Adding follow up node {next_node}: {steps} from {G_nodes[k]}\") G_presentation[next_node] = (G_nodes[k],steps) next_node = follow_endomap(G,next_node) steps += 1 print(f\"next node {next_node} already has presentation\") G_relations[G_nodes[k]] = ((G_nodes[k],steps),G_presentation[next_node]) else: print(f\"More than 1 way in\") return { \"generators\":list(G_relations.keys()), \"relations\":list(G_relations.values()) } endomap_alpha = make_presentation(XG) print(endomap_alpha)  This code produced the following output:  Checking node 0 with 0 arrows in Adding root generator X0 Adding follow up node X4: 1 from X0 Adding follow up node X5: 2 from X0 Adding follow up node X6: 3 from X0 Adding follow up node X7: 4 from X0 next node X5 already has presentation Checking node 1 with 0 arrows in Adding root generator X1 next node X5 already has presentation Checking node 2 with 0 arrows in Adding root generator X2 next node X6 already has presentation Checking node 3 with 1 arrows in Only 1 way into node 3 Found potential loop Adding follow up node X8: 1 from X3 next node X3 already has presentation Checking node 4 with 1 arrows in Only 1 way into node 4 already has a presentation Checking node 7 with 1 arrows in Only 1 way into node 7 already has a presentation Checking node 8 with 1 arrows in Only 1 way into node 8 already has a presentation Checking node 6 with 2 arrows in More than 1 way in Checking node 5 with 3 arrows in More than 1 way in { 'generators': ['X0', 'X1', 'X2', 'X3'], 'relations': [ (('X0', 5), ('X0', 2)), (('X1', 1), ('X0', 2)), (('X2', 1), ('X0', 3)), (('X3', 2), ('X3', 0)) ] }  This matches up with our expected presentation for with the substitions , , , and . The relations are expressed as a ordered pair based on the number of \"presses\" from a specified generator. This the equation becomes (('X0', 5), ('X0', 2)) , becomes (('X1', 1), ('X0', 2)) , becomes (('X2', 1), ('X0', 3)) , and becomes (('X3', 2), ('X3', 0)) .  We can use a similar process to find a presentation for as well with the following code.  y_nodes = [\"Y\"+y for y in [\"p\", \"q\", \"r\", \"s\", \"t\", \"v\", \"u\", \"m\", \"l\", \"w\", \"x\", \"y\", \"z\"]] y_edges = [ (y_nodes[0],y_nodes[2]), (y_nodes[1],y_nodes[2]), (y_nodes[2],y_nodes[4]), (y_nodes[3],y_nodes[4]), (y_nodes[4],y_nodes[5]), (y_nodes[5],y_nodes[6]), (y_nodes[6],y_nodes[3]), (y_nodes[7],y_nodes[8]), (y_nodes[8],y_nodes[7]), (y_nodes[9],y_nodes[10]), (y_nodes[10],y_nodes[11]), (y_nodes[11],y_nodes[9]), (y_nodes[12],y_nodes[11]) ] YG = nx.DiGraph() YG.add_nodes_from(y_nodes) YG.add_edges_from(y_edges) endomap_beta = make_presentation(YG) print(endomap_beta)  The output of the above code is the following presentation:  { 'generators': ['p', 'q', 'z', 'm'], 'relations': [ (('p', 6), ('p', 2)), (('q', 1), ('p', 1)), (('z', 4), ('z', 1)), (('m', 2), ('m', 0)) ] }  Using the notation in the text, our corresponding relations would be , , , and .  It seems like this method would be characterized as depth first search for the presentation. Depending on what order the nodes of the nodes used to express the maps, the above algorithm may produce a different result.  For example, suppose we defined X with the nodes in reverse:  XG2 = nx.DiGraph() x2_nodes = [x_nodes[-1-i] for i in range(len(x_nodes))] print(x2_nodes) XG2.add_nodes_from(x2_nodes) XG2.add_edges_from(x_edges) endomap_alpha_prime = make_presentation(XG2) print(endomap_alpha_prime)  We get the following output:  ['X8', 'X7', 'X6', 'X5', 'X4', 'X3', 'X2', 'X1', 'X0'] Checking node 6 with 0 arrows in Adding root generator X2 Adding follow up node X6: 1 from X2 Adding follow up node X7: 2 from X2 Adding follow up node X5: 3 from X2 next node X6 already has presentation Checking node 7 with 0 arrows in Adding root generator X1 next node X5 already has presentation Checking node 8 with 0 arrows in Adding root generator X0 Adding follow up node X4: 1 from X0 next node X5 already has presentation Checking node 0 with 1 arrows in Only 1 way into node 0 Found potential loop Adding follow up node X3: 1 from X8 next node X8 already has presentation Checking node 1 with 1 arrows in Only 1 way into node 1 already has a presentation Checking node 4 with 1 arrows in Only 1 way into node 4 already has a presentation Checking node 5 with 1 arrows in Only 1 way into node 5 already has a presentation Checking node 2 with 2 arrows in More than 1 way in Checking node 3 with 3 arrows in More than 1 way in { 'generators': ['X2', 'X1', 'X0', 'X8'], 'relations': [ (('X2', 4), ('X2', 1)), (('X1', 1), ('X2', 3)), (('X0', 2), ('X2', 3)), (('X8', 2), ('X8', 0)) ] }  This is an \"equivalent presentation\" for . We have the same generators still, but they're listed in different order and our relations are slightly different. The equivalent expressions are , , , and .  I'm thinking that my task for Exercise 9 will be a little easier if I can standardize my relations and generators in a unified manner that makes these \"equivalent presentations\" easier to identify. I'm wondering if using a \"breadth first search\" instead of a \"depth first search\" might allow me to more readily identify the cylces of each length.     Exercise 7 (Part 2):   Given my code above, let's review where I got stuck last week and what I think my roadblock is. As mentioned in Exercise 8 above, part of that difficulty was matching up the cycles of matching lengths.    My code from my previous attempt tried to follow my pen-and-paper process as closely as possible. The relevant Python code was as follows:  def get_cycles(endomap): cycles_by_length = {} cycles_by_generator = {} for k,v in enumerate(endomap[\"relations\"]): if v[0][0] == v[1][0]: cl = abs(v[0][1] - v[1][1]) mins = min(v[0][1],v[1][1]) print(f\"{v[0][0]} leads to cycle of length {cl} after {mins} steps\") if not cl in cycles_by_length: cycles_by_length[cl] = { \"primary_generators\":[k], \"secondary_generators\":[] } else: cycles_by_length[cl]['primary_generators'].append(k) cycles_by_generator[v[0][0]] = cl else: cl = cycles_by_generator[v[1][0]] cycles_by_length[cl]['secondary_generators'].append(k) cycles_by_generator[v[0][0]] = cl return { \"cycles_by_length\":cycles_by_length, \"cycles_by_generator\":cycles_by_generator } def iterate_endomap(endomap, start, steps): out_val = start for i in range(steps): out_val = follow_endomap(endomap,out_val) return out_val def make_assignments(gen,poss_vals): output = [] for v in poss_vals: output.append({gen:v}) return output def join_assignments(ass1,ass2): if len(ass1) == 0: return ass2 if len(ass2)<len(ass1): return join_assignments(ass2,ass1) output = [] for a1 in ass1: for a2 in ass2: new_a1 = a1.copy() for k,v in zip(a2.keys(),a2.values()): new_a1[k] = v output.append(new_a1) return output def find_predecessors(endomap,target,steps=1): preds = list(endomap.predecessors(target)) if steps > 1 and len(preds) > 0: r_preds = [] for t in preds: r_preds.extend(find_predecessors(endomap,t,steps-1)) return r_preds else: return preds assignments = [] for idx,rel in enumerate(endomap_alpha['relations']): print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\") x_gen = rel[0][0] print(f'Attempting to match relation on: {x_gen}') cl = alpha_cycles['cycles_by_generator'][x_gen] print(f'Cycle Length: {cl}') y_cycles = alpha_cycles['cycles_by_length'][cl] poss_y_gen = y_cycles['primary_generators']+y_cycles['secondary_generators'] print(f\"Possible Generators: {poss_y_gen}\") print(f\"Attempting to satisfy: {rel}\") rel_lhs = iterate_endomap(XG,rel[0][0],rel[0][1]) rel_rhs = iterate_endomap(XG,rel[1][0],rel[1][1]) print(f\"In X: {rel_lhs} = {rel_rhs}\") for gen in poss_y_gen: print(f\"Testing generator: {gen}\") if rel[0][0]==rel[1][0]: print(\"Trying to match up a loop\") seen_in_Y = set([]) eligible_subs = {} cur_y = endomap_beta['generators'][gen] y_steps = 0 found_pairs = [] while not cur_y in seen_in_Y: lhs = iterate_endomap(YG,cur_y,rel[0][1]) rhs = iterate_endomap(YG,cur_y,rel[1][1]) if lhs == rhs: print(f\"Potential match at {cur_y}! {y_steps} from {gen}\") found_pairs.append(cur_y) seen_in_Y.add(cur_y) y_steps += 1 cur_y = iterate_endomap(YG,cur_y,1) print(f\"Potential matches for {x_gen}: {found_pairs}\") new_assignments = make_assignments(x_gen,found_pairs) print(f\"New assignments: {new_assignments}\") assignments = join_assignments(assignments,new_assignments) print(f\"Joined assignments: {assignments}\") else: print(\"Trying to match up a chain\") new_assignments = [] print(f\"Existing Assignments: {assignments}\") for ass in assignments: print(f\"* Checking {ass}\") if rel[1][0] in ass.keys(): print(f\"\\t Found assignment from {rel[1][0]} to {ass[rel[1][0]]}\") y_target = ass[rel[1][0]] x_lhs = iterate_endomap(XG,rel[0][0],rel[0][1]) print(f\"\\tIn X: {rel[0][1]} steps from {rel[0][0]} is {x_lhs}\") x_rhs = iterate_endomap(XG,rel[1][0],rel[1][1]) print(f\"\\tIn X: {rel[1][1]} steps from {rel[1][0]} is {x_rhs}\") y_rhs = iterate_endomap(YG,y_target,rel[1][1]) print(f\"\\tIn Y: {rel[1][1]} steps from {y_target} is {y_rhs}\") print(f\"\\tThis means {rel[0][0]} needs to map to {y_rhs} after {rel[0][1]} steps\") poss_vals = find_predecessors(YG,y_rhs,rel[0][1]) print(f\"\\tPossible Predecessors: {poss_vals}\") for v in poss_vals: new_ass = ass.copy() new_ass[rel[0][0]] = v print(f\"\\tAdding new assignment: {new_ass}\") new_assignments.append(new_ass) print(\"Done checking old assignments\") print(f\"New assignments({len(new_assignments)}): {new_assignments}\") assignments = new_assignments print(f\"Pre-dupe removal: {len(assignments)}\") remove_dupes = set([str(x) for x in assignments]) print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\") print(f\"Final assignment count: {len(remove_dupes)}\") print(remove_dupes)  The relevant output of which gives me:  Final assignment count: 12 { \"{'X3': 'Ym', 'X0': 'Yw', 'X1': 'Yx', 'X2': 'Yy'}\", \"{'X3': 'Yl', 'X0': 'Yy', 'X1': 'Yw', 'X2': 'Yx'}\", \"{'X3': 'Yl', 'X0': 'Yw', 'X1': 'Yz', 'X2': 'Yy'}\", \"{'X3': 'Ym', 'X0': 'Yy', 'X1': 'Yw', 'X2': 'Yz'}\", \"{'X3': 'Ym', 'X0': 'Yx', 'X1': 'Yy', 'X2': 'Yw'}\", \"{'X3': 'Yl', 'X0': 'Yy', 'X1': 'Yw', 'X2': 'Yz'}\", \"{'X3': 'Ym', 'X0': 'Yy', 'X1': 'Yw', 'X2': 'Yx'}\", \"{'X3': 'Ym', 'X0': 'Yw', 'X1': 'Yz', 'X2': 'Yy'}\", \"{'X3': 'Yl', 'X0': 'Yw', 'X1': 'Yx', 'X2': 'Yy'}\", \"{'X3': 'Ym', 'X0': 'Yz', 'X1': 'Yy', 'X2': 'Yw'}\", \"{'X3': 'Yl', 'X0': 'Yz', 'X1': 'Yy', 'X2': 'Yw'}\", \"{'X3': 'Yl', 'X0': 'Yx', 'X1': 'Yy', 'X2': 'Yw'}\" }  These are precisely the 12 maps I came up with by hand. Not satisfied, I took this one step further with a more exhaustive search on a smaller \"subgraph\" of . Specifically, between the cluster of points around my 3-cycle in to the respective 3-cycle in .  sm_x_nodes = [\"a\", \"b\", \"c\", \" a\", \"^2 a\", \"^3 a\", \"^4 a\"] sm_x_edges = [ (sm_x_nodes[0],sm_x_nodes[3]), (sm_x_nodes[1],sm_x_nodes[4]), (sm_x_nodes[2],sm_x_nodes[5]), (sm_x_nodes[3],sm_x_nodes[4]), (sm_x_nodes[4],sm_x_nodes[5]), (sm_x_nodes[5],sm_x_nodes[6]), (sm_x_nodes[6],sm_x_nodes[4]) ] sm_XG = nx.DiGraph() sm_XG.add_nodes_from(sm_x_nodes) sm_XG.add_edges_from(sm_x_edges) sm_y_nodes = [\"w\",\"x\",\"y\",\"z\"] sm_y_edges = [ (sm_y_nodes[0],sm_y_nodes[1]), (sm_y_nodes[1],sm_y_nodes[2]), (sm_y_nodes[2],sm_y_nodes[0]), (sm_y_nodes[3],sm_y_nodes[2]) ] sm_YG = nx.DiGraph() sm_YG.add_nodes_from(sm_y_nodes) sm_YG.add_edges_from(sm_y_edges) sm_X_alpha = make_presentation(sm_XG) sm_Y_beta = make_presentation(sm_YG) print(sm_X_alpha) print(\"~~~~~~~~~~~~~~~~~~~\") print(sm_Y_beta)  This gives me the following (expected) presentations:  {'generators': ['a', 'b', 'c'], 'relations': [(('a', 5), ('a', 2)), (('b', 1), ('a', 2)), (('c', 1), ('a', 3))]} ~~~~~~~~~~~~~~~~~~~ {'generators': ['z'], 'relations': [(('z', 4), ('z', 1))]}  Given that this aligned with my expectation, I tried to generate ALL maps in . I know that since I'm mapping from a 7 element set to a 4 element set there are possible maps all together. I can then methodically test each map to see if they \"preserve structure\".  def make_all_maps(xs,ys): x_size = len(xs) y_size = len(ys) total = y_size**x_size print(total) all_assignments = [] for x in xs: new_maps = [] for y in ys: new_maps.append({x:y}) all_assignments = join_assignments(all_assignments,new_maps) return all_assignments sm_maps = make_all_maps(sm_x_nodes,sm_y_nodes) def preserves_structure(f,x_graph,y_graph): for k,v in zip(f.keys(),f.values()): #print(f\"f({k}) = {v}\") alpha_x = follow_endomap(x_graph,k) f_alpha_x = f[alpha_x] #print(f\"alpha({k}) = {alpha_x}\") #print(f\"f({alpha_x}) = {f_alpha_x}\") beta_y = follow_endomap(y_graph,v) #print(f\"beta({v}) = {beta_y}\") if beta_y != f_alpha_x: #print(\"fails to preserve structure\") return False return True sm_evaluations = list(filter(lambda x: preserves_structure(x,sm_XG,sm_YG),sm_maps)) print(len(sm_evaluations)) print(sm_evaluations)  Since each of these 6 maps could have either and as options, this essentially confirms the 12 maps I saw earlier.  Where this problem became interesting was when I stopped to consider the question: \"how could I possibly get 7 maps?\". After testing out some variations I came across the following graph which finally \"worked\".  sm_z_nodes = [\"X\"+str(i) for i in range(8)] sm_z_edges = [ (sm_z_nodes[0],sm_z_nodes[3]), (sm_z_nodes[1],sm_z_nodes[4]), (sm_z_nodes[2],sm_z_nodes[5]), (sm_z_nodes[3],sm_z_nodes[4]), (sm_z_nodes[4],sm_z_nodes[5]), (sm_z_nodes[5],sm_z_nodes[6]), (sm_z_nodes[6],sm_z_nodes[4]), (sm_z_nodes[7],sm_z_nodes[0]) ] sm_ZG = nx.DiGraph() sm_ZG.add_nodes_from(sm_z_nodes) sm_ZG.add_edges_from(sm_z_edges) # make my latex easier print(\"\\n\".join([\"(\"+e[0]+\") edge (\"+e[1]+\")\" for e in sm_z_edges])) nx.draw(sm_ZG, with_labels=True, font_weight='bold') my_missing_maps = make_all_maps(sm_z_nodes,sm_y_nodes) missing_map_evaluations = list(filter(lambda x: preserves_structure(x,sm_ZG,sm_YG),my_missing_maps)) print(len(missing_map_evaluations)) print(missing_map_evaluations)   My map      Once run, this gave me the following 7 structure preserving maps:  [ {'X8': 'w', 'X7': 'y', 'X6': 'x', 'X5': 'w', 'X4': 'y', 'X3': 'w', 'X1': 'x', 'X2': 'y'}, {'X8': 'x', 'X7': 'w', 'X6': 'y', 'X5': 'x', 'X4': 'w', 'X3': 'x', 'X1': 'y', 'X2': 'w'}, {'X8': 'x', 'X7': 'w', 'X6': 'y', 'X5': 'x', 'X4': 'w', 'X3': 'z', 'X1': 'y', 'X2': 'w'}, {'X8': 'y', 'X7': 'x', 'X6': 'w', 'X5': 'y', 'X4': 'x', 'X3': 'y', 'X1': 'w', 'X2': 'x'}, {'X8': 'y', 'X7': 'x', 'X6': 'w', 'X5': 'y', 'X4': 'x', 'X3': 'y', 'X1': 'w', 'X2': 'z'}, {'X8': 'z', 'X7': 'w', 'X6': 'y', 'X5': 'x', 'X4': 'w', 'X3': 'x', 'X1': 'y', 'X2': 'w'}, {'X8': 'z', 'X7': 'w', 'X6': 'y', 'X5': 'x', 'X4': 'w', 'X3': 'z', 'X1': 'y', 'X2': 'w'} ]  This got me wondering if I had an object \"0\" with the property needed in the above map and that's when I got really excited by this idea of the objects \"0\" and \"1\" being defined as maps.  The first time I started asking \"is the text wrong\" was way back in Article 1 when we first started counting maps. The discrepancy had to do with the way I was allowing things to be \"undecided\" in my model of a map in a way that the authors had explicitly not. Essentially, I had left as \"undefined\" while the authors had defined , so there was an off-by-one error in how I was counting my maps.  I think I'm implicitly doing the something similar again here. I feel like this mystery point in my map comes from the fact that I have a map that assigns to my generators. You can see this in my code where I use the adjacency matrix of my graph to count the incoming arrows at each node to find potential generators. From there, I had to go through a great deal of messy code to pull a generator out of the loop by iterating through points with exactly one arrow in. I've started to wonder if I should be thinking of \"0\" as a map from the \"empty set\" to \"my generators\" and treat my cycle of two more like a single element.  I've also started thinking about using as an intermediary step between and .   My map      Part of my reasoning is that it seems like there are certain \"natural maps\" based on the structure of the endomap. Once such map is the \"number of incoming arrows map\", as established by the product of my \"ones vector\" with the \"adjacency matrix\". This is an \"objective value\" that can be assigned to each node.   Incoming arrow counts on      Then there's a second \"natural map\" that assigns a value to each node based on \"the number of steps to stabilize\". That is, for any given point , how many times can we apply until we see a point that we've seen before.   Steps to stabilize on      It seems like these two graphs labelings are somehow connected with the presentation of in a way I can't quite articulate yet.  There's one last idea I want to get out my head for the week, and it's this idea that one of my 12 maps is \"special\". Namely, I think the map that assigns has a different interpretation that the others do not. Specifically, I think this map has an \"isomorphism\" with a subset of that would describe as \"the image of under \". Where does it say that the points in can't also be points in ? Maybe that's the missing binary question that produces my two missing maps.   Definitions of and      Once I apply to the points in , each one of the \"tails on the loop\" shortens by 1. If I apply a second time, the tails disappear entirely. Maybe I should be taking exponents of my adjacency matrix instead of trying to break things apart into cycles.    I'm going to stop there for the week. Having to manually format the output of my Juypter notebooks is exhausting. If I'm going to continue solving questions with code it might be worthwhile to automate the process.  "
},
{
  "id": "session15-p5-4",
  "level": "2",
  "url": "session15-p5.html#session15-p5-4",
  "type": "Example",
  "number": "4.14.1",
  "title": "Exercise 8:.",
  "body": " Exercise 8:   Draw some simple dynamical systems...    Rather than manually finding these presentations, I'm going to build a Python script that does it for me. I leveraged some common libraries, includeing NetworkX for the \"digraph\" object, NumPy for linear algebra. I used Matplotlib for visuals during development, but I'll map to latex for this document. Our endomap might be defined as follows:  import numpy as np import networkx as nx import matplotlib.pyplot as plt x_nodes = [\"X\"+str(i) for i in range(9)] x_edges = [ (x_nodes[0],x_nodes[4]), (x_nodes[1],x_nodes[5]), (x_nodes[2],x_nodes[6]), (x_nodes[3],x_nodes[8]), (x_nodes[4],x_nodes[5]), (x_nodes[5],x_nodes[6]), (x_nodes[6],x_nodes[7]), (x_nodes[7],x_nodes[5]), (x_nodes[8],x_nodes[3]) ] XG = nx.DiGraph() XG.add_nodes_from(x_nodes) XG.add_edges_from(x_edges)  Since this directed graph represents an endomap, each node should have precisely one \"successor\". We can use this property to implent our endomap as a function on the graph:  def follow_endomap(G,n): return list(G.successors(n))[0]  We can then use the algorithm described in the text to produce a \"presentation\" from a given endomap. I tried  def make_presentation(G): G_nodes = list(G.nodes()) ones_G = np.full((len(G_nodes),),1) GA = nx.adjacency_matrix(G) G_arrows_in = np.matmul(ones_G,GA.toarray()) G_arrows_by_node = sorted(zip(range(len(G_nodes)),G_arrows_in), key=lambda x: x[1]) G_presentation = {} G_relations = {} for k,v in G_arrows_by_node: print(f\"Checking node {k} with {v} arrows in\") if v == 0: print(f\"Adding root generator {G_nodes[k]}\") G_presentation[G_nodes[k]] = (G_nodes[k],v) next_node = follow_endomap(G,G_nodes[k]) steps = 1 while not next_node in G_presentation: print(f\"Adding follow up node {next_node}: {steps} from {G_nodes[k]}\") G_presentation[next_node] = (G_nodes[k],steps) next_node = follow_endomap(G,next_node) steps += 1 print(f\"next node {next_node} already has presentation\") G_relations[G_nodes[k]] = ((G_nodes[k],steps),G_presentation[next_node]) elif v == 1: print(f\"Only 1 way into node {k}\") if G_nodes[k] in G_presentation: print(\"already has a presentation\") else: print(\"Found potential loop\") G_presentation[G_nodes[k]] = (G_nodes[k],0) next_node = follow_endomap(G,G_nodes[k]) steps = 1 while not next_node in G_presentation: print(f\"Adding follow up node {next_node}: {steps} from {G_nodes[k]}\") G_presentation[next_node] = (G_nodes[k],steps) next_node = follow_endomap(G,next_node) steps += 1 print(f\"next node {next_node} already has presentation\") G_relations[G_nodes[k]] = ((G_nodes[k],steps),G_presentation[next_node]) else: print(f\"More than 1 way in\") return { \"generators\":list(G_relations.keys()), \"relations\":list(G_relations.values()) } endomap_alpha = make_presentation(XG) print(endomap_alpha)  This code produced the following output:  Checking node 0 with 0 arrows in Adding root generator X0 Adding follow up node X4: 1 from X0 Adding follow up node X5: 2 from X0 Adding follow up node X6: 3 from X0 Adding follow up node X7: 4 from X0 next node X5 already has presentation Checking node 1 with 0 arrows in Adding root generator X1 next node X5 already has presentation Checking node 2 with 0 arrows in Adding root generator X2 next node X6 already has presentation Checking node 3 with 1 arrows in Only 1 way into node 3 Found potential loop Adding follow up node X8: 1 from X3 next node X3 already has presentation Checking node 4 with 1 arrows in Only 1 way into node 4 already has a presentation Checking node 7 with 1 arrows in Only 1 way into node 7 already has a presentation Checking node 8 with 1 arrows in Only 1 way into node 8 already has a presentation Checking node 6 with 2 arrows in More than 1 way in Checking node 5 with 3 arrows in More than 1 way in { 'generators': ['X0', 'X1', 'X2', 'X3'], 'relations': [ (('X0', 5), ('X0', 2)), (('X1', 1), ('X0', 2)), (('X2', 1), ('X0', 3)), (('X3', 2), ('X3', 0)) ] }  This matches up with our expected presentation for with the substitions , , , and . The relations are expressed as a ordered pair based on the number of \"presses\" from a specified generator. This the equation becomes (('X0', 5), ('X0', 2)) , becomes (('X1', 1), ('X0', 2)) , becomes (('X2', 1), ('X0', 3)) , and becomes (('X3', 2), ('X3', 0)) .  We can use a similar process to find a presentation for as well with the following code.  y_nodes = [\"Y\"+y for y in [\"p\", \"q\", \"r\", \"s\", \"t\", \"v\", \"u\", \"m\", \"l\", \"w\", \"x\", \"y\", \"z\"]] y_edges = [ (y_nodes[0],y_nodes[2]), (y_nodes[1],y_nodes[2]), (y_nodes[2],y_nodes[4]), (y_nodes[3],y_nodes[4]), (y_nodes[4],y_nodes[5]), (y_nodes[5],y_nodes[6]), (y_nodes[6],y_nodes[3]), (y_nodes[7],y_nodes[8]), (y_nodes[8],y_nodes[7]), (y_nodes[9],y_nodes[10]), (y_nodes[10],y_nodes[11]), (y_nodes[11],y_nodes[9]), (y_nodes[12],y_nodes[11]) ] YG = nx.DiGraph() YG.add_nodes_from(y_nodes) YG.add_edges_from(y_edges) endomap_beta = make_presentation(YG) print(endomap_beta)  The output of the above code is the following presentation:  { 'generators': ['p', 'q', 'z', 'm'], 'relations': [ (('p', 6), ('p', 2)), (('q', 1), ('p', 1)), (('z', 4), ('z', 1)), (('m', 2), ('m', 0)) ] }  Using the notation in the text, our corresponding relations would be , , , and .  It seems like this method would be characterized as depth first search for the presentation. Depending on what order the nodes of the nodes used to express the maps, the above algorithm may produce a different result.  For example, suppose we defined X with the nodes in reverse:  XG2 = nx.DiGraph() x2_nodes = [x_nodes[-1-i] for i in range(len(x_nodes))] print(x2_nodes) XG2.add_nodes_from(x2_nodes) XG2.add_edges_from(x_edges) endomap_alpha_prime = make_presentation(XG2) print(endomap_alpha_prime)  We get the following output:  ['X8', 'X7', 'X6', 'X5', 'X4', 'X3', 'X2', 'X1', 'X0'] Checking node 6 with 0 arrows in Adding root generator X2 Adding follow up node X6: 1 from X2 Adding follow up node X7: 2 from X2 Adding follow up node X5: 3 from X2 next node X6 already has presentation Checking node 7 with 0 arrows in Adding root generator X1 next node X5 already has presentation Checking node 8 with 0 arrows in Adding root generator X0 Adding follow up node X4: 1 from X0 next node X5 already has presentation Checking node 0 with 1 arrows in Only 1 way into node 0 Found potential loop Adding follow up node X3: 1 from X8 next node X8 already has presentation Checking node 1 with 1 arrows in Only 1 way into node 1 already has a presentation Checking node 4 with 1 arrows in Only 1 way into node 4 already has a presentation Checking node 5 with 1 arrows in Only 1 way into node 5 already has a presentation Checking node 2 with 2 arrows in More than 1 way in Checking node 3 with 3 arrows in More than 1 way in { 'generators': ['X2', 'X1', 'X0', 'X8'], 'relations': [ (('X2', 4), ('X2', 1)), (('X1', 1), ('X2', 3)), (('X0', 2), ('X2', 3)), (('X8', 2), ('X8', 0)) ] }  This is an \"equivalent presentation\" for . We have the same generators still, but they're listed in different order and our relations are slightly different. The equivalent expressions are , , , and .  I'm thinking that my task for Exercise 9 will be a little easier if I can standardize my relations and generators in a unified manner that makes these \"equivalent presentations\" easier to identify. I'm wondering if using a \"breadth first search\" instead of a \"depth first search\" might allow me to more readily identify the cylces of each length.   "
},
{
  "id": "session15-p5-5",
  "level": "2",
  "url": "session15-p5.html#session15-p5-5",
  "type": "Example",
  "number": "4.14.2",
  "title": "Exercise 7 (Part 2):.",
  "body": " Exercise 7 (Part 2):   Given my code above, let's review where I got stuck last week and what I think my roadblock is. As mentioned in Exercise 8 above, part of that difficulty was matching up the cycles of matching lengths.    My code from my previous attempt tried to follow my pen-and-paper process as closely as possible. The relevant Python code was as follows:  def get_cycles(endomap): cycles_by_length = {} cycles_by_generator = {} for k,v in enumerate(endomap[\"relations\"]): if v[0][0] == v[1][0]: cl = abs(v[0][1] - v[1][1]) mins = min(v[0][1],v[1][1]) print(f\"{v[0][0]} leads to cycle of length {cl} after {mins} steps\") if not cl in cycles_by_length: cycles_by_length[cl] = { \"primary_generators\":[k], \"secondary_generators\":[] } else: cycles_by_length[cl]['primary_generators'].append(k) cycles_by_generator[v[0][0]] = cl else: cl = cycles_by_generator[v[1][0]] cycles_by_length[cl]['secondary_generators'].append(k) cycles_by_generator[v[0][0]] = cl return { \"cycles_by_length\":cycles_by_length, \"cycles_by_generator\":cycles_by_generator } def iterate_endomap(endomap, start, steps): out_val = start for i in range(steps): out_val = follow_endomap(endomap,out_val) return out_val def make_assignments(gen,poss_vals): output = [] for v in poss_vals: output.append({gen:v}) return output def join_assignments(ass1,ass2): if len(ass1) == 0: return ass2 if len(ass2)<len(ass1): return join_assignments(ass2,ass1) output = [] for a1 in ass1: for a2 in ass2: new_a1 = a1.copy() for k,v in zip(a2.keys(),a2.values()): new_a1[k] = v output.append(new_a1) return output def find_predecessors(endomap,target,steps=1): preds = list(endomap.predecessors(target)) if steps > 1 and len(preds) > 0: r_preds = [] for t in preds: r_preds.extend(find_predecessors(endomap,t,steps-1)) return r_preds else: return preds assignments = [] for idx,rel in enumerate(endomap_alpha['relations']): print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\") x_gen = rel[0][0] print(f'Attempting to match relation on: {x_gen}') cl = alpha_cycles['cycles_by_generator'][x_gen] print(f'Cycle Length: {cl}') y_cycles = alpha_cycles['cycles_by_length'][cl] poss_y_gen = y_cycles['primary_generators']+y_cycles['secondary_generators'] print(f\"Possible Generators: {poss_y_gen}\") print(f\"Attempting to satisfy: {rel}\") rel_lhs = iterate_endomap(XG,rel[0][0],rel[0][1]) rel_rhs = iterate_endomap(XG,rel[1][0],rel[1][1]) print(f\"In X: {rel_lhs} = {rel_rhs}\") for gen in poss_y_gen: print(f\"Testing generator: {gen}\") if rel[0][0]==rel[1][0]: print(\"Trying to match up a loop\") seen_in_Y = set([]) eligible_subs = {} cur_y = endomap_beta['generators'][gen] y_steps = 0 found_pairs = [] while not cur_y in seen_in_Y: lhs = iterate_endomap(YG,cur_y,rel[0][1]) rhs = iterate_endomap(YG,cur_y,rel[1][1]) if lhs == rhs: print(f\"Potential match at {cur_y}! {y_steps} from {gen}\") found_pairs.append(cur_y) seen_in_Y.add(cur_y) y_steps += 1 cur_y = iterate_endomap(YG,cur_y,1) print(f\"Potential matches for {x_gen}: {found_pairs}\") new_assignments = make_assignments(x_gen,found_pairs) print(f\"New assignments: {new_assignments}\") assignments = join_assignments(assignments,new_assignments) print(f\"Joined assignments: {assignments}\") else: print(\"Trying to match up a chain\") new_assignments = [] print(f\"Existing Assignments: {assignments}\") for ass in assignments: print(f\"* Checking {ass}\") if rel[1][0] in ass.keys(): print(f\"\\t Found assignment from {rel[1][0]} to {ass[rel[1][0]]}\") y_target = ass[rel[1][0]] x_lhs = iterate_endomap(XG,rel[0][0],rel[0][1]) print(f\"\\tIn X: {rel[0][1]} steps from {rel[0][0]} is {x_lhs}\") x_rhs = iterate_endomap(XG,rel[1][0],rel[1][1]) print(f\"\\tIn X: {rel[1][1]} steps from {rel[1][0]} is {x_rhs}\") y_rhs = iterate_endomap(YG,y_target,rel[1][1]) print(f\"\\tIn Y: {rel[1][1]} steps from {y_target} is {y_rhs}\") print(f\"\\tThis means {rel[0][0]} needs to map to {y_rhs} after {rel[0][1]} steps\") poss_vals = find_predecessors(YG,y_rhs,rel[0][1]) print(f\"\\tPossible Predecessors: {poss_vals}\") for v in poss_vals: new_ass = ass.copy() new_ass[rel[0][0]] = v print(f\"\\tAdding new assignment: {new_ass}\") new_assignments.append(new_ass) print(\"Done checking old assignments\") print(f\"New assignments({len(new_assignments)}): {new_assignments}\") assignments = new_assignments print(f\"Pre-dupe removal: {len(assignments)}\") remove_dupes = set([str(x) for x in assignments]) print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\") print(f\"Final assignment count: {len(remove_dupes)}\") print(remove_dupes)  The relevant output of which gives me:  Final assignment count: 12 { \"{'X3': 'Ym', 'X0': 'Yw', 'X1': 'Yx', 'X2': 'Yy'}\", \"{'X3': 'Yl', 'X0': 'Yy', 'X1': 'Yw', 'X2': 'Yx'}\", \"{'X3': 'Yl', 'X0': 'Yw', 'X1': 'Yz', 'X2': 'Yy'}\", \"{'X3': 'Ym', 'X0': 'Yy', 'X1': 'Yw', 'X2': 'Yz'}\", \"{'X3': 'Ym', 'X0': 'Yx', 'X1': 'Yy', 'X2': 'Yw'}\", \"{'X3': 'Yl', 'X0': 'Yy', 'X1': 'Yw', 'X2': 'Yz'}\", \"{'X3': 'Ym', 'X0': 'Yy', 'X1': 'Yw', 'X2': 'Yx'}\", \"{'X3': 'Ym', 'X0': 'Yw', 'X1': 'Yz', 'X2': 'Yy'}\", \"{'X3': 'Yl', 'X0': 'Yw', 'X1': 'Yx', 'X2': 'Yy'}\", \"{'X3': 'Ym', 'X0': 'Yz', 'X1': 'Yy', 'X2': 'Yw'}\", \"{'X3': 'Yl', 'X0': 'Yz', 'X1': 'Yy', 'X2': 'Yw'}\", \"{'X3': 'Yl', 'X0': 'Yx', 'X1': 'Yy', 'X2': 'Yw'}\" }  These are precisely the 12 maps I came up with by hand. Not satisfied, I took this one step further with a more exhaustive search on a smaller \"subgraph\" of . Specifically, between the cluster of points around my 3-cycle in to the respective 3-cycle in .  sm_x_nodes = [\"a\", \"b\", \"c\", \" a\", \"^2 a\", \"^3 a\", \"^4 a\"] sm_x_edges = [ (sm_x_nodes[0],sm_x_nodes[3]), (sm_x_nodes[1],sm_x_nodes[4]), (sm_x_nodes[2],sm_x_nodes[5]), (sm_x_nodes[3],sm_x_nodes[4]), (sm_x_nodes[4],sm_x_nodes[5]), (sm_x_nodes[5],sm_x_nodes[6]), (sm_x_nodes[6],sm_x_nodes[4]) ] sm_XG = nx.DiGraph() sm_XG.add_nodes_from(sm_x_nodes) sm_XG.add_edges_from(sm_x_edges) sm_y_nodes = [\"w\",\"x\",\"y\",\"z\"] sm_y_edges = [ (sm_y_nodes[0],sm_y_nodes[1]), (sm_y_nodes[1],sm_y_nodes[2]), (sm_y_nodes[2],sm_y_nodes[0]), (sm_y_nodes[3],sm_y_nodes[2]) ] sm_YG = nx.DiGraph() sm_YG.add_nodes_from(sm_y_nodes) sm_YG.add_edges_from(sm_y_edges) sm_X_alpha = make_presentation(sm_XG) sm_Y_beta = make_presentation(sm_YG) print(sm_X_alpha) print(\"~~~~~~~~~~~~~~~~~~~\") print(sm_Y_beta)  This gives me the following (expected) presentations:  {'generators': ['a', 'b', 'c'], 'relations': [(('a', 5), ('a', 2)), (('b', 1), ('a', 2)), (('c', 1), ('a', 3))]} ~~~~~~~~~~~~~~~~~~~ {'generators': ['z'], 'relations': [(('z', 4), ('z', 1))]}  Given that this aligned with my expectation, I tried to generate ALL maps in . I know that since I'm mapping from a 7 element set to a 4 element set there are possible maps all together. I can then methodically test each map to see if they \"preserve structure\".  def make_all_maps(xs,ys): x_size = len(xs) y_size = len(ys) total = y_size**x_size print(total) all_assignments = [] for x in xs: new_maps = [] for y in ys: new_maps.append({x:y}) all_assignments = join_assignments(all_assignments,new_maps) return all_assignments sm_maps = make_all_maps(sm_x_nodes,sm_y_nodes) def preserves_structure(f,x_graph,y_graph): for k,v in zip(f.keys(),f.values()): #print(f\"f({k}) = {v}\") alpha_x = follow_endomap(x_graph,k) f_alpha_x = f[alpha_x] #print(f\"alpha({k}) = {alpha_x}\") #print(f\"f({alpha_x}) = {f_alpha_x}\") beta_y = follow_endomap(y_graph,v) #print(f\"beta({v}) = {beta_y}\") if beta_y != f_alpha_x: #print(\"fails to preserve structure\") return False return True sm_evaluations = list(filter(lambda x: preserves_structure(x,sm_XG,sm_YG),sm_maps)) print(len(sm_evaluations)) print(sm_evaluations)  Since each of these 6 maps could have either and as options, this essentially confirms the 12 maps I saw earlier.  Where this problem became interesting was when I stopped to consider the question: \"how could I possibly get 7 maps?\". After testing out some variations I came across the following graph which finally \"worked\".  sm_z_nodes = [\"X\"+str(i) for i in range(8)] sm_z_edges = [ (sm_z_nodes[0],sm_z_nodes[3]), (sm_z_nodes[1],sm_z_nodes[4]), (sm_z_nodes[2],sm_z_nodes[5]), (sm_z_nodes[3],sm_z_nodes[4]), (sm_z_nodes[4],sm_z_nodes[5]), (sm_z_nodes[5],sm_z_nodes[6]), (sm_z_nodes[6],sm_z_nodes[4]), (sm_z_nodes[7],sm_z_nodes[0]) ] sm_ZG = nx.DiGraph() sm_ZG.add_nodes_from(sm_z_nodes) sm_ZG.add_edges_from(sm_z_edges) # make my latex easier print(\"\\n\".join([\"(\"+e[0]+\") edge (\"+e[1]+\")\" for e in sm_z_edges])) nx.draw(sm_ZG, with_labels=True, font_weight='bold') my_missing_maps = make_all_maps(sm_z_nodes,sm_y_nodes) missing_map_evaluations = list(filter(lambda x: preserves_structure(x,sm_ZG,sm_YG),my_missing_maps)) print(len(missing_map_evaluations)) print(missing_map_evaluations)   My map      Once run, this gave me the following 7 structure preserving maps:  [ {'X8': 'w', 'X7': 'y', 'X6': 'x', 'X5': 'w', 'X4': 'y', 'X3': 'w', 'X1': 'x', 'X2': 'y'}, {'X8': 'x', 'X7': 'w', 'X6': 'y', 'X5': 'x', 'X4': 'w', 'X3': 'x', 'X1': 'y', 'X2': 'w'}, {'X8': 'x', 'X7': 'w', 'X6': 'y', 'X5': 'x', 'X4': 'w', 'X3': 'z', 'X1': 'y', 'X2': 'w'}, {'X8': 'y', 'X7': 'x', 'X6': 'w', 'X5': 'y', 'X4': 'x', 'X3': 'y', 'X1': 'w', 'X2': 'x'}, {'X8': 'y', 'X7': 'x', 'X6': 'w', 'X5': 'y', 'X4': 'x', 'X3': 'y', 'X1': 'w', 'X2': 'z'}, {'X8': 'z', 'X7': 'w', 'X6': 'y', 'X5': 'x', 'X4': 'w', 'X3': 'x', 'X1': 'y', 'X2': 'w'}, {'X8': 'z', 'X7': 'w', 'X6': 'y', 'X5': 'x', 'X4': 'w', 'X3': 'z', 'X1': 'y', 'X2': 'w'} ]  This got me wondering if I had an object \"0\" with the property needed in the above map and that's when I got really excited by this idea of the objects \"0\" and \"1\" being defined as maps.  The first time I started asking \"is the text wrong\" was way back in Article 1 when we first started counting maps. The discrepancy had to do with the way I was allowing things to be \"undecided\" in my model of a map in a way that the authors had explicitly not. Essentially, I had left as \"undefined\" while the authors had defined , so there was an off-by-one error in how I was counting my maps.  I think I'm implicitly doing the something similar again here. I feel like this mystery point in my map comes from the fact that I have a map that assigns to my generators. You can see this in my code where I use the adjacency matrix of my graph to count the incoming arrows at each node to find potential generators. From there, I had to go through a great deal of messy code to pull a generator out of the loop by iterating through points with exactly one arrow in. I've started to wonder if I should be thinking of \"0\" as a map from the \"empty set\" to \"my generators\" and treat my cycle of two more like a single element.  I've also started thinking about using as an intermediary step between and .   My map      Part of my reasoning is that it seems like there are certain \"natural maps\" based on the structure of the endomap. Once such map is the \"number of incoming arrows map\", as established by the product of my \"ones vector\" with the \"adjacency matrix\". This is an \"objective value\" that can be assigned to each node.   Incoming arrow counts on      Then there's a second \"natural map\" that assigns a value to each node based on \"the number of steps to stabilize\". That is, for any given point , how many times can we apply until we see a point that we've seen before.   Steps to stabilize on      It seems like these two graphs labelings are somehow connected with the presentation of in a way I can't quite articulate yet.  There's one last idea I want to get out my head for the week, and it's this idea that one of my 12 maps is \"special\". Namely, I think the map that assigns has a different interpretation that the others do not. Specifically, I think this map has an \"isomorphism\" with a subset of that would describe as \"the image of under \". Where does it say that the points in can't also be points in ? Maybe that's the missing binary question that produces my two missing maps.   Definitions of and      Once I apply to the points in , each one of the \"tails on the loop\" shortens by 1. If I apply a second time, the tails disappear entirely. Maybe I should be taking exponents of my adjacency matrix instead of trying to break things apart into cycles.   "
},
{
  "id": "session15-p6",
  "level": "1",
  "url": "session15-p6.html",
  "type": "Section",
  "number": "4.15",
  "title": "Session 15: Objectification of Properties, Part 6",
  "body": " Session 15: Objectification of Properties, Part 6  It's been another long week of staring into Jupyter notebooks for hours on end and I still feel like I'm being haunted by those two missing maps.  Having given Exercises 7-9 a good share of time already, it might be time for me to consider moving on and coming back to them later. The hint on Exercise 11 suggests there will be more on presentations in Session 22.   Exercise 9:   ...One can even program a computer....    In all honesty, I don't think this solution is quite there yet, but my code from this week can be found in this Jupyter notebook .  Since I still can't seem to find these missing two maps, there's definitely something I'm missing here. However, what I did manage to accomplish was to restore the original graph structures from the presentations. I also got some much needed practice with Python's generators in the process.  My essential idea was that I could simplify my presentations by ordering the (generator,iteration) pairs in my relations by a single natural number. This was based in part by the proof that the rational numbers are countable.  My idea was that I could form a table with the generators as the columns and powers of the endomap as my rows. By traversing the table along the diagonals, I could ensure that I'm producing each possible relation in a well-defined order.   Traversing generators along diagonals      With a fixed ordering for these elements, the relation could be rewritten as pairs (\"2nd\" iteration of generator \"0\") and (\"1st iteration\" of generator \"1\"), These pairs can be turned into indexes in by using the \"zig-zag\" pattern illustrated above. The pair gets mapped to and the pair gets mapped to .  This was important because it allowed me to ensure that each of my relations was described in such a way that the higher index was always mapped to a lower index. For example, the above relation became a simple Python dictionary entry {4:3} . Without this I was trying to link points to other points that hadn't yet been indexed.  With this in place, I had enough information to reconstruct equivalent definitions of and given only the presentations I produced last week. My map counts are still off by the same two maps I couldn't find in Exercise 7, but the fact that I can reconstruct my maps in this way means any method that would work on the original maps could be still be applied given the presentation.  Obviously the point of the Exercise was that we don't need to reconstruct the maps in this way, but at least this feels like some kind of progress. It allows me to break up the larger endomaps into smaller sub-presentations, develop a \"cluster\" endomap from the sub-presentation, and then compare these \"clusters\" for compatibility. Even if I don't have a full list of maps quite yet, I at least have an algorithm that is consistent with my earlier results.    "
},
{
  "id": "session15-p6-4",
  "level": "2",
  "url": "session15-p6.html#session15-p6-4",
  "type": "Example",
  "number": "4.15.1",
  "title": "Exercise 9:.",
  "body": " Exercise 9:   ...One can even program a computer....    In all honesty, I don't think this solution is quite there yet, but my code from this week can be found in this Jupyter notebook .  Since I still can't seem to find these missing two maps, there's definitely something I'm missing here. However, what I did manage to accomplish was to restore the original graph structures from the presentations. I also got some much needed practice with Python's generators in the process.  My essential idea was that I could simplify my presentations by ordering the (generator,iteration) pairs in my relations by a single natural number. This was based in part by the proof that the rational numbers are countable.  My idea was that I could form a table with the generators as the columns and powers of the endomap as my rows. By traversing the table along the diagonals, I could ensure that I'm producing each possible relation in a well-defined order.   Traversing generators along diagonals      With a fixed ordering for these elements, the relation could be rewritten as pairs (\"2nd\" iteration of generator \"0\") and (\"1st iteration\" of generator \"1\"), These pairs can be turned into indexes in by using the \"zig-zag\" pattern illustrated above. The pair gets mapped to and the pair gets mapped to .  This was important because it allowed me to ensure that each of my relations was described in such a way that the higher index was always mapped to a lower index. For example, the above relation became a simple Python dictionary entry {4:3} . Without this I was trying to link points to other points that hadn't yet been indexed.  With this in place, I had enough information to reconstruct equivalent definitions of and given only the presentations I produced last week. My map counts are still off by the same two maps I couldn't find in Exercise 7, but the fact that I can reconstruct my maps in this way means any method that would work on the original maps could be still be applied given the presentation.  Obviously the point of the Exercise was that we don't need to reconstruct the maps in this way, but at least this feels like some kind of progress. It allows me to break up the larger endomaps into smaller sub-presentations, develop a \"cluster\" endomap from the sub-presentation, and then compare these \"clusters\" for compatibility. Even if I don't have a full list of maps quite yet, I at least have an algorithm that is consistent with my earlier results.   "
},
{
  "id": "session15-p7",
  "level": "1",
  "url": "session15-p7.html",
  "type": "Section",
  "number": "4.16",
  "title": "Session 15: Objectification of Properties, Part 7",
  "body": " Session 15: Objectification of Properties, Part 7  I think I'm at a point where it's time to move forward, so I'm going to try to wrap up this Session as best I can.   Exercise 10:   Find a presentation...    To begin, I labeled the set of points with no incoming points as my generators:   Given diagram with generators      Next, I start labeling nodes by following each generator until I reach a point with more than one incoming arrow. This identifies two relations for the presentation.   Given diagram with generators      So my presentation for this endomap is given by the set of generators with the relations and .  The interesting thing I notice about this is that knowing that no generator appears twice in any relation. This property seems to imply that the resulting graph is \"infinite\". It's also interesting that every point in this graph from on is the same distance from each of the three generators.     Exercise 11:   Think about presentations...    With so much to think about, where do I begin?  I think one of the big ideas that's been floating in my head is that I can represent any finite endomap as a directed graph and I can construct an adjacency matrix that simulates the behavior of the map. If I take an \"eigendecomposition\" of the adjacency matrix, it seems like the \"eigenvalues\" tell me what kinds of \"loops\" I have.  If I calculate the eigenvalues for the used in this session using np.linalg.eig , I get the following list of s: four copies of , two copies of , one instance of and a pair of complex conjugates .  What strikes me as curious about this is that the numbers are what I would describe as \"third roots of unity\". The number defined by has a special property that and . Thus, my 3-cycle in the graph corresponds directly to set of 3 eigenvalues: .  Likewise, is a \"second root of unity\" since . If my cycle of 2 is corresponds with the set , the only unaccounted for eigenvalues left are the 4 copies of . It seems natural that the four values would correspond to the four generators.  It seems this is too big of a coincidence to be true by accident. It makes me wonder if there is some kind of connection here between the eigenvectors of the adjacency matrix and the relations in its presentation.     Exercise 12:   A non-autonomous dynamical system...    Suppose we have two different sequences with the properties that , , and . In order to have there would need to exist some such that   Consider what happens when we evaluate and . Applying our definitions gives us and . Since both expressions are equivalent to , it follows that .  Having established that , consider the case where . It follows from our definitions that . Since , it follows from induction that for all and contradicts our assumption that they were two different maps.     Exercise 7-9 Follow Up   About my \"missing maps\"    I'm still not sure I have a satisfactory answer to this, but I'm starting think it's more closely related to the way we defined \"parity\" on maps using the existence of a fixed point.  As I was exploring the graphs using the adjacency matrix representation, I found it helpful to use a zeroes_vec of the form and ones_vec of the form of the form to assist in ascertaining the properties of the endomap. What was interesting about these was how it allowed me to easily formulate questions about the behavior of all the points in the map at once.  One of the interesting things I noticed was that if was my adjacency matrix, multiplying by was \"commutative\" but my multiplying by was not. More specifically, I found and , which suggests that is essentially a \"fixed point\" when applied on either side. In contrast, only has this property when multiplied on the right. I found that , because each point has exactly one arrow out, but because some points had more than one arrow leading in.  What's interesting about this is that is kind of acting like an idempotent here. Whether we multiple on the left or right, we still get back again. In contrast, is fixed on one side but not the other. This got me thinking about somehow using as a proxy for the \"universal quantifier\" ( and as a proxy for the \"existential quantifier\" ( .  Once I discovered which dimensions are different in , those were the points that I added to my set of generators. One of the tricky parts was that this doesn't give a generator for the cycle of 2. In order to give that point a identifier, I'd need to evaluate the expression . I'll go out on a limb here and suggest that I'd need to examine higher powers of to find generators for larger cycles if they didn't already get identified by a \"tail\".  In essence, I'm thinking that since we can assign a map from points of to that classifies points into \"fixed\" or \"not fixed\" under the operator for every . As long as I enumerate along the \"zig zag\" pattern, I can check this property for every element of to every power of .  Part of being in a category means we need to have an identity map on . The structure preservation property of asserts that . With that in mind, what if I define ? It would follow that would really be the \"image\" of . If that map counts as a new map, there's also the symmetry of the two cycle that could be used to produce another map where the roles of points in the two-cycle have been reversed.  Anything I seem to come up with to explain those missing two maps makes this feel like a \"trick question\" somehow. Perhaps the answers I'm looking for will be illuminated in a later chapter.    And with that, we'll call this session \"complete\".  "
},
{
  "id": "session15-p7-3",
  "level": "2",
  "url": "session15-p7.html#session15-p7-3",
  "type": "Example",
  "number": "4.16.1",
  "title": "Exercise 10:.",
  "body": " Exercise 10:   Find a presentation...    To begin, I labeled the set of points with no incoming points as my generators:   Given diagram with generators      Next, I start labeling nodes by following each generator until I reach a point with more than one incoming arrow. This identifies two relations for the presentation.   Given diagram with generators      So my presentation for this endomap is given by the set of generators with the relations and .  The interesting thing I notice about this is that knowing that no generator appears twice in any relation. This property seems to imply that the resulting graph is \"infinite\". It's also interesting that every point in this graph from on is the same distance from each of the three generators.   "
},
{
  "id": "session15-p7-4",
  "level": "2",
  "url": "session15-p7.html#session15-p7-4",
  "type": "Example",
  "number": "4.16.4",
  "title": "Exercise 11:.",
  "body": " Exercise 11:   Think about presentations...    With so much to think about, where do I begin?  I think one of the big ideas that's been floating in my head is that I can represent any finite endomap as a directed graph and I can construct an adjacency matrix that simulates the behavior of the map. If I take an \"eigendecomposition\" of the adjacency matrix, it seems like the \"eigenvalues\" tell me what kinds of \"loops\" I have.  If I calculate the eigenvalues for the used in this session using np.linalg.eig , I get the following list of s: four copies of , two copies of , one instance of and a pair of complex conjugates .  What strikes me as curious about this is that the numbers are what I would describe as \"third roots of unity\". The number defined by has a special property that and . Thus, my 3-cycle in the graph corresponds directly to set of 3 eigenvalues: .  Likewise, is a \"second root of unity\" since . If my cycle of 2 is corresponds with the set , the only unaccounted for eigenvalues left are the 4 copies of . It seems natural that the four values would correspond to the four generators.  It seems this is too big of a coincidence to be true by accident. It makes me wonder if there is some kind of connection here between the eigenvectors of the adjacency matrix and the relations in its presentation.   "
},
{
  "id": "session15-p7-5",
  "level": "2",
  "url": "session15-p7.html#session15-p7-5",
  "type": "Example",
  "number": "4.16.5",
  "title": "Exercise 12:.",
  "body": " Exercise 12:   A non-autonomous dynamical system...    Suppose we have two different sequences with the properties that , , and . In order to have there would need to exist some such that   Consider what happens when we evaluate and . Applying our definitions gives us and . Since both expressions are equivalent to , it follows that .  Having established that , consider the case where . It follows from our definitions that . Since , it follows from induction that for all and contradicts our assumption that they were two different maps.   "
},
{
  "id": "session15-p7-6",
  "level": "2",
  "url": "session15-p7.html#session15-p7-6",
  "type": "Example",
  "number": "4.16.6",
  "title": "Exercise 7-9 Follow Up.",
  "body": " Exercise 7-9 Follow Up   About my \"missing maps\"    I'm still not sure I have a satisfactory answer to this, but I'm starting think it's more closely related to the way we defined \"parity\" on maps using the existence of a fixed point.  As I was exploring the graphs using the adjacency matrix representation, I found it helpful to use a zeroes_vec of the form and ones_vec of the form of the form to assist in ascertaining the properties of the endomap. What was interesting about these was how it allowed me to easily formulate questions about the behavior of all the points in the map at once.  One of the interesting things I noticed was that if was my adjacency matrix, multiplying by was \"commutative\" but my multiplying by was not. More specifically, I found and , which suggests that is essentially a \"fixed point\" when applied on either side. In contrast, only has this property when multiplied on the right. I found that , because each point has exactly one arrow out, but because some points had more than one arrow leading in.  What's interesting about this is that is kind of acting like an idempotent here. Whether we multiple on the left or right, we still get back again. In contrast, is fixed on one side but not the other. This got me thinking about somehow using as a proxy for the \"universal quantifier\" ( and as a proxy for the \"existential quantifier\" ( .  Once I discovered which dimensions are different in , those were the points that I added to my set of generators. One of the tricky parts was that this doesn't give a generator for the cycle of 2. In order to give that point a identifier, I'd need to evaluate the expression . I'll go out on a limb here and suggest that I'd need to examine higher powers of to find generators for larger cycles if they didn't already get identified by a \"tail\".  In essence, I'm thinking that since we can assign a map from points of to that classifies points into \"fixed\" or \"not fixed\" under the operator for every . As long as I enumerate along the \"zig zag\" pattern, I can check this property for every element of to every power of .  Part of being in a category means we need to have an identity map on . The structure preservation property of asserts that . With that in mind, what if I define ? It would follow that would really be the \"image\" of . If that map counts as a new map, there's also the symmetry of the two cycle that could be used to produce another map where the roles of points in the two-cycle have been reversed.  Anything I seem to come up with to explain those missing two maps makes this feel like a \"trick question\" somehow. Perhaps the answers I'm looking for will be illuminated in a later chapter.   "
},
{
  "id": "session16",
  "level": "1",
  "url": "session16.html",
  "type": "Section",
  "number": "4.17",
  "title": "Session 16: Idempotents, involutions, and graphs",
  "body": " Session 16: Idempotents, involutions, and graphs  It was nice having an organized record of my previous work in Article III to look back on as I went through this section. I think most of the answers described here are \"close enough\" to what I came up with on my own.  Despite there being only one exercise in this session, there's a considerable amount to unpack here. I'm not quite sure how all of this fits together yet, so we'll just have to wait and see.   Exercise 1:   For a given object ...    Before we get too into this, let's start by examining the examples we're asked to consider. Having already solved Session 12 Exercise 3 and Article III Exercise 17, let's review what we learned from each.  Both of these questions deal with a \"gender\" construct, but it's defined a little differently in each.   Comparing \"gender\" structures between Session 12 Exercise 3 and Article 3 Exercise 17      In Session 12 Exercise 3, we defined gender as a map from the set of people, , to a set of genders, . In this situation, we essentially get a pair of \"mother maps\" and \"father maps\" depending on whether they operate in \"people space\" ( ) or \"gender space\" ( ).  In Article 3 Exercise 17, we don't actually describe a set of genders directly, we just subdivide people into sets of males, , and females, , and a set of maps between combinations of those two sets. In this situation, we have pairs of mother and father maps again, but this time these are all effectively in \"people space\" and are differentiated by domain and codomain.  My previously created external diagrams for these exercises are reproduced below.   Comparing commutative diagrams between Session 12 Exercise 3 and Article 3 Exercise 17      So how are these representations connected?  My first observation is that . In this universe where everyone is either male or female, we can think of the \"set of all people\" as a union the \"set of all males\" with the \"set of all females\". We're also assuming implicitly that no one belongs to more than one gender so we also know .  Effectively, the map provides a \"sorting\" of the set of people into these two groups. For every , and .  In Session 12 Exercise 3, we needed two relations to preserve structure. We needed to assert \"the gender of my mother is the gender of my mother's mother\" and to assert \"the gender of my father is the gender of my father's father\".  In Article 3 Exercise 17, we needed a total of 4 relations to preserve structure between these \"gender-like\" structures: , , , and . However, some of these maps are essentially the same if we define them over instead of and using a generalized \"father map\" and \"mother map\" .  Specifically, for any we can define such that for such that and for such that . Likewise, we can define such that for such that and for such that .  Furthermore, the distinction between the pairs and is basically an illusion because and are both really just and are really . The only reason we needed this distinction to begin with was to enforce the condition that \"no person is their own parent\". Equivalently, and . These are both maps with no fixed point .  My hunch is that the authors are trying to reinforce the idea that the existence of fixed points provides a form of parity on maps in a way that behaves similarly to this gender object. Let's return to the commutative diagram we were given at the start of the exercise:   Commutative Triangle in Session 16 Exercise 1      I think this is actually close to one of the ideas I was playing around with in Session 15 where I was using a non-structure preserving map from as an itermediate step to finding the structure preserving maps from .  In this diagram, it looks like is really an endomap on with denoting the \"image\" of under the map . This basically allows us to frame a question about whether or not the the structure of is preserved by the map .  For each pairing of an element and map , we can \"ask\" if . For example, assign if and if . In the same way that we split , we could then split into the union of where and .  I think this brings me to the point in Session 15 where I was confused about how to handle the \"null map\" and \"identity map\". For the \"identity map\", every point is fixed so for every . In contrast, the \"null map\" doesn't have any points so how could it possibly have a fixed point? It seems reasonable to assume . At the same time, the fact that the \"null map\" returns the empty set after being given the empty set also makes seem reasonable as well but that's if and only if we treat the empty set as a object itself.  Let's take another step back to that commutative diagram. We essentially have two paths we could follow to get from to . We can either apply alone or through the composition . This allows use to ask the question: does ?  If the answer is \"yes\" then . If the answer is \"no\" then we must have some counterexample. Namely, . However, we've defined in such a way that either or . Since there's only two choices, that means that where is our \"antipodal map\" given by and . Since and are essentially the same map, these two situtations are equivalent to the relations and .  What happens if we know ? The relation would seem to imply . The other relation gives us . Given that , it would follow that . This basically guarantees that either or .  I'm not really sure where I'm going with this anymore, but I'm reminded of two diagrams I drew while exploring Session 15. It seemed that there were two \"natural\" maps from while I'll present side-by-side for comparison:   \"Incoming arrows\" vs \"Steps to stabilize\" on      I'm beginning to wonder if one of the things I was missing here was that the object is effectively the \"antipodal map\" of the object defined as with the structure .  The reason this seems relevant now is that when I iterate the map by applying a second time, the numbers in both of these diagrams either \"shrink\" or \"stabilize\" like they do the object . If I define , then these natural maps become the following:   \"Incoming arrows\" vs \"Steps to stabilize\" after applying      In fact, after an additional application of both of these graphs stabilize completely into a pair of cycles:   \"Incoming arrows\" vs \"Steps to stabilize\" after applying      Basically, this splitting of \"people into genders\" is analagous to the splitting of \"endomaps into clusters\". Maybe that means that my missing maps in Session 15 are somehow related to the two possible \"common sections\" that assign to the possible generators. Namely, the map which assigns and the map which assigns .  In an effort to wrap this up, what exactly is this category ?  Well, we know is an object in the category . The objects of are described as \"objects of equipped with a given -sorting \", but what does that mean?  I'm thinking that if every object of is some arbitrary graph , we can think of the objects in as being an \"ordered pairs\" such that . Since one of our objects must be the same as , the existence of a corresponding object in is guaranteed by the identity map in since . Maybe it would make sense to define this ensured element as where is a \"common section\" formed by merging the individual sections over all the possible domains .  If those are our objects of , what about our maps? We're told they are \"commutative triangles in \". I'm thinking this means a map in would need to \"preserve structure\" by satisfying the relation for every pair in .  In order to confirm that this is a valid category, we still need to verify the identity and associative laws. Our identity map needs to take an object in and return the same object. It seems like we should get that naturally from our identity map on , leaving us with only the associative property to worry about.  Suppose are both maps in . If and for every pair in , then consider the composition of . For any , the expression could be rewritten as using the associative law from . Since we know and , we can substiute the former to get and then subsitute the latter to get . It follows that for all , which establishes that and confirms that the composition of maps preserves the desired structure.  I have a feeling that a far simpler proof of this probably exists, but we'll call that a wrap for this week.    "
},
{
  "id": "session16-4",
  "level": "2",
  "url": "session16.html#session16-4",
  "type": "Example",
  "number": "4.17.1",
  "title": "Exercise 1:.",
  "body": " Exercise 1:   For a given object ...    Before we get too into this, let's start by examining the examples we're asked to consider. Having already solved Session 12 Exercise 3 and Article III Exercise 17, let's review what we learned from each.  Both of these questions deal with a \"gender\" construct, but it's defined a little differently in each.   Comparing \"gender\" structures between Session 12 Exercise 3 and Article 3 Exercise 17      In Session 12 Exercise 3, we defined gender as a map from the set of people, , to a set of genders, . In this situation, we essentially get a pair of \"mother maps\" and \"father maps\" depending on whether they operate in \"people space\" ( ) or \"gender space\" ( ).  In Article 3 Exercise 17, we don't actually describe a set of genders directly, we just subdivide people into sets of males, , and females, , and a set of maps between combinations of those two sets. In this situation, we have pairs of mother and father maps again, but this time these are all effectively in \"people space\" and are differentiated by domain and codomain.  My previously created external diagrams for these exercises are reproduced below.   Comparing commutative diagrams between Session 12 Exercise 3 and Article 3 Exercise 17      So how are these representations connected?  My first observation is that . In this universe where everyone is either male or female, we can think of the \"set of all people\" as a union the \"set of all males\" with the \"set of all females\". We're also assuming implicitly that no one belongs to more than one gender so we also know .  Effectively, the map provides a \"sorting\" of the set of people into these two groups. For every , and .  In Session 12 Exercise 3, we needed two relations to preserve structure. We needed to assert \"the gender of my mother is the gender of my mother's mother\" and to assert \"the gender of my father is the gender of my father's father\".  In Article 3 Exercise 17, we needed a total of 4 relations to preserve structure between these \"gender-like\" structures: , , , and . However, some of these maps are essentially the same if we define them over instead of and using a generalized \"father map\" and \"mother map\" .  Specifically, for any we can define such that for such that and for such that . Likewise, we can define such that for such that and for such that .  Furthermore, the distinction between the pairs and is basically an illusion because and are both really just and are really . The only reason we needed this distinction to begin with was to enforce the condition that \"no person is their own parent\". Equivalently, and . These are both maps with no fixed point .  My hunch is that the authors are trying to reinforce the idea that the existence of fixed points provides a form of parity on maps in a way that behaves similarly to this gender object. Let's return to the commutative diagram we were given at the start of the exercise:   Commutative Triangle in Session 16 Exercise 1      I think this is actually close to one of the ideas I was playing around with in Session 15 where I was using a non-structure preserving map from as an itermediate step to finding the structure preserving maps from .  In this diagram, it looks like is really an endomap on with denoting the \"image\" of under the map . This basically allows us to frame a question about whether or not the the structure of is preserved by the map .  For each pairing of an element and map , we can \"ask\" if . For example, assign if and if . In the same way that we split , we could then split into the union of where and .  I think this brings me to the point in Session 15 where I was confused about how to handle the \"null map\" and \"identity map\". For the \"identity map\", every point is fixed so for every . In contrast, the \"null map\" doesn't have any points so how could it possibly have a fixed point? It seems reasonable to assume . At the same time, the fact that the \"null map\" returns the empty set after being given the empty set also makes seem reasonable as well but that's if and only if we treat the empty set as a object itself.  Let's take another step back to that commutative diagram. We essentially have two paths we could follow to get from to . We can either apply alone or through the composition . This allows use to ask the question: does ?  If the answer is \"yes\" then . If the answer is \"no\" then we must have some counterexample. Namely, . However, we've defined in such a way that either or . Since there's only two choices, that means that where is our \"antipodal map\" given by and . Since and are essentially the same map, these two situtations are equivalent to the relations and .  What happens if we know ? The relation would seem to imply . The other relation gives us . Given that , it would follow that . This basically guarantees that either or .  I'm not really sure where I'm going with this anymore, but I'm reminded of two diagrams I drew while exploring Session 15. It seemed that there were two \"natural\" maps from while I'll present side-by-side for comparison:   \"Incoming arrows\" vs \"Steps to stabilize\" on      I'm beginning to wonder if one of the things I was missing here was that the object is effectively the \"antipodal map\" of the object defined as with the structure .  The reason this seems relevant now is that when I iterate the map by applying a second time, the numbers in both of these diagrams either \"shrink\" or \"stabilize\" like they do the object . If I define , then these natural maps become the following:   \"Incoming arrows\" vs \"Steps to stabilize\" after applying      In fact, after an additional application of both of these graphs stabilize completely into a pair of cycles:   \"Incoming arrows\" vs \"Steps to stabilize\" after applying      Basically, this splitting of \"people into genders\" is analagous to the splitting of \"endomaps into clusters\". Maybe that means that my missing maps in Session 15 are somehow related to the two possible \"common sections\" that assign to the possible generators. Namely, the map which assigns and the map which assigns .  In an effort to wrap this up, what exactly is this category ?  Well, we know is an object in the category . The objects of are described as \"objects of equipped with a given -sorting \", but what does that mean?  I'm thinking that if every object of is some arbitrary graph , we can think of the objects in as being an \"ordered pairs\" such that . Since one of our objects must be the same as , the existence of a corresponding object in is guaranteed by the identity map in since . Maybe it would make sense to define this ensured element as where is a \"common section\" formed by merging the individual sections over all the possible domains .  If those are our objects of , what about our maps? We're told they are \"commutative triangles in \". I'm thinking this means a map in would need to \"preserve structure\" by satisfying the relation for every pair in .  In order to confirm that this is a valid category, we still need to verify the identity and associative laws. Our identity map needs to take an object in and return the same object. It seems like we should get that naturally from our identity map on , leaving us with only the associative property to worry about.  Suppose are both maps in . If and for every pair in , then consider the composition of . For any , the expression could be rewritten as using the associative law from . Since we know and , we can substiute the former to get and then subsitute the latter to get . It follows that for all , which establishes that and confirms that the composition of maps preserves the desired structure.  I have a feeling that a far simpler proof of this probably exists, but we'll call that a wrap for this week.   "
},
{
  "id": "session17",
  "level": "1",
  "url": "session17.html",
  "type": "Section",
  "number": "4.18",
  "title": "Session 17: Some uses of graphs",
  "body": " Session 17: Some uses of graphs  This week's reading started with the discussion of a simple game, so I kind of started this week by implementing it in Javascript using React . If you want to see how it works, the source code is available here . Looking back over my code, it's kind of funny how obvious it is that my Javascript was derived from a Python implementation.  Maybe I'll come back to this later and see if I can \"solve the game\" also, but for now I'll just settle for solving the exercises to see how they might be related to that task.   Exercise 1:   ...have a terminal object?    Our given diagrams are reconstructed below:   Diagrams for Sesssion 17 Exercise 1      One part of this problem that's a little unclear at the moment is how exactly we're defining \"terminal object\". Given the context, I'm guessing it means that there is a path from every point in the graph to the terminal object.  The other part that's confusing is how we're handling self-loops. Since every \"point\" in the graph can be thought of as a self-loop, it makes sense to treat each point as a having a path of length 0. Even though has an explicit map to itself and does not, I'm thinking we still need to treat both of them as \"terminal objects\" in order to properly identify paths of length 0.  If I treat as terminal object in (a) and treat as a terminal object in (b), then it would make sense to identify as a terminal point in (c) even though the loop at this point is not explicitly shown. There's a path of length 0 from to itself, paths of length 1 from or , and paths of length 2 from or .  In graph (d), I'm thinking it makes the most sense to identify both and as terminal points. My reasoning is that the existence of a path of length 0 from to itself and path of length 1 from means that is terminal, while likewise has a 0 length path to itself and a path of length 1 from . The fact that we can follow the loop to potentially make longer paths is irrelevant.  In (e), it seems that would be the lone terminal object. We have two paths of length 1 from to and an implicit path of length 0 from to itself. There is no path that starts at and ends at so that would disqualify as a terminal point.  In (f), my definition of terminal object would imply that no such element exists here. There is no path from to or vice versa. This seems very similar to the situation we saw in the last exercise of Session 11.     Exercise 2:   Show that a diagram of shape commutes...    Let's start by naming the objects in the diagram as if they were maps: . These two maps are inverses if and only if and .  So what does it mean for the shape to commute? I'm thinking that it means we need to enforce and . This seemed most clear if I expanded my maps into the following external diagrams:   Diagrams for Sesssion 17 Exercise 1      In these situations, we can follow the arrow directly from the top left to top right or we can travel \"down and around\". Saying it \"commutes\" means we'll get the same result no matter which path we take.  Given that we have maps satisfying and , can we use that information to establish and ? It's clear that we can apply on the left to show and apply on the left to show but the converse isn't so straight forward.  Suppose . We'd need to have some elements with the property that . Apply of the left of both sides to get . Since our definition of \"commute\" establishes we get a contradiction . It follows that , and we can use an analogous argument to show .     Exercise 3:   In the diagram...    Let's assume we're given nothing more than the three equations: , , . If follows from the associative property that   . Thus, .  This seems almost too easy, but I'll take it.     Exercise 4:   For each of these diagrams...    I think we'll actually need the diagrams for these:   Diagrams for Sesssion 17 Exercise 1      In (a), it looks like we have two paths from to and two paths from to . To make the paths from to commute we'd need . To make the paths from to commute we'd need .  In (b), we have a cycle of 3 which means we can start and end at any of , and . It shouldn't matter how many times we loop around, so any subsequent loop should be the original. Therefore, the cycle for corresponds with the relation , the cycle for corresponds with , and the cycle for corresponds with .  Are these equations the \"minimal\" ones? I'm not sure yet. Part of me originally wanted to make the cycle to be equal to the identity map, but my experiences with sturcture preserving maps in Session 15 lead me to believe that's not true. Obviously, something like would imply that , but there's no assurance that we don't lose points from when we first apply .  In (c), I'm thinking that the additional map between and gives us an additional path for each of the 3-cycles. Namely:   Furthermore, the explicit self-loop at seems to imply that and because we can freely choose to take or not take at our discretion.  So how do I know I covered them all? I'm thinking we could come up with a way to enumerate all possible paths of a given length, and then use the relations to simplify any path longer than the minimal one.  Let's start by considering the case in (a). We have precisely two paths of length 0, corresponding to the points and respectively. We have three paths of length 1, one starting at and two starting at , which directly correspond to our three maps . Once we step up to paths of length 2, our relations reduce the four possible sequences down to two equivalence classes. Any longer path would need to be formed by a composition of these building blocks. Specifically, for , any path of lenth will reduce to if it starts and ends at or if it starts and ends at . For a path of length , the start and end be different points but we can still simplify the path by taking out the loops of 2. It doesn't matter how many times it loops because both loops are idempotent.  I think the case in (b) follows quite similarly. We've got 3 paths of length 0 corresponding to , three paths of length 1 corresponding to , three paths of length 2 corresponding to the compositions , and three paths of length 3 corresponding to the 3 relations. Since every length can be expressed as for some and , every path can be thought of as having one of the 3-cycles in our relations repeated times followed by a path of length 1 or 2.  It's not quite as clear how this works in (c) because the self loop at means we have potentially have cycles of almost any length. This means we're going to have to take extra care to keep track of the domain and codomain relative to how we approached (a). We still have 3 paths of length 0 that start and end at and 5 paths of length 1 for each map . Where this gets weird is when we look at paths of length two. In addition to having two pairs of equivalent two-step paths ( and ) we also have a two-step path which is equal to the one step path and likewise for .  I'm thinking this map is kind of like a pit-stop in a car race. If we subtract out all the time we spend in pit-stops, what time remains is the time we spend on the track. If take the length of a path, subtract the number of times we apply , what remains would be the number of steps we spend looping around our 3-cycle. Each time we loop we have two choices of path, but our relations enforce the fact that repeated loops are equivalent. I'm thinking that there are 4 unique 4 step paths from to , namely , , , and . Any path containing more than 4 steps must be some composition of the smaller paths we've already established.  Coming back to the question of \"minimal equations\", perhaps something can be done to simplify these cycles for (c). If I include the relations and , then maybe I don't need as many equations to path out all the 3-cycles. For example, knowing and would automatically imply .    "
},
{
  "id": "session17-4",
  "level": "2",
  "url": "session17.html#session17-4",
  "type": "Problem",
  "number": "4.18.1",
  "title": "Exercise 1:.",
  "body": " Exercise 1:   ...have a terminal object?    Our given diagrams are reconstructed below:   Diagrams for Sesssion 17 Exercise 1      One part of this problem that's a little unclear at the moment is how exactly we're defining \"terminal object\". Given the context, I'm guessing it means that there is a path from every point in the graph to the terminal object.  The other part that's confusing is how we're handling self-loops. Since every \"point\" in the graph can be thought of as a self-loop, it makes sense to treat each point as a having a path of length 0. Even though has an explicit map to itself and does not, I'm thinking we still need to treat both of them as \"terminal objects\" in order to properly identify paths of length 0.  If I treat as terminal object in (a) and treat as a terminal object in (b), then it would make sense to identify as a terminal point in (c) even though the loop at this point is not explicitly shown. There's a path of length 0 from to itself, paths of length 1 from or , and paths of length 2 from or .  In graph (d), I'm thinking it makes the most sense to identify both and as terminal points. My reasoning is that the existence of a path of length 0 from to itself and path of length 1 from means that is terminal, while likewise has a 0 length path to itself and a path of length 1 from . The fact that we can follow the loop to potentially make longer paths is irrelevant.  In (e), it seems that would be the lone terminal object. We have two paths of length 1 from to and an implicit path of length 0 from to itself. There is no path that starts at and ends at so that would disqualify as a terminal point.  In (f), my definition of terminal object would imply that no such element exists here. There is no path from to or vice versa. This seems very similar to the situation we saw in the last exercise of Session 11.   "
},
{
  "id": "session17-5",
  "level": "2",
  "url": "session17.html#session17-5",
  "type": "Problem",
  "number": "4.18.3",
  "title": "Exercise 2:.",
  "body": " Exercise 2:   Show that a diagram of shape commutes...    Let's start by naming the objects in the diagram as if they were maps: . These two maps are inverses if and only if and .  So what does it mean for the shape to commute? I'm thinking that it means we need to enforce and . This seemed most clear if I expanded my maps into the following external diagrams:   Diagrams for Sesssion 17 Exercise 1      In these situations, we can follow the arrow directly from the top left to top right or we can travel \"down and around\". Saying it \"commutes\" means we'll get the same result no matter which path we take.  Given that we have maps satisfying and , can we use that information to establish and ? It's clear that we can apply on the left to show and apply on the left to show but the converse isn't so straight forward.  Suppose . We'd need to have some elements with the property that . Apply of the left of both sides to get . Since our definition of \"commute\" establishes we get a contradiction . It follows that , and we can use an analogous argument to show .   "
},
{
  "id": "session17-6",
  "level": "2",
  "url": "session17.html#session17-6",
  "type": "Problem",
  "number": "4.18.5",
  "title": "Exercise 3:.",
  "body": " Exercise 3:   In the diagram...    Let's assume we're given nothing more than the three equations: , , . If follows from the associative property that   . Thus, .  This seems almost too easy, but I'll take it.   "
},
{
  "id": "session17-7",
  "level": "2",
  "url": "session17.html#session17-7",
  "type": "Problem",
  "number": "4.18.6",
  "title": "Exercise 4:.",
  "body": " Exercise 4:   For each of these diagrams...    I think we'll actually need the diagrams for these:   Diagrams for Sesssion 17 Exercise 1      In (a), it looks like we have two paths from to and two paths from to . To make the paths from to commute we'd need . To make the paths from to commute we'd need .  In (b), we have a cycle of 3 which means we can start and end at any of , and . It shouldn't matter how many times we loop around, so any subsequent loop should be the original. Therefore, the cycle for corresponds with the relation , the cycle for corresponds with , and the cycle for corresponds with .  Are these equations the \"minimal\" ones? I'm not sure yet. Part of me originally wanted to make the cycle to be equal to the identity map, but my experiences with sturcture preserving maps in Session 15 lead me to believe that's not true. Obviously, something like would imply that , but there's no assurance that we don't lose points from when we first apply .  In (c), I'm thinking that the additional map between and gives us an additional path for each of the 3-cycles. Namely:   Furthermore, the explicit self-loop at seems to imply that and because we can freely choose to take or not take at our discretion.  So how do I know I covered them all? I'm thinking we could come up with a way to enumerate all possible paths of a given length, and then use the relations to simplify any path longer than the minimal one.  Let's start by considering the case in (a). We have precisely two paths of length 0, corresponding to the points and respectively. We have three paths of length 1, one starting at and two starting at , which directly correspond to our three maps . Once we step up to paths of length 2, our relations reduce the four possible sequences down to two equivalence classes. Any longer path would need to be formed by a composition of these building blocks. Specifically, for , any path of lenth will reduce to if it starts and ends at or if it starts and ends at . For a path of length , the start and end be different points but we can still simplify the path by taking out the loops of 2. It doesn't matter how many times it loops because both loops are idempotent.  I think the case in (b) follows quite similarly. We've got 3 paths of length 0 corresponding to , three paths of length 1 corresponding to , three paths of length 2 corresponding to the compositions , and three paths of length 3 corresponding to the 3 relations. Since every length can be expressed as for some and , every path can be thought of as having one of the 3-cycles in our relations repeated times followed by a path of length 1 or 2.  It's not quite as clear how this works in (c) because the self loop at means we have potentially have cycles of almost any length. This means we're going to have to take extra care to keep track of the domain and codomain relative to how we approached (a). We still have 3 paths of length 0 that start and end at and 5 paths of length 1 for each map . Where this gets weird is when we look at paths of length two. In addition to having two pairs of equivalent two-step paths ( and ) we also have a two-step path which is equal to the one step path and likewise for .  I'm thinking this map is kind of like a pit-stop in a car race. If we subtract out all the time we spend in pit-stops, what time remains is the time we spend on the track. If take the length of a path, subtract the number of times we apply , what remains would be the number of steps we spend looping around our 3-cycle. Each time we loop we have two choices of path, but our relations enforce the fact that repeated loops are equivalent. I'm thinking that there are 4 unique 4 step paths from to , namely , , , and . Any path containing more than 4 steps must be some composition of the smaller paths we've already established.  Coming back to the question of \"minimal equations\", perhaps something can be done to simplify these cycles for (c). If I include the relations and , then maybe I don't need as many equations to path out all the 3-cycles. For example, knowing and would automatically imply .   "
},
{
  "id": "session18",
  "level": "1",
  "url": "session18.html",
  "type": "Section",
  "number": "4.19",
  "title": "Session 18: Review of Test 2",
  "body": " Session 18: Review of Test 2  Happy New Year!  I worked Test 2 out on paper first, but I simply couldn't resist the looking at the review. I think I'm going to keep that separate for now, but have an idea of what I want to do with it. Stay tuned.  I am, however, going to do a self-reflection on Test 2 in a problem block below. I always told my students how it's an important part of the learning process, so it's only fair I practice it myself.   Test 2, Problem (1)   ...fixed point...    I think my solution is \"close enough\" to Danilo's, but I did leave out the parentheses where I thought they were obvious. A picky professor might ding me on that I suppose.  To include or not to include? It's hard to write math not knowing who the target audience is sometimes. Assuming the associative property implies that the parentheses don't matter, but putting the explicit parentheses in makes the substitution a little clearer.     Test 2, Problem (3)   Find an example...    I think I made the same \"mistake\" as Katie did here and should have explicitly tested every point. Calling out that everyone's diagram looked the same was a nice touch too.  The natural sequence of diagrams here was very interesting, and reminds me of some of the diagram sequences I drew in Session 16 only backwards.     Test 2, Problem (2)   Find all maps...    On the bright side, I found the correct number of of maps and I know at 3 out of my 4 maps are correct. Had I not spent a whole month on Session 15, I probably wouldn't have found the fourth, so it's nice to have some validation that I'm on the right track.  Had this been an actual test, I probably would have tripped up on this one and run out of time. I worked through a page and a half before I realized I had confused \"irreflexive graphs\" with \"reflexive graphs\". Furthermore, my approach of proving that and through \"giant tables\" isn't a very test-friendly strategy.    "
},
{
  "id": "session18-5",
  "level": "2",
  "url": "session18.html#session18-5",
  "type": "Problem",
  "number": "4.19.1",
  "title": "Test 2, Problem (1).",
  "body": " Test 2, Problem (1)   ...fixed point...    I think my solution is \"close enough\" to Danilo's, but I did leave out the parentheses where I thought they were obvious. A picky professor might ding me on that I suppose.  To include or not to include? It's hard to write math not knowing who the target audience is sometimes. Assuming the associative property implies that the parentheses don't matter, but putting the explicit parentheses in makes the substitution a little clearer.   "
},
{
  "id": "session18-6",
  "level": "2",
  "url": "session18.html#session18-6",
  "type": "Problem",
  "number": "4.19.2",
  "title": "Test 2, Problem (3).",
  "body": " Test 2, Problem (3)   Find an example...    I think I made the same \"mistake\" as Katie did here and should have explicitly tested every point. Calling out that everyone's diagram looked the same was a nice touch too.  The natural sequence of diagrams here was very interesting, and reminds me of some of the diagram sequences I drew in Session 16 only backwards.   "
},
{
  "id": "session18-7",
  "level": "2",
  "url": "session18.html#session18-7",
  "type": "Problem",
  "number": "4.19.3",
  "title": "Test 2, Problem (2).",
  "body": " Test 2, Problem (2)   Find all maps...    On the bright side, I found the correct number of of maps and I know at 3 out of my 4 maps are correct. Had I not spent a whole month on Session 15, I probably wouldn't have found the fourth, so it's nice to have some validation that I'm on the right track.  Had this been an actual test, I probably would have tripped up on this one and run out of time. I worked through a page and a half before I realized I had confused \"irreflexive graphs\" with \"reflexive graphs\". Furthermore, my approach of proving that and through \"giant tables\" isn't a very test-friendly strategy.   "
},
{
  "id": "article4",
  "level": "1",
  "url": "article4.html",
  "type": "Section",
  "number": "5.1",
  "title": "Article 4: Universal Mapping Properties",
  "body": " Article 4: Universal Mapping Properties  Yay for concrete definitions! We encountered these \"terminal objects\" back in Session 17 and I wasn't sure how to articulate it back then. I do find it interesting that we're defining \"terminal objects\" before \"initial objects\". It seems a little backwards, but maybe there's a reason for it that I don't quite see yet.   Exercise 1:    has one point...   The lack of a question means we're proving the given statement, so let's peice together what we've been given.  Our point is defined as a -map , where is a terminal object in . By the definition of terminal object, there exists exactly one -map for each object of . To help keep these ideas separate, let's call the point and the \"terminal map\" .  If we have some arbitrary map , then we should be able to compose this map with our \"point map\". Namely, if we have a map in our category then our composition should also be in the category. This effectively gives us a map since we have .  So how do we prove is a point? I think we basically already have done so by establishing the existance of a map through composition. We might have to also prove that there's a corresponding map too, which I think we can effectively do by following the arrows backwards since each of these single element sets are isomorphic to every other one by the \"Uniqueness of Terminal Objects\" theorem.  I think we're effectively splitting the domain up into points. If we have a map , this terminal object lets us break apart into a bunch of individual points , and consequently allows us to break up into smaller maps where the domain and codomain are both single element sets. For any map , each point in could be used to construct a map . Each such \"mini-map\" must be invertable, so there's precisely one map from to and it's given by the composition .     Exercise 2:   In the category of abstract sets...    I'm thinking that this is actually a special case of Exercise 1 where and . If we have a point , that implies the existance of a map . If we compose this map with the identity map, the result should also be a point in since the category is closed under the composition .  Since is a point of , there must be a unique -map . If we take this map and compose it with , then the result should also be a -map.  In other words, the requirement of an identity map in our category ensures that these maps are unique. Since we have a sequence of maps , it also should follow that the composite is also in our category. Note that and since we're using the identity map.  I suppose the part we haven't addressed yet is the uniqueness property. If we had a point of that points to two different elements of , then we don't have a well-defined \"map\" because each point of a map can only point to one value. On the other hand, if we had two points that both point to some point then is not really a point because the map needs to be unique by the definition of as a terminal object.     Exercise 3:   In the category of discrete dynamical systems...   So now we don't just have a set alone, but one that's also equipped with an endomap . If this set has a terminal object , that implies the existence of exactly one -map for each element in . However, since there's only one element in the only possible endomap on is the identity map . It follows from the structure preserving property of that , and substituting gives us .  Effectively, this map must be invariate with respect to the operation . If is a fixed point under , then it's obvious that will hold true because . If is not a fixed point, then implies that is a different point in and must have it's own unique map such that .     Exercise 4:   In the category of (irreflexive) graphs...   In this category, an -map requires that both \"source and target\" must be preserved. Namely, and . If the codomain of any such a map is a one-element space , then the only possible choice for of maps for and is .  It follows that and . This, in turn, implies that for every \"point\" . In other words, each \"point\" in refers to a \"dot\" which is both the source and target of an \"arrow\". Such points are effectively our \"self-loops\" in .  I'm a little uncertain about this actually. I was expecting to see a loop of multiple points rather than something that looks like a fixed point.     Exercise 5:   The terminal object in ...    Suppose we have a pair of maps , and each point has the property that .  It seems like the fact that is self-evident to a degree. Two maps are the same if the domains and codomains are the same, and they agree on the value of each possible input. We already established that being a point in means that and are necessarily points in .  So why would this fail in or ? I'd suspect it has something to do with the way the our dots can degenerate into arrows. Consider the following endomap:   A simple endomap      If we take each of the \"points\" and replace them with an \"self-loop\", we'd get something like this:   A simple endomap      I think the problem here arises when we try to distinguish between the self-loop that \"is\" and the self-loop that connects to itself. We've defined terminal objects in such a way that there would be exactly one map from , but here we essentially have two different arrows which both have a source of and a target of .  This has got me second guessing my answers to Session 17 Exercise 1. I'm starting to wonder if I was supposed to classify (b) is terminal but (a) as not, because (a) admits a loop that (b) doesn't.    "
},
{
  "id": "article4-3",
  "level": "2",
  "url": "article4.html#article4-3",
  "type": "Example",
  "number": "5.1.1",
  "title": "Exercise 1:.",
  "body": " Exercise 1:    has one point...   The lack of a question means we're proving the given statement, so let's peice together what we've been given.  Our point is defined as a -map , where is a terminal object in . By the definition of terminal object, there exists exactly one -map for each object of . To help keep these ideas separate, let's call the point and the \"terminal map\" .  If we have some arbitrary map , then we should be able to compose this map with our \"point map\". Namely, if we have a map in our category then our composition should also be in the category. This effectively gives us a map since we have .  So how do we prove is a point? I think we basically already have done so by establishing the existance of a map through composition. We might have to also prove that there's a corresponding map too, which I think we can effectively do by following the arrows backwards since each of these single element sets are isomorphic to every other one by the \"Uniqueness of Terminal Objects\" theorem.  I think we're effectively splitting the domain up into points. If we have a map , this terminal object lets us break apart into a bunch of individual points , and consequently allows us to break up into smaller maps where the domain and codomain are both single element sets. For any map , each point in could be used to construct a map . Each such \"mini-map\" must be invertable, so there's precisely one map from to and it's given by the composition .   "
},
{
  "id": "article4-4",
  "level": "2",
  "url": "article4.html#article4-4",
  "type": "Example",
  "number": "5.1.2",
  "title": "Exercise 2:.",
  "body": " Exercise 2:   In the category of abstract sets...    I'm thinking that this is actually a special case of Exercise 1 where and . If we have a point , that implies the existance of a map . If we compose this map with the identity map, the result should also be a point in since the category is closed under the composition .  Since is a point of , there must be a unique -map . If we take this map and compose it with , then the result should also be a -map.  In other words, the requirement of an identity map in our category ensures that these maps are unique. Since we have a sequence of maps , it also should follow that the composite is also in our category. Note that and since we're using the identity map.  I suppose the part we haven't addressed yet is the uniqueness property. If we had a point of that points to two different elements of , then we don't have a well-defined \"map\" because each point of a map can only point to one value. On the other hand, if we had two points that both point to some point then is not really a point because the map needs to be unique by the definition of as a terminal object.   "
},
{
  "id": "article4-5",
  "level": "2",
  "url": "article4.html#article4-5",
  "type": "Example",
  "number": "5.1.3",
  "title": "Exercise 3:.",
  "body": " Exercise 3:   In the category of discrete dynamical systems...   So now we don't just have a set alone, but one that's also equipped with an endomap . If this set has a terminal object , that implies the existence of exactly one -map for each element in . However, since there's only one element in the only possible endomap on is the identity map . It follows from the structure preserving property of that , and substituting gives us .  Effectively, this map must be invariate with respect to the operation . If is a fixed point under , then it's obvious that will hold true because . If is not a fixed point, then implies that is a different point in and must have it's own unique map such that .   "
},
{
  "id": "article4-6",
  "level": "2",
  "url": "article4.html#article4-6",
  "type": "Example",
  "number": "5.1.4",
  "title": "Exercise 4:.",
  "body": " Exercise 4:   In the category of (irreflexive) graphs...   In this category, an -map requires that both \"source and target\" must be preserved. Namely, and . If the codomain of any such a map is a one-element space , then the only possible choice for of maps for and is .  It follows that and . This, in turn, implies that for every \"point\" . In other words, each \"point\" in refers to a \"dot\" which is both the source and target of an \"arrow\". Such points are effectively our \"self-loops\" in .  I'm a little uncertain about this actually. I was expecting to see a loop of multiple points rather than something that looks like a fixed point.   "
},
{
  "id": "article4-7",
  "level": "2",
  "url": "article4.html#article4-7",
  "type": "Example",
  "number": "5.1.5",
  "title": "Exercise 5:.",
  "body": " Exercise 5:   The terminal object in ...    Suppose we have a pair of maps , and each point has the property that .  It seems like the fact that is self-evident to a degree. Two maps are the same if the domains and codomains are the same, and they agree on the value of each possible input. We already established that being a point in means that and are necessarily points in .  So why would this fail in or ? I'd suspect it has something to do with the way the our dots can degenerate into arrows. Consider the following endomap:   A simple endomap      If we take each of the \"points\" and replace them with an \"self-loop\", we'd get something like this:   A simple endomap      I think the problem here arises when we try to distinguish between the self-loop that \"is\" and the self-loop that connects to itself. We've defined terminal objects in such a way that there would be exactly one map from , but here we essentially have two different arrows which both have a source of and a target of .  This has got me second guessing my answers to Session 17 Exercise 1. I'm starting to wonder if I was supposed to classify (b) is terminal but (a) as not, because (a) admits a loop that (b) doesn't.   "
},
{
  "id": "article4-p2",
  "level": "1",
  "url": "article4-p2.html",
  "type": "Section",
  "number": "5.2",
  "title": "Article 4: Universal Mapping Properties, Part 2",
  "body": " Article 4: Universal Mapping Properties, Part 2  We resume this week with \"separating\".   Exercise 6:   Show that in the category ...    The very heavy-handed \"hint\" suggests that our mystery object is most likely related to or maybe even .  Further, I'd expect that we're going to somehow need this theorem that any two graphs and maps , we have the property that if for all and then .  Consider a pair of -maps . By definition, these must satisfy and and . As endomaps, and require that each \"dot\" gets assigned exactly one \"arrow\". Thus, we can effectively use this to split up \"objects\" of into the union of some \"dots\" and \"arrows\" with a 1-1 correspondence.  In Session 15, we established an isomorphism between maps in and maps in through the process of \"evaluation at 0\" and \"iteration\". We defined \"iteration\" as assigning to each a map given by .   Iteration and evaluation defined      This is relevant because we now also know that having a \"point in \" and a \"map\" necessarily gives us a \"point in \" given by . Now that we have the addition of an endomap , we can define \"sequences\" of points by iterating like so:     If this sequence goes on producing new points forever without repeating, then this element is essentially the object . This the pattern is finite, then there must be some element where it repeats. Instead of simply separating our space into \"dots and arrows\" like we did in , in we separate into \"loops and tails\".  Maybe the key here is the sort of \"antipodal\" relationship between and . if we think of there existing a map from that swaps the operations and . If I consider the \"number of steps to stabilize\" as a map from , then a point can be either a \"tail\", in which case , or a \"loop\", in which case . Every \"tail\" (with the exception of ) must have a \"loop\" that acts as a terminal object, and we can establish a sorting of those loops by length.  More specifically though, what I've been called \"tails\" if the endomap are more like a \"tree\" structure. They might have multiple branches unlike the example from Session 15. What matters is that we have a 1-1 correspondence between these trees and the element of a fixed length cycle. Trees are nice because we have an easily established notion of \"depth\" that maps to a natural number.  Perhaps I'm approaching this from the wrong angle. What if there exists a way to enumerate all the possible endomaps ?  We've already established that we can construct a presentation for by sectioning out a set of elements as \"generators\" combined with a set of \"relations\" between those generators.  Our object was defined by a single generator, , and no relations. What would the presentation of our object look like?  Let's call this endomap(?) . There's something close to an isomorphism between and . For each in , we have and . We can easily say that but I'm not sure we can assert The problem is that we need to preserve but is undefined because .  It's almost as if has a presentation with an infinite number of generators. For each object we can associate a respective graph that approaches the behavior of as .     In this context, it makes sense to think of and to \"complete\" the natural numbers.  Let's back this up for a second. Suppose we have an arbitrary . We can define a \"section\" in by assigning to every \"terminal object\" and otherwise. In those terminal objects are \"loops\". If it's not a terminal object, it either has to \"go on forever\" which would effectively map it to or it has to repeat in a cycle of some fixed length. Let's call the cycle of length defined by the behavior of . If we want, we can effectively treat the object as and as .  This gives a means of locating our objects in by means of a cartesian product in of a generator and number of steps of . Each point in the can be represented by an ordered pair where is the terminal object it converges to a cycle of and is a -step path in a tree which leads to a unique \"root\" element in the cycle.  In Session 15, I started calling these different subsections of our graphs \"clusters\". The idea was that there only exists structure preserving maps between clusters that converge to loops of the same size. I'm not sure if I really answered this question here, but those \"clusters\" essentially performed the function of separating graph maps.  This exercise got me thinking about where I left off on Session 15, so I decided to spend the rest of the week exploring the \"minimal categories\" that were presented there with Python. You can find my code this week here .  I observed some of the interesting things while doing this were. First, I realized I had to keep close tabs on the domain and codomain of each map. I was representing maps as dictionaries, so sometimes two objects would have the same key and value pairs but were techincally different objects because they came from different sets.  The other thing I noticed was that I seemed to be able to separate out a subset of maps that could be used to form the others through composition. It seemed that I'm able to express all maps in a category from compositions of some \"points\", \"terminators\", and \"loops\". Since those \"loops\" correspond to structure preserving maps from , this would seem to support my theory that this is, in fact, the object I was looking for in this exercise.  This exercise seems to have left me with more questions than answered. It seemed odd how my minimal categories blurred the distinctions between \"sets\", \"points\", and \"maps\". I'm reminded of how, in Session 16, the authors used as an extension of in order to utilize the inverse operation. It seems like this mirrors what I was trying to accomplish by mapping between and . It's almost like I need to step out from to , solve the problem there, then come back and verify that the solution is something that still exists in .    Despite only making it through the one exercise, I feel like I learned a lot this week by going off on tangents.  "
},
{
  "id": "article4-p2-3",
  "level": "2",
  "url": "article4-p2.html#article4-p2-3",
  "type": "Example",
  "number": "5.2.1",
  "title": "Exercise 6:.",
  "body": " Exercise 6:   Show that in the category ...    The very heavy-handed \"hint\" suggests that our mystery object is most likely related to or maybe even .  Further, I'd expect that we're going to somehow need this theorem that any two graphs and maps , we have the property that if for all and then .  Consider a pair of -maps . By definition, these must satisfy and and . As endomaps, and require that each \"dot\" gets assigned exactly one \"arrow\". Thus, we can effectively use this to split up \"objects\" of into the union of some \"dots\" and \"arrows\" with a 1-1 correspondence.  In Session 15, we established an isomorphism between maps in and maps in through the process of \"evaluation at 0\" and \"iteration\". We defined \"iteration\" as assigning to each a map given by .   Iteration and evaluation defined      This is relevant because we now also know that having a \"point in \" and a \"map\" necessarily gives us a \"point in \" given by . Now that we have the addition of an endomap , we can define \"sequences\" of points by iterating like so:     If this sequence goes on producing new points forever without repeating, then this element is essentially the object . This the pattern is finite, then there must be some element where it repeats. Instead of simply separating our space into \"dots and arrows\" like we did in , in we separate into \"loops and tails\".  Maybe the key here is the sort of \"antipodal\" relationship between and . if we think of there existing a map from that swaps the operations and . If I consider the \"number of steps to stabilize\" as a map from , then a point can be either a \"tail\", in which case , or a \"loop\", in which case . Every \"tail\" (with the exception of ) must have a \"loop\" that acts as a terminal object, and we can establish a sorting of those loops by length.  More specifically though, what I've been called \"tails\" if the endomap are more like a \"tree\" structure. They might have multiple branches unlike the example from Session 15. What matters is that we have a 1-1 correspondence between these trees and the element of a fixed length cycle. Trees are nice because we have an easily established notion of \"depth\" that maps to a natural number.  Perhaps I'm approaching this from the wrong angle. What if there exists a way to enumerate all the possible endomaps ?  We've already established that we can construct a presentation for by sectioning out a set of elements as \"generators\" combined with a set of \"relations\" between those generators.  Our object was defined by a single generator, , and no relations. What would the presentation of our object look like?  Let's call this endomap(?) . There's something close to an isomorphism between and . For each in , we have and . We can easily say that but I'm not sure we can assert The problem is that we need to preserve but is undefined because .  It's almost as if has a presentation with an infinite number of generators. For each object we can associate a respective graph that approaches the behavior of as .     In this context, it makes sense to think of and to \"complete\" the natural numbers.  Let's back this up for a second. Suppose we have an arbitrary . We can define a \"section\" in by assigning to every \"terminal object\" and otherwise. In those terminal objects are \"loops\". If it's not a terminal object, it either has to \"go on forever\" which would effectively map it to or it has to repeat in a cycle of some fixed length. Let's call the cycle of length defined by the behavior of . If we want, we can effectively treat the object as and as .  This gives a means of locating our objects in by means of a cartesian product in of a generator and number of steps of . Each point in the can be represented by an ordered pair where is the terminal object it converges to a cycle of and is a -step path in a tree which leads to a unique \"root\" element in the cycle.  In Session 15, I started calling these different subsections of our graphs \"clusters\". The idea was that there only exists structure preserving maps between clusters that converge to loops of the same size. I'm not sure if I really answered this question here, but those \"clusters\" essentially performed the function of separating graph maps.  This exercise got me thinking about where I left off on Session 15, so I decided to spend the rest of the week exploring the \"minimal categories\" that were presented there with Python. You can find my code this week here .  I observed some of the interesting things while doing this were. First, I realized I had to keep close tabs on the domain and codomain of each map. I was representing maps as dictionaries, so sometimes two objects would have the same key and value pairs but were techincally different objects because they came from different sets.  The other thing I noticed was that I seemed to be able to separate out a subset of maps that could be used to form the others through composition. It seemed that I'm able to express all maps in a category from compositions of some \"points\", \"terminators\", and \"loops\". Since those \"loops\" correspond to structure preserving maps from , this would seem to support my theory that this is, in fact, the object I was looking for in this exercise.  This exercise seems to have left me with more questions than answered. It seemed odd how my minimal categories blurred the distinctions between \"sets\", \"points\", and \"maps\". I'm reminded of how, in Session 16, the authors used as an extension of in order to utilize the inverse operation. It seems like this mirrors what I was trying to accomplish by mapping between and . It's almost like I need to step out from to , solve the problem there, then come back and verify that the solution is something that still exists in .   "
},
{
  "id": "article4-p3",
  "level": "1",
  "url": "article4-p3.html",
  "type": "Section",
  "number": "5.3",
  "title": "Article 4: Universal Mapping Properties, Part 3",
  "body": " Article 4: Universal Mapping Properties, Part 3  We pick up this week with \"Initial Objects\". Now, let's get started! (pun intended)   Exercise 7:   If are both initial...    By the definition of as initial objects, for every object of there is exactly one -map and one -map .  Since are both \"initial objects\" in , they must also be \"objects\" in . By setting or , it follows that there needs to be exactly one map and exactly one map .  Now consider an arbitrary initial object in . By the definition of initial objects, any in must have exactly one -map . Since is itself an object in , it follows that there is precisely one map . Since there must by an identity map for any domain in the category, it follows that this unique map must necessarily be the identity map .  By the same reasoning, any map must be the unique map and any map must be the unique map . Since the composition is a map , it follows that . Similarly, the composition formed by is a map . It follows that .  Having established that both and , the maps and are inverses of each other. Consequently, these two maps define an isomorphism between and .     Exercise 8:   In each of , , and ...    In each of , , and ...  We're given that is an initial object and is a map. We're attempting to show that (a) for every we have and that (b) itself is initial.  By defining as an intial object, we know that for any object in the category there is exactly one map . Since is itself an object of the category, there is exactly one map . Furthermore, every domain needs an identity map, so the only possible map we could possibly have is the identity map .  Consider the compositions and . In the first case, we have defining a map . Since there is precisely one such map, it must be the unique identity map . Likewise, must also be the same map . It follows that .  If we assume , then there needs to exist some \"point\" with . However, the property of being an initial object in the category says that we must have exactly one map . It follows from uniqueness of that we have a unique composition .  In the category , the \"points\" of are maps which correspond to each element of and \"point to\" themselves. That means that each of the compositions and are effectively a map from . Since there can only be exactly one such map (the identity map on that single element ), these compositions must be the same map. By precomposing with our maps we see that and are both effectively the identity map . This contradicts our choice of . The uniqueness of a map ensures the uniqueness of the composition , making an initial object with the sole map being the identity .  In the category , our \"points\" are the elements fixed under the operation . Here a point is a map such that . In this situation, we also know so the following compositions should all result in \"the same map\":     In the category , we need to preserve source and target relations. Namely, for any point we need amd . However, there's precisely one map from , so and both need to evaluate to the same object. We essentially have an equivalence between the following compositions:       I'm a little uncertain about the rigor of these solutions. Hopefully the follow-up questions will give me more to go on.     Exercise 9:   Define the category of pointed sets ...    In this category, an object is a map in and a map from to is a map in for which . We're given the following external diagram:   Given Diagram for Article 4 Exercise 9      We're asked to show that \"any terminal object is also initial\" and that \"part (b) of the previous exercise is false\".  Let's start by assuming we have some \"terminal object\" in this category. We'll call this object . As a terminal object of , there is exactly one -map for any object of .  Our choice of defined an object as a map . Our definition of a terminal object implies that there is a unique map I'll call with the property that satisfies .  Now, what happens if we were to also have an initial object in ? That would imply for that every object of we have exactly one -map . Since our objects of are limited to maps , our object would also need to exist as some map . Given how we've defined our terminal object, there should be exactly one map . If we compose this unique map with the unique map , we get a unique map . It follows that any initial object is necessarily a terminal object.  That's close to what we've been asked to prove, but not quite. We were asked to prove every terminal object is initial, and instead proved the converse. I think we might actually need to compose with once more to show is the same as our unique map . Having both a unique map and a unique map should be sufficient to show the uniqueness of the map .  So why does part (b) fail in this case? If were itself an initial object, then there would be exactly one map . Since we need to have an identity map from , the unique map would need to the same as the composition . This is a problem because two maps can only be the same map if the domains and codomains match. The existence of a unique map , separate from our map , means that the composition formed by would be a different map from . The lack of uniqueness would disqualify as an initial object.     Exercise 10:   Let be a fixed 2-point set...    This time we define a category of bipointed objects , with the objects being -maps and maps being the -maps satistfying . We're also given the following diagram:   Given Diagram for Article 4 Exercise 9      First, we want to show that the initial object in is actually the identity map . In other words, we need to prove that for any object in there is exactly one map from .  If every object in is some map , then consider the composition . Our category has defined our maps as those maps in satisfying the relation . By assigning and , it follows that which is only true if it holds for every element in the domain . If that we call the objects of then both and need to hold true for every in . If is an object in , that structure preservation must also apply to the map . The relations and ensure this is a valid map in .  Maybe what I need to be doing here is establishing an isomorphism between the elements and with the \"null map\" and \"identity map on objects of \". We know there is precisely one -map and precisely one from . If we have a two element-set , then assigning and creates an unique isomorphism such that and .  In the category , a map exists between any sets and except in the case where and . If we choose and , then we know from the non-existence of a map in that we couln't possibly have one in . In other words, we have a unique map , a unique map , a unique map , and exactly zero maps .  If is a subset of , a map is guaranteed to exist. If we know no map exists, there needs to exist at least one element in that is not in . The set of those two elements and need to be isomorphic to the set .  I think this is relevant because it provides us a way to define an \"antipodal\" map in . There is a unique map defined by and . Composing swaps the roles of and . This mirrors the relationship between and statements under logical negation.  Perhaps this provides an answer the second half of the exercise. Knowing that , the existence of the antipodal map provides a second map to the initial object by way of the composition .  I keep thinking back to the minimal categories I was playing with in Python last week. In the course of my experimentation, one of the things I tried was defining my objects of my BinaryCategory to be [[0],[1,2]] instead of [[0],[0,1]] . Doing so changes the representation of my \"point\" maps from {'domain': [0], 'codomain': [0], 'map': {0: 0}}, {'domain': [0], 'codomain': [0, 1], 'map': {0: 0}}, {'domain': [0], 'codomain': [0, 1], 'map': {0: 1}}] to {'domain': [0], 'codomain': [0], 'map': {0: 0}}, {'domain': [0], 'codomain': [1, 2], 'map': {0: 1}}, {'domain': [0], 'codomain': [1, 2], 'map': {0: 2}}] making it lot clearer what my 3 points \"point\" to. If I add a \"null map\" to my category, a map with {'domain': [], 'codomain': [], 'map': {}} , and a unique map , then I can think of my 3 points as being isomorphic to the maps [{'domain': [], 'codomain': [0], 'map': {}}, {'domain': [], 'codomain': [1], 'map': {}}, {'domain': [], 'codomain': [2], 'map': {}}] by precomposing my \"points\" with that unique map .  I'm not sure where I'm going with this anymore, so lets keep moving forward.     Exercise 11:   Show that in the category ...    Let start by assuming we have some object which is NOT an initial object in . That means there is either no map or more than one map . We know that we're assured to at least have an identity map , so we can rule out the first case and focus on the second. Let's call these maps , and we know we must at least two such maps .  A terminal object in would have the property that for any in there is exactly one map . Clearly , so we can assume is a terminal object. If we also have a second map such that , then we can apply on the left again:   I think I'm starting to see where we're going with this. By asserting that and are different maps, and knowing that is the identity map, we know these maps must satisfy , , . But there's one more combination, and the composition above suggests that . Since we proved ealier that all terminal objects are isomorphic, having two distinct maps like this allows us to create an isomorphism between the terminal object and each of the maps respectively.  We've already shown \" is not initial\" implies the existence of two distinct endomaps with with isomorphisms between them and the terminal object . Having these isomorphisms and allows us compositions and . I think we can make the claim that there exists at least \"one point\" in defined by this unique map , which I think is techinically just the map itself.  We can say is terminal because . We can say in by the identity property of .  So why would this fail in the categories or ? It probably has something to do with the structure preservation in those categories.  Consider the endomap on the one point set . This set technically has two distinct \"objects\": the point and the map . A \"point\" in needs to satisfy , which is not true of our map for all objects by virtue of it being necessarily distinct from the identity map.  For maps in , they need to preserve source and target relations. Namely, preserve and . Our terminal objects here are \"loops\". Maybe can embed our object by defining and . Since we've defined such that , this would essentially give us and .  I'm picturing the case in as needing to preserve the source and target of the endomap on one point. In order to preserve source and target of , both the source and target must be the unique point . However, this space technically has two unique objects. As we \"loop\" through the point, we alternate between \"dot\" and \"arrow\". Since there's no retraction in from the two point set to the one point set , there couldn't possibly be an isomorphism with the unique terminal object .    "
},
{
  "id": "article4-p3-3",
  "level": "2",
  "url": "article4-p3.html#article4-p3-3",
  "type": "Example",
  "number": "5.3.1",
  "title": "Exercise 7:.",
  "body": " Exercise 7:   If are both initial...    By the definition of as initial objects, for every object of there is exactly one -map and one -map .  Since are both \"initial objects\" in , they must also be \"objects\" in . By setting or , it follows that there needs to be exactly one map and exactly one map .  Now consider an arbitrary initial object in . By the definition of initial objects, any in must have exactly one -map . Since is itself an object in , it follows that there is precisely one map . Since there must by an identity map for any domain in the category, it follows that this unique map must necessarily be the identity map .  By the same reasoning, any map must be the unique map and any map must be the unique map . Since the composition is a map , it follows that . Similarly, the composition formed by is a map . It follows that .  Having established that both and , the maps and are inverses of each other. Consequently, these two maps define an isomorphism between and .   "
},
{
  "id": "article4-p3-4",
  "level": "2",
  "url": "article4-p3.html#article4-p3-4",
  "type": "Example",
  "number": "5.3.2",
  "title": "Exercise 8:.",
  "body": " Exercise 8:   In each of , , and ...    In each of , , and ...  We're given that is an initial object and is a map. We're attempting to show that (a) for every we have and that (b) itself is initial.  By defining as an intial object, we know that for any object in the category there is exactly one map . Since is itself an object of the category, there is exactly one map . Furthermore, every domain needs an identity map, so the only possible map we could possibly have is the identity map .  Consider the compositions and . In the first case, we have defining a map . Since there is precisely one such map, it must be the unique identity map . Likewise, must also be the same map . It follows that .  If we assume , then there needs to exist some \"point\" with . However, the property of being an initial object in the category says that we must have exactly one map . It follows from uniqueness of that we have a unique composition .  In the category , the \"points\" of are maps which correspond to each element of and \"point to\" themselves. That means that each of the compositions and are effectively a map from . Since there can only be exactly one such map (the identity map on that single element ), these compositions must be the same map. By precomposing with our maps we see that and are both effectively the identity map . This contradicts our choice of . The uniqueness of a map ensures the uniqueness of the composition , making an initial object with the sole map being the identity .  In the category , our \"points\" are the elements fixed under the operation . Here a point is a map such that . In this situation, we also know so the following compositions should all result in \"the same map\":     In the category , we need to preserve source and target relations. Namely, for any point we need amd . However, there's precisely one map from , so and both need to evaluate to the same object. We essentially have an equivalence between the following compositions:       I'm a little uncertain about the rigor of these solutions. Hopefully the follow-up questions will give me more to go on.   "
},
{
  "id": "article4-p3-5",
  "level": "2",
  "url": "article4-p3.html#article4-p3-5",
  "type": "Example",
  "number": "5.3.3",
  "title": "Exercise 9:.",
  "body": " Exercise 9:   Define the category of pointed sets ...    In this category, an object is a map in and a map from to is a map in for which . We're given the following external diagram:   Given Diagram for Article 4 Exercise 9      We're asked to show that \"any terminal object is also initial\" and that \"part (b) of the previous exercise is false\".  Let's start by assuming we have some \"terminal object\" in this category. We'll call this object . As a terminal object of , there is exactly one -map for any object of .  Our choice of defined an object as a map . Our definition of a terminal object implies that there is a unique map I'll call with the property that satisfies .  Now, what happens if we were to also have an initial object in ? That would imply for that every object of we have exactly one -map . Since our objects of are limited to maps , our object would also need to exist as some map . Given how we've defined our terminal object, there should be exactly one map . If we compose this unique map with the unique map , we get a unique map . It follows that any initial object is necessarily a terminal object.  That's close to what we've been asked to prove, but not quite. We were asked to prove every terminal object is initial, and instead proved the converse. I think we might actually need to compose with once more to show is the same as our unique map . Having both a unique map and a unique map should be sufficient to show the uniqueness of the map .  So why does part (b) fail in this case? If were itself an initial object, then there would be exactly one map . Since we need to have an identity map from , the unique map would need to the same as the composition . This is a problem because two maps can only be the same map if the domains and codomains match. The existence of a unique map , separate from our map , means that the composition formed by would be a different map from . The lack of uniqueness would disqualify as an initial object.   "
},
{
  "id": "article4-p3-6",
  "level": "2",
  "url": "article4-p3.html#article4-p3-6",
  "type": "Example",
  "number": "5.3.5",
  "title": "Exercise 10:.",
  "body": " Exercise 10:   Let be a fixed 2-point set...    This time we define a category of bipointed objects , with the objects being -maps and maps being the -maps satistfying . We're also given the following diagram:   Given Diagram for Article 4 Exercise 9      First, we want to show that the initial object in is actually the identity map . In other words, we need to prove that for any object in there is exactly one map from .  If every object in is some map , then consider the composition . Our category has defined our maps as those maps in satisfying the relation . By assigning and , it follows that which is only true if it holds for every element in the domain . If that we call the objects of then both and need to hold true for every in . If is an object in , that structure preservation must also apply to the map . The relations and ensure this is a valid map in .  Maybe what I need to be doing here is establishing an isomorphism between the elements and with the \"null map\" and \"identity map on objects of \". We know there is precisely one -map and precisely one from . If we have a two element-set , then assigning and creates an unique isomorphism such that and .  In the category , a map exists between any sets and except in the case where and . If we choose and , then we know from the non-existence of a map in that we couln't possibly have one in . In other words, we have a unique map , a unique map , a unique map , and exactly zero maps .  If is a subset of , a map is guaranteed to exist. If we know no map exists, there needs to exist at least one element in that is not in . The set of those two elements and need to be isomorphic to the set .  I think this is relevant because it provides us a way to define an \"antipodal\" map in . There is a unique map defined by and . Composing swaps the roles of and . This mirrors the relationship between and statements under logical negation.  Perhaps this provides an answer the second half of the exercise. Knowing that , the existence of the antipodal map provides a second map to the initial object by way of the composition .  I keep thinking back to the minimal categories I was playing with in Python last week. In the course of my experimentation, one of the things I tried was defining my objects of my BinaryCategory to be [[0],[1,2]] instead of [[0],[0,1]] . Doing so changes the representation of my \"point\" maps from {'domain': [0], 'codomain': [0], 'map': {0: 0}}, {'domain': [0], 'codomain': [0, 1], 'map': {0: 0}}, {'domain': [0], 'codomain': [0, 1], 'map': {0: 1}}] to {'domain': [0], 'codomain': [0], 'map': {0: 0}}, {'domain': [0], 'codomain': [1, 2], 'map': {0: 1}}, {'domain': [0], 'codomain': [1, 2], 'map': {0: 2}}] making it lot clearer what my 3 points \"point\" to. If I add a \"null map\" to my category, a map with {'domain': [], 'codomain': [], 'map': {}} , and a unique map , then I can think of my 3 points as being isomorphic to the maps [{'domain': [], 'codomain': [0], 'map': {}}, {'domain': [], 'codomain': [1], 'map': {}}, {'domain': [], 'codomain': [2], 'map': {}}] by precomposing my \"points\" with that unique map .  I'm not sure where I'm going with this anymore, so lets keep moving forward.   "
},
{
  "id": "article4-p3-7",
  "level": "2",
  "url": "article4-p3.html#article4-p3-7",
  "type": "Example",
  "number": "5.3.7",
  "title": "Exercise 11:.",
  "body": " Exercise 11:   Show that in the category ...    Let start by assuming we have some object which is NOT an initial object in . That means there is either no map or more than one map . We know that we're assured to at least have an identity map , so we can rule out the first case and focus on the second. Let's call these maps , and we know we must at least two such maps .  A terminal object in would have the property that for any in there is exactly one map . Clearly , so we can assume is a terminal object. If we also have a second map such that , then we can apply on the left again:   I think I'm starting to see where we're going with this. By asserting that and are different maps, and knowing that is the identity map, we know these maps must satisfy , , . But there's one more combination, and the composition above suggests that . Since we proved ealier that all terminal objects are isomorphic, having two distinct maps like this allows us to create an isomorphism between the terminal object and each of the maps respectively.  We've already shown \" is not initial\" implies the existence of two distinct endomaps with with isomorphisms between them and the terminal object . Having these isomorphisms and allows us compositions and . I think we can make the claim that there exists at least \"one point\" in defined by this unique map , which I think is techinically just the map itself.  We can say is terminal because . We can say in by the identity property of .  So why would this fail in the categories or ? It probably has something to do with the structure preservation in those categories.  Consider the endomap on the one point set . This set technically has two distinct \"objects\": the point and the map . A \"point\" in needs to satisfy , which is not true of our map for all objects by virtue of it being necessarily distinct from the identity map.  For maps in , they need to preserve source and target relations. Namely, preserve and . Our terminal objects here are \"loops\". Maybe can embed our object by defining and . Since we've defined such that , this would essentially give us and .  I'm picturing the case in as needing to preserve the source and target of the endomap on one point. In order to preserve source and target of , both the source and target must be the unique point . However, this space technically has two unique objects. As we \"loop\" through the point, we alternate between \"dot\" and \"arrow\". Since there's no retraction in from the two point set to the one point set , there couldn't possibly be an isomorphism with the unique terminal object .   "
},
{
  "id": "article4-p4",
  "level": "1",
  "url": "article4-p4.html",
  "type": "Section",
  "number": "5.4",
  "title": "Article 4: Universal Mapping Properties, Part 4",
  "body": " Article 4: Universal Mapping Properties, Part 4  This week we pick up with defining products and start working towards establishing a generalized definition of binary operations. It reminds me of that \"isomorphism zoo\" in Session 4 and how we had to be very specifc about operations translate from the domain to codomain.   Exercise 12:   If and also are both products...    Let's start by recapping the definition. The maps are a product if and only if for each object and any pair of maps and there is exactly one map satisfying both and .  If that statement is true for every object , it must also be true for the object . We know we have a pair of maps and , so there must be a unique map with and .  Likewise, the maps form a product. For any object with arbitrary maps and , we must have exactly one map . If this is true for all objects, it must also be true for . It follows that there is a unique map with and .  Having established that the maps and exist and are both unique, we must also prove they are isomorphisms. To do so we'll need to establish and .  If the maps are unique, then the compositions of maps and must also be unique. Since we're guaranteed to have an identity map for any given domain, it follows from uniqueness that and . Thus, we've established that are inverses of each other and consequently isomorphisms.     Exercise 13:   In a category with products and a terminal object...    Let's begin by summarizing what we know.  We know this category has a terminal object. Let's call it . For any object in our category , there is exactly one -map . Since this must also hold true for , we can safely assume the existence of a unique map .  We also know we have a product and projection maps . For any object in , and any pair of maps and , there exists exactly one map with the property that and .  Let's combine these definitions by choosing . It follows that for any pair of points and , there is exactly one map with and .  Given that is a terminal object, we can pair each of the maps with it's respective dual: , , and .  Essentially, either are the unique inverses such that or we get two competing definitions of these three unqiue compositions:        Exercise 14:   Define composition of maps...    Our category has as objects a set together with any action of . Our maps from to are -maps which \"respect actions of \" such that for all .  So lets attempt to define composition . We'll need a pair of -maps. Let's call them and . The action respecting nature of these maps means that for all we have preserved by the first map and preserved by the second map.  Let's define the composition as the composition of respective -maps . We'll need to show that it respect actions in our category, namely that for all .  Let's start with . We can regroup the terms to form . Since , we can substitute to get . Since we also know , that means that . This establishes that is a valid -map.  As a category, each domain must have an identity map . Each set\/action pair must have some map such that for all . I think we get this from the \"product\" of identity maps . This lets us rewrite the identity above as .  For any -map , we know for all . This should continue to hold true if we choose . Thus, for all we can assert .  What about our associative property ? I think we kind of inherit this from the properties of . Since our -maps come from -maps, they must uphold independently of the additional retrictions placed on them as members of . We've already established that actions are respected by composition, so both sides necessisarily produce -maps.     Exercise 15:   Exprese these equations...    Okay, I was under the impression that \"equations\" implied the presence of \"an equals sign\". I'm not even sure how to interpret this:   The preceeding text discusses a \"preferred binary operation\" and a \"point\" . The action corresponds to map composition and acts as the identity map . It would be described by through the equations: and .  This sounds a lot like how in Session 15 I was using an invertable \"zig zag\" map to iterate through all the possible steps of all the possible generators. In fact, I'd say these so called \"equations\" here look very similar to the equation for our generator which corresponded to an equation in our presentation.  When I was trying to verify my work in Python, I decided on using a tuple to represent the relations. The equation became represented by a generator and iteration pair (('d',2),('d',0)) . Maybe that's what I'm looking at here. Some action is applied twice to and the result is isomorphic to the sitation where the action isn't applied at all.  Maybe it might be helpful for me to think of those double arrows as projection maps from Exercise 13. I could potentially think of as a short hand for Any spliting of into would define three unique maps as follows.     The big difference between then and now is that here I'm splitting my space into instead of . The closest thing I have to \"equality\" is \"isomorphism\" and I get one of those for free between any terminal objects. Maybe it might help me to think of the statement in the exercise as defining two isomorphisms:    Since there must be an isomorphism between any pair of terminal objects, there must necessarily be an isomorphism . In fact, the very existence of an object implies an equation if I try to enforce the associative law on those maps. I can think of as being a map followed by a map or being two evaluations of . That essentially gives us an \"equation\" .  The other way of expressing this equation is by way of the \"preferred\" maps . Given and , we can express the associative law above as . At least that gives us something to work with.  As long as we have this preferred element which \"acts as\" , it has a corresponding map defined by the unique map . Our preferred action then gives rise to an endomap on : . This seems like a perfect candidate to define as the object . Better still, defines an easily constructable map to when applied twice!  Assuming that is a uniquely defined pair of maps, perhaps the pairing of this with denotes that these maps are not \"the same map\", just that there exists an isomorphism between them. Since associative property must apply to the latter, the compositions and must ultimately be the same.  A suppose we have a \"point\" , expressed by the triple . With the first composition, we can apply to get , followed by to get or we can apply twice to get . Knowing is true for any choice of actions, it must be true for our preferred action . Substituting gives us , which establishes that it acts as an identity map.  I feel like there's a parallel between these maps and role played by the functions (car L) and (cdr L) in LISP. Given a list L of '(a b x) , car returns the first element a and cdr returns a list of the rest: '(b,c) . The operations played by and let us isolate arbitrary elements in a space , just like how LISP would use (car (cdr L)) to access the second element b .    "
},
{
  "id": "article4-p4-3",
  "level": "2",
  "url": "article4-p4.html#article4-p4-3",
  "type": "Example",
  "number": "5.4.1",
  "title": "Exercise 12:.",
  "body": " Exercise 12:   If and also are both products...    Let's start by recapping the definition. The maps are a product if and only if for each object and any pair of maps and there is exactly one map satisfying both and .  If that statement is true for every object , it must also be true for the object . We know we have a pair of maps and , so there must be a unique map with and .  Likewise, the maps form a product. For any object with arbitrary maps and , we must have exactly one map . If this is true for all objects, it must also be true for . It follows that there is a unique map with and .  Having established that the maps and exist and are both unique, we must also prove they are isomorphisms. To do so we'll need to establish and .  If the maps are unique, then the compositions of maps and must also be unique. Since we're guaranteed to have an identity map for any given domain, it follows from uniqueness that and . Thus, we've established that are inverses of each other and consequently isomorphisms.   "
},
{
  "id": "article4-p4-4",
  "level": "2",
  "url": "article4-p4.html#article4-p4-4",
  "type": "Example",
  "number": "5.4.2",
  "title": "Exercise 13:.",
  "body": " Exercise 13:   In a category with products and a terminal object...    Let's begin by summarizing what we know.  We know this category has a terminal object. Let's call it . For any object in our category , there is exactly one -map . Since this must also hold true for , we can safely assume the existence of a unique map .  We also know we have a product and projection maps . For any object in , and any pair of maps and , there exists exactly one map with the property that and .  Let's combine these definitions by choosing . It follows that for any pair of points and , there is exactly one map with and .  Given that is a terminal object, we can pair each of the maps with it's respective dual: , , and .  Essentially, either are the unique inverses such that or we get two competing definitions of these three unqiue compositions:      "
},
{
  "id": "article4-p4-5",
  "level": "2",
  "url": "article4-p4.html#article4-p4-5",
  "type": "Example",
  "number": "5.4.3",
  "title": "Exercise 14:.",
  "body": " Exercise 14:   Define composition of maps...    Our category has as objects a set together with any action of . Our maps from to are -maps which \"respect actions of \" such that for all .  So lets attempt to define composition . We'll need a pair of -maps. Let's call them and . The action respecting nature of these maps means that for all we have preserved by the first map and preserved by the second map.  Let's define the composition as the composition of respective -maps . We'll need to show that it respect actions in our category, namely that for all .  Let's start with . We can regroup the terms to form . Since , we can substitute to get . Since we also know , that means that . This establishes that is a valid -map.  As a category, each domain must have an identity map . Each set\/action pair must have some map such that for all . I think we get this from the \"product\" of identity maps . This lets us rewrite the identity above as .  For any -map , we know for all . This should continue to hold true if we choose . Thus, for all we can assert .  What about our associative property ? I think we kind of inherit this from the properties of . Since our -maps come from -maps, they must uphold independently of the additional retrictions placed on them as members of . We've already established that actions are respected by composition, so both sides necessisarily produce -maps.   "
},
{
  "id": "article4-p4-6",
  "level": "2",
  "url": "article4-p4.html#article4-p4-6",
  "type": "Example",
  "number": "5.4.4",
  "title": "Exercise 15:.",
  "body": " Exercise 15:   Exprese these equations...    Okay, I was under the impression that \"equations\" implied the presence of \"an equals sign\". I'm not even sure how to interpret this:   The preceeding text discusses a \"preferred binary operation\" and a \"point\" . The action corresponds to map composition and acts as the identity map . It would be described by through the equations: and .  This sounds a lot like how in Session 15 I was using an invertable \"zig zag\" map to iterate through all the possible steps of all the possible generators. In fact, I'd say these so called \"equations\" here look very similar to the equation for our generator which corresponded to an equation in our presentation.  When I was trying to verify my work in Python, I decided on using a tuple to represent the relations. The equation became represented by a generator and iteration pair (('d',2),('d',0)) . Maybe that's what I'm looking at here. Some action is applied twice to and the result is isomorphic to the sitation where the action isn't applied at all.  Maybe it might be helpful for me to think of those double arrows as projection maps from Exercise 13. I could potentially think of as a short hand for Any spliting of into would define three unique maps as follows.     The big difference between then and now is that here I'm splitting my space into instead of . The closest thing I have to \"equality\" is \"isomorphism\" and I get one of those for free between any terminal objects. Maybe it might help me to think of the statement in the exercise as defining two isomorphisms:    Since there must be an isomorphism between any pair of terminal objects, there must necessarily be an isomorphism . In fact, the very existence of an object implies an equation if I try to enforce the associative law on those maps. I can think of as being a map followed by a map or being two evaluations of . That essentially gives us an \"equation\" .  The other way of expressing this equation is by way of the \"preferred\" maps . Given and , we can express the associative law above as . At least that gives us something to work with.  As long as we have this preferred element which \"acts as\" , it has a corresponding map defined by the unique map . Our preferred action then gives rise to an endomap on : . This seems like a perfect candidate to define as the object . Better still, defines an easily constructable map to when applied twice!  Assuming that is a uniquely defined pair of maps, perhaps the pairing of this with denotes that these maps are not \"the same map\", just that there exists an isomorphism between them. Since associative property must apply to the latter, the compositions and must ultimately be the same.  A suppose we have a \"point\" , expressed by the triple . With the first composition, we can apply to get , followed by to get or we can apply twice to get . Knowing is true for any choice of actions, it must be true for our preferred action . Substituting gives us , which establishes that it acts as an identity map.  I feel like there's a parallel between these maps and role played by the functions (car L) and (cdr L) in LISP. Given a list L of '(a b x) , car returns the first element a and cdr returns a list of the rest: '(b,c) . The operations played by and let us isolate arbitrary elements in a space , just like how LISP would use (car (cdr L)) to access the second element b .   "
},
{
  "id": "article4-p5",
  "level": "1",
  "url": "article4-p5.html",
  "type": "Section",
  "number": "5.5",
  "title": "Article 4: Universal Mapping Properties, Part 5",
  "body": " Article 4: Universal Mapping Properties, Part 5  This week the authors introduce some notation for \"families\". I take some strange comfort in the fact that the set of indices is allowed to be empty.   Exercise 16:   Show that... has the appropriate universal mapping property...    So let's sketch out what we're looking at.   Problem statement for Article 4 Exercise 16      In order to do so, we need to establish it has the \"universal mapping property\" with all:   Universal maps for Article 4 Exercise 16      The \"universal mapping property\" essentially says we have 3 unique isomorphisms for the terminal object :     For convenience, let's steal the multi-arrow notation from the previous exercise and denote it simply as . By the definition of our products, we can also name two other unique isomorphisms in this manner:    I think this is similar to what we did with Exercise 15. Our universal mapping property says that we have a unique map satsifying . Our products define unique maps and , which allow us to form two unique compositions:    We can chain these maps together to get a unique map :   Or a unqiue map :   This is what we'd expect based on our \"Uniqueness of Products\" theore. It states that if the maps and both make products of the same family, then there is exactly one map for which and that this map is an isomorphism. Since our , this gives us three equations , , .  Well, we already have a uniquely defined map given by so we could only possibly have . It follows that and . Apply on the right of the three equations above to get:     This map seems to come from nowhere, but is simultaneously well defined by applying the composition .  Putting this all together now, any triple-product uniquely determines a triple-product via the isomorphisms given by:   and   As one last step, let's see if we can draw a more complete diagram of the situation.   Problem statement for Article 4 Exercise 16      The \"Uniqueness of Products\" essentially states that we have 3 unique maps defined by the map equivalencies , , and .  This still feels a little more \"hand-wavy\" than I'd like, but it makes sense that when the maps are uniquely defined by the domain and codomain that there would be precisely one way to compose them such that .     Exercise 17:   In , , and ...    First let's review the definition of sum . A pair of maps and makes a sum if for each object and each pair , there is exactly one map for which both and .  If the definition of sum holds for every object , and we know we have a \"point\" , we should be able to choose as our object. This means that we have for each pair of maps and exactly one map satisfying and .  It must continue to hold if we substitute as well. For any pair of maps , we must have exactly one map such that and . If that's true, then why not choose as our arbitrary pair of maps? It follows that for , there should be exactly one map with and .  Two maps are only equal when they produce the same output for every possible input, so this means for every map we have and for every map we have . Consider an arbitrary point . If this \"comes from\" , there exists such that . Apply on the left to get . If this \"comes from\" , there exists such that . Apply on the left to get . We find that every point coming from either or is \"fixed\" by .  Suppose we have some special point that \"comes from both \". This point would need to satisfy for some and . Applying on the left of all three parts of that equation gives us and . Since these are points, we have a corresponding pair of maps and . By our definition of sum, there should be exactly one map with and but here we have two unique maps given by the compositions and . This contradiction means points in must come from at most one of and .  Now suppose we have some special point which comes from neither nor . There would exist no such that and no such that . We can apply our point's dual on the right of both sides to say those equations are equivalent to map and . However, if we substitute and into our ealier equations we see and . This contradicts our choice of and implies that all points in must come from at least one of or .  Having established each \"point\" comes from \"at most one point\" in and \"at least one point\" in , I think it's safe to say that each comes from \"exactly one of\" .  I think this is where we get to behavior that splits between different categories. When we're in , each point \"points to\" itself. When we move to each \"point\" is a \"fixed point\" of the dynamical system such that . When we move to further out to the category of our \"points\" become the \"loops\" of a graph instead.  In the case of -maps, I'm thinking that our map defined as above could really only possibly be the identity map . In the case of -maps, we already saw that preserves the behavior of fixed points since . It stands to reason that in a space we would have and . As long as each preserves this structure also, such that and , it would follow that and .  I feel like this must have a simplier explanation that I'm overlooking. Maybe I should be using this notion of initial objects somehow. We defined an object \"initial\" if for every object of there exists exactly one -map . In particular, there should be precisely one map . Maybe precomposing our sum with some of these unique maps might give me more to work with.   Expanded definition of sum      I'm picturing my sum as a set that contains at least two unique elements: and . We defined a unique composition by the \"path\" , but our retractions to allow us to \"factor\" through after we get to because we have a unique pair of maps . The existence of a equivalent map that doubles back without changing , allows use to assert the uniqueness of two other maps:    I can imagine these as maps which goes through the points of and labeling each of them as coming from or . Furthermore, I can imagine and behaving like \"dots\" and \"arrows\" in , effectively alternating between and as we follow the endomap.    I think I'm going to stop here and let some of this sink in. I feel like I was supposed to use this notion of \"families\" somehow but didn't. It might have something to do with my feud over the bookkeeping rules and \"maps to nothing\" from way back in Article 1.  "
},
{
  "id": "article4-p5-3",
  "level": "2",
  "url": "article4-p5.html#article4-p5-3",
  "type": "Example",
  "number": "5.5.1",
  "title": "Exercise 16:.",
  "body": " Exercise 16:   Show that... has the appropriate universal mapping property...    So let's sketch out what we're looking at.   Problem statement for Article 4 Exercise 16      In order to do so, we need to establish it has the \"universal mapping property\" with all:   Universal maps for Article 4 Exercise 16      The \"universal mapping property\" essentially says we have 3 unique isomorphisms for the terminal object :     For convenience, let's steal the multi-arrow notation from the previous exercise and denote it simply as . By the definition of our products, we can also name two other unique isomorphisms in this manner:    I think this is similar to what we did with Exercise 15. Our universal mapping property says that we have a unique map satsifying . Our products define unique maps and , which allow us to form two unique compositions:    We can chain these maps together to get a unique map :   Or a unqiue map :   This is what we'd expect based on our \"Uniqueness of Products\" theore. It states that if the maps and both make products of the same family, then there is exactly one map for which and that this map is an isomorphism. Since our , this gives us three equations , , .  Well, we already have a uniquely defined map given by so we could only possibly have . It follows that and . Apply on the right of the three equations above to get:     This map seems to come from nowhere, but is simultaneously well defined by applying the composition .  Putting this all together now, any triple-product uniquely determines a triple-product via the isomorphisms given by:   and   As one last step, let's see if we can draw a more complete diagram of the situation.   Problem statement for Article 4 Exercise 16      The \"Uniqueness of Products\" essentially states that we have 3 unique maps defined by the map equivalencies , , and .  This still feels a little more \"hand-wavy\" than I'd like, but it makes sense that when the maps are uniquely defined by the domain and codomain that there would be precisely one way to compose them such that .   "
},
{
  "id": "article4-p5-4",
  "level": "2",
  "url": "article4-p5.html#article4-p5-4",
  "type": "Example",
  "number": "5.5.5",
  "title": "Exercise 17:.",
  "body": " Exercise 17:   In , , and ...    First let's review the definition of sum . A pair of maps and makes a sum if for each object and each pair , there is exactly one map for which both and .  If the definition of sum holds for every object , and we know we have a \"point\" , we should be able to choose as our object. This means that we have for each pair of maps and exactly one map satisfying and .  It must continue to hold if we substitute as well. For any pair of maps , we must have exactly one map such that and . If that's true, then why not choose as our arbitrary pair of maps? It follows that for , there should be exactly one map with and .  Two maps are only equal when they produce the same output for every possible input, so this means for every map we have and for every map we have . Consider an arbitrary point . If this \"comes from\" , there exists such that . Apply on the left to get . If this \"comes from\" , there exists such that . Apply on the left to get . We find that every point coming from either or is \"fixed\" by .  Suppose we have some special point that \"comes from both \". This point would need to satisfy for some and . Applying on the left of all three parts of that equation gives us and . Since these are points, we have a corresponding pair of maps and . By our definition of sum, there should be exactly one map with and but here we have two unique maps given by the compositions and . This contradiction means points in must come from at most one of and .  Now suppose we have some special point which comes from neither nor . There would exist no such that and no such that . We can apply our point's dual on the right of both sides to say those equations are equivalent to map and . However, if we substitute and into our ealier equations we see and . This contradicts our choice of and implies that all points in must come from at least one of or .  Having established each \"point\" comes from \"at most one point\" in and \"at least one point\" in , I think it's safe to say that each comes from \"exactly one of\" .  I think this is where we get to behavior that splits between different categories. When we're in , each point \"points to\" itself. When we move to each \"point\" is a \"fixed point\" of the dynamical system such that . When we move to further out to the category of our \"points\" become the \"loops\" of a graph instead.  In the case of -maps, I'm thinking that our map defined as above could really only possibly be the identity map . In the case of -maps, we already saw that preserves the behavior of fixed points since . It stands to reason that in a space we would have and . As long as each preserves this structure also, such that and , it would follow that and .  I feel like this must have a simplier explanation that I'm overlooking. Maybe I should be using this notion of initial objects somehow. We defined an object \"initial\" if for every object of there exists exactly one -map . In particular, there should be precisely one map . Maybe precomposing our sum with some of these unique maps might give me more to work with.   Expanded definition of sum      I'm picturing my sum as a set that contains at least two unique elements: and . We defined a unique composition by the \"path\" , but our retractions to allow us to \"factor\" through after we get to because we have a unique pair of maps . The existence of a equivalent map that doubles back without changing , allows use to assert the uniqueness of two other maps:    I can imagine these as maps which goes through the points of and labeling each of them as coming from or . Furthermore, I can imagine and behaving like \"dots\" and \"arrows\" in , effectively alternating between and as we follow the endomap.   "
},
{
  "id": "article4-p6",
  "level": "1",
  "url": "article4-p6.html",
  "type": "Section",
  "number": "5.6",
  "title": "Article 4: Universal Mapping Properties, Part 6",
  "body": " Article 4: Universal Mapping Properties, Part 6  After thinking about it some more, I'm wondering if exercise 19 might get into the \"dual\" notion of \"a sum family\". The best course of action is for now is probably just to pick up right where I left off.   Exercise 18:   In , there are many...    The authors discussed this notion of factoriong in the context of products before. Specifically, they considered an example of a system changing over time:   This notation was meant to convey the existence of a unique isomorphism between the product and pairs of factors.  The \"dual\" notion of factoring for sums would probably look like but what actually follows from the definition of sum is something to the effect of   So what happens if we have an arbitrary map ? Maybe we can substitute into our definition. Doing so says that any pair of maps and would imply that for any and pair of maps , we will have exactly one map with the property that and .  If that's true for all , why not try assigning ? The existence of a unique map defined by would need to be the identity map so we can conclude . It follows that we'd need to have and .  So we start with some points in which are each isomorphic to  By mapping each with , the corresponding should uniquely satisfy but we actually have two such maps given by and   That said, I'm still struggling to come up with a concrete example which meets this criteria. Maybe that statement that is supposed to be a hint. If we have a unique map and a unique map the resulting composition should be unique as well. However, while there should be a unique inverse , there can't exist a inverse satisfying because we need someplace for the map to send the points to.    Given that I'm kind of stuck here, maybe it would be productive to revisit Exercise 17 with some of these new ideas.   Execise 17 (part 2):   Continued from ...    Looking back over my notes, I'm wondering if I need to establish in terms of an and action   binary operation  .  The \"initial object\" and \"terminal object\" each have exactly one endomap. We have a \"null map\" and identity map . In , we can think of as the empty set which has the nice property that for any set the union is identical to the original set . This means that for any there is precisely one map and that is the identity map . If that's true for all objects, it should also hold true for the terminal object providing us with a unique map .  Let's choose and in the definition of a sum . For a pair of \"injection maps\" and to be a sum, we need to know that for each object and pair of maps and there is exactly one map with and . Our map must uniquely satisfy and must uniquely satisfy . Since we effectively have , we're basically naming two distinct maps depending on whether or not the composition passes through . Maybe this will be better illustrated with a diagram.   Maps defined by sums of initial and terminal objects      My hunch is that this allows us a method for counting things in an arbitrary category. We should have the properties that , , and , since for any set we have . In fact, we can make the stronger statement that for all . It seems like the obvious question to consider next is what works out to be. I'm seeing some similarity here with Peano's axioms, so I wonder if there's a way to construct some kind of successor function here. If I can define here, that gives me a method for constructing the natural numbers . There must some kind of a set isomorphic to because I already have a set of two unique maps .  Once I have this binary operation corresponding to the usual definition of addition, how could I define an action ? I think I can do this by counting the loops through in the diagram above. We have a sequence , which means must be equal to the unique map . We can also use to build an endomap on by following the sequence of maps . It follows that since both sides must be isomorphic to a unique map . This should let us define our action such that for and we'd have .    Okay, I feel like I'm starting to talk myself in circles again so I'll take that as a sign that I need to spend some more time on this later.  "
},
{
  "id": "article4-p6-3",
  "level": "2",
  "url": "article4-p6.html#article4-p6-3",
  "type": "Example",
  "number": "5.6.1",
  "title": "Exercise 18:.",
  "body": " Exercise 18:   In , there are many...    The authors discussed this notion of factoriong in the context of products before. Specifically, they considered an example of a system changing over time:   This notation was meant to convey the existence of a unique isomorphism between the product and pairs of factors.  The \"dual\" notion of factoring for sums would probably look like but what actually follows from the definition of sum is something to the effect of   So what happens if we have an arbitrary map ? Maybe we can substitute into our definition. Doing so says that any pair of maps and would imply that for any and pair of maps , we will have exactly one map with the property that and .  If that's true for all , why not try assigning ? The existence of a unique map defined by would need to be the identity map so we can conclude . It follows that we'd need to have and .  So we start with some points in which are each isomorphic to  By mapping each with , the corresponding should uniquely satisfy but we actually have two such maps given by and   That said, I'm still struggling to come up with a concrete example which meets this criteria. Maybe that statement that is supposed to be a hint. If we have a unique map and a unique map the resulting composition should be unique as well. However, while there should be a unique inverse , there can't exist a inverse satisfying because we need someplace for the map to send the points to.   "
},
{
  "id": "article4-p6-5",
  "level": "2",
  "url": "article4-p6.html#article4-p6-5",
  "type": "Example",
  "number": "5.6.2",
  "title": "Execise 17 (part 2):.",
  "body": " Execise 17 (part 2):   Continued from ...    Looking back over my notes, I'm wondering if I need to establish in terms of an and action   binary operation  .  The \"initial object\" and \"terminal object\" each have exactly one endomap. We have a \"null map\" and identity map . In , we can think of as the empty set which has the nice property that for any set the union is identical to the original set . This means that for any there is precisely one map and that is the identity map . If that's true for all objects, it should also hold true for the terminal object providing us with a unique map .  Let's choose and in the definition of a sum . For a pair of \"injection maps\" and to be a sum, we need to know that for each object and pair of maps and there is exactly one map with and . Our map must uniquely satisfy and must uniquely satisfy . Since we effectively have , we're basically naming two distinct maps depending on whether or not the composition passes through . Maybe this will be better illustrated with a diagram.   Maps defined by sums of initial and terminal objects      My hunch is that this allows us a method for counting things in an arbitrary category. We should have the properties that , , and , since for any set we have . In fact, we can make the stronger statement that for all . It seems like the obvious question to consider next is what works out to be. I'm seeing some similarity here with Peano's axioms, so I wonder if there's a way to construct some kind of successor function here. If I can define here, that gives me a method for constructing the natural numbers . There must some kind of a set isomorphic to because I already have a set of two unique maps .  Once I have this binary operation corresponding to the usual definition of addition, how could I define an action ? I think I can do this by counting the loops through in the diagram above. We have a sequence , which means must be equal to the unique map . We can also use to build an endomap on by following the sequence of maps . It follows that since both sides must be isomorphic to a unique map . This should let us define our action such that for and we'd have .   "
},
{
  "id": "article4-p7",
  "level": "1",
  "url": "article4-p7.html",
  "type": "Section",
  "number": "5.7",
  "title": "Article 4: Universal Mapping Properties, Part 7",
  "body": " Article 4: Universal Mapping Properties, Part 7  I think reformulating Exercise 17 using actions last week was productive and I have some new ideas for Exercise 18 that I want to explore.   Exercise 18 (part 2):   Continued from ...    I've been thinking a lot about the \"family tree\" problem from and am wondering if combining two different \"binaries\" might give me what I'm looking for here. Consider the set we defined in Session 12 Exercise 3:   Endomaps and on as seen in solution to Session 12 Exercise 3      What if we choose some map as our sum ?  We have a unique pair of injection maps and defined by and . For any object and maps , our definition of a sum says there should be exactly one map for which and .  Let's take to be our product . As a product, we should have a unique set of three maps:     By defining by a sum, we also force another set of three unique maps:     For any person in , consider the compositions and .  First, consider a person . In the first composition, we'd have , and . In the second composition, we'd have , , and .  Next, consider another person . In the first composition, we'd have , and . In the second composition, we'd have , , and .  This gives us an isomorphism between the set of labels and the compositions which fix those respective points . Since our definition of product requires the maps and to be unique, we'd be unable to use these factor to completely because we'd be excluding all of the people in the wolf clan that get \"stepped over\" through the composition.  This doesn't feel like a very rigorous solution, but I think as close I'm going to get for now. Let's keep moving forward.     Exercise 19:   Show that in a category with sums...    Okay, I see four different sums we're going to need: , , and . We'll start with the easy sums first.  For with maps to be a sum, each and pair of maps and should have exactly one map such that and .  For with maps to be a sum, each and pair of maps and should have exactly one map such that and .  Now let's start composing our sums.  For with maps to be a sum, each and pair of maps and should have exactly one map such that and .  For with maps to be a sum, each and pair of maps and should have exactly one map such that and .  Maybe here we can define a \"triple sum\" as a \"family\" by a unique set of 3 maps , , and . These should have the property that for any object and maps , we have exactly one map with , , and .  If we choose , the set of the 3 unique maps , , and should have some corresponding unique map with the property that , , .  Likewise, choosing gives us unique maps , , and corresponding to the unique map satisfying , , .  It seems like it would make sense to build an isomorphism by pairing up each with the respective pair for . That's at least starting to resemble a dual definition for to the \"product family\". Perhaps we can define a \"sum family\" as follows:    A sum family is a object together with maps (one for each ), having the universal property:  Given any object and any maps , there is exactly one map such that all the triangles below commute, i.e. such that for each in .   Commutitive diagram of sum        This is basically the situation I presently have with the subsitution . Maybe I can think of my \"triple sum\" as the following collection of 4 unique maps:    and identify another unique pair of maps to use as my grouping operations as acting on the \"left\" or \"right\":  maybe that will give me a method of forming the isomorphism I'm looking for:      I'm not totally confident in this quite yet, but prior experiences suggest that the subsequent Sessions will help clear things up.  "
},
{
  "id": "article4-p7-3",
  "level": "2",
  "url": "article4-p7.html#article4-p7-3",
  "type": "Example",
  "number": "5.7.1",
  "title": "Exercise 18 (part 2):.",
  "body": " Exercise 18 (part 2):   Continued from ...    I've been thinking a lot about the \"family tree\" problem from and am wondering if combining two different \"binaries\" might give me what I'm looking for here. Consider the set we defined in Session 12 Exercise 3:   Endomaps and on as seen in solution to Session 12 Exercise 3      What if we choose some map as our sum ?  We have a unique pair of injection maps and defined by and . For any object and maps , our definition of a sum says there should be exactly one map for which and .  Let's take to be our product . As a product, we should have a unique set of three maps:     By defining by a sum, we also force another set of three unique maps:     For any person in , consider the compositions and .  First, consider a person . In the first composition, we'd have , and . In the second composition, we'd have , , and .  Next, consider another person . In the first composition, we'd have , and . In the second composition, we'd have , , and .  This gives us an isomorphism between the set of labels and the compositions which fix those respective points . Since our definition of product requires the maps and to be unique, we'd be unable to use these factor to completely because we'd be excluding all of the people in the wolf clan that get \"stepped over\" through the composition.  This doesn't feel like a very rigorous solution, but I think as close I'm going to get for now. Let's keep moving forward.   "
},
{
  "id": "article4-p7-4",
  "level": "2",
  "url": "article4-p7.html#article4-p7-4",
  "type": "Example",
  "number": "5.7.3",
  "title": "Exercise 19:.",
  "body": " Exercise 19:   Show that in a category with sums...    Okay, I see four different sums we're going to need: , , and . We'll start with the easy sums first.  For with maps to be a sum, each and pair of maps and should have exactly one map such that and .  For with maps to be a sum, each and pair of maps and should have exactly one map such that and .  Now let's start composing our sums.  For with maps to be a sum, each and pair of maps and should have exactly one map such that and .  For with maps to be a sum, each and pair of maps and should have exactly one map such that and .  Maybe here we can define a \"triple sum\" as a \"family\" by a unique set of 3 maps , , and . These should have the property that for any object and maps , we have exactly one map with , , and .  If we choose , the set of the 3 unique maps , , and should have some corresponding unique map with the property that , , .  Likewise, choosing gives us unique maps , , and corresponding to the unique map satisfying , , .  It seems like it would make sense to build an isomorphism by pairing up each with the respective pair for . That's at least starting to resemble a dual definition for to the \"product family\". Perhaps we can define a \"sum family\" as follows:    A sum family is a object together with maps (one for each ), having the universal property:  Given any object and any maps , there is exactly one map such that all the triangles below commute, i.e. such that for each in .   Commutitive diagram of sum        This is basically the situation I presently have with the subsitution . Maybe I can think of my \"triple sum\" as the following collection of 4 unique maps:    and identify another unique pair of maps to use as my grouping operations as acting on the \"left\" or \"right\":  maybe that will give me a method of forming the isomorphism I'm looking for:     "
},
{
  "id": "article4-p8",
  "level": "1",
  "url": "article4-p8.html",
  "type": "Section",
  "number": "5.8",
  "title": "Article 4: Universal Mapping Properties, Part 8",
  "body": " Article 4: Universal Mapping Properties, Part 8  There's only two exercises left, but I've never felt more confused by the distributive property so we'll see how far I get.   Exercise 20:   The category of pointed sets...    We defined this category back in Exercise 9, to have as objects maps in , and as maps tbe maps in from to in satisfying . We showed that under these condiditions any terminal object is also inital and that itself is not inital.  Our hint was to determine the nature of sums within the category , so lets do that next. The best analogy I have for sum here is the disjoint union of sets . Let's consider the breakfast ordering scenario from way back in Article 1. Suppose John, Mary, and Sam are at a dinner that only serves a single choice of either coffee or eggs.   \"Fantasy Diner\" map from Article 1      If and , then every map corresponds with an endomap that we can make by taking as the union of and mapping each point in to itself.   \"Fantasy Diner\" embedded in an endomap      Now suppose our situation is a little bit different. The server comes asks \"What does everyone want?\". Sam says \"coffee\" and Mary says \"eggs\". John, however, is a little distracted and reveals his true feelings by blurting out \"Mary\". The server assumes that John wants the same order as the only woman at the table and puts in a second order of eggs for John. Effectively, our server acts as a composition of maps between what they ordered and what they get.   \"Fantasy Diner\" map with order by reference      My hunch is that the treatment of as one object or two is going to present problems in . Consider what happens when we try to embed this composition as an endomap.   Referential order embedded in an endomap      We should have exactly one map from but effectively have a second one that passes through . The only way we can resolve this in is to separate out two unique Mary maps and .  I think the key fact here is that every -map is inherently invertable. By the uniqueness of terminal objects, each must correspond with a unique inverse map . Given that , precomposing with gives us . If we define , then it follows that and . It's easier to see this with a diagram:   Invertability of -maps      The uniqueness of our maps basically depends on whether or not . If , then we must have . If , then then we know .  I'm thinking about as uniquely defining a dual map by the property that if for every and if there exists some for which . This allows me to define an something like an injection map that records for each whether the point we came from is the same or different.  Perhaps this is setting up something similar to Russell's Paradox : \"Does the set of all sets not containing itself contain itself?\". A set which contains itself, shouldn't, and a set which doesn't contain itself, should. Maybe we can use the notion that the map admits a retraction but does not to further show that either fixes all points or no points.  To get a better idea of what's going on, lets draw an external diagram showing both the sum and product:   Sums and product maps combined      I'm thinking this diagram is uniquely defines a map from satisfying all commutative triangles. It seems reasonable to conclude that and would satisfy this property, but our result from Exercise 9 said that implies and . Maybe we can use that to contradict the distributive property somehow.  Let's try breaking down each side of the distributive property with some diagrams.   Breaking down       Breaking down      Breaking this down like this doesn't quite seem right. The way we've defined a sum, we come from those sets rather than go to them. My sum of should probably look more like this:   Fixed break-down of      Likewise, our should be updated as well:   Fixed Break down of      Alright, let's try to combine this idea with our universal mapping property. Let's use the convention to index our objects for . Our definition of product family with maps implies for any maps there's a unique map such that all triangles below commute.   Product Family      Likewise, our definition of a sum family says that for with maps implies for any maps there's a unique map such that all triangles below commute.   Sum Family      Combining those two diagrams together:   Product and Sum Families Combined      There for any set of , there should be exactly one pair such that everything commutes.  I'm not exactly sure where to take it from here, so maybe I should just let it simmer for a while.    "
},
{
  "id": "article4-p8-3",
  "level": "2",
  "url": "article4-p8.html#article4-p8-3",
  "type": "Example",
  "number": "5.8.1",
  "title": "Exercise 20:.",
  "body": " Exercise 20:   The category of pointed sets...    We defined this category back in Exercise 9, to have as objects maps in , and as maps tbe maps in from to in satisfying . We showed that under these condiditions any terminal object is also inital and that itself is not inital.  Our hint was to determine the nature of sums within the category , so lets do that next. The best analogy I have for sum here is the disjoint union of sets . Let's consider the breakfast ordering scenario from way back in Article 1. Suppose John, Mary, and Sam are at a dinner that only serves a single choice of either coffee or eggs.   \"Fantasy Diner\" map from Article 1      If and , then every map corresponds with an endomap that we can make by taking as the union of and mapping each point in to itself.   \"Fantasy Diner\" embedded in an endomap      Now suppose our situation is a little bit different. The server comes asks \"What does everyone want?\". Sam says \"coffee\" and Mary says \"eggs\". John, however, is a little distracted and reveals his true feelings by blurting out \"Mary\". The server assumes that John wants the same order as the only woman at the table and puts in a second order of eggs for John. Effectively, our server acts as a composition of maps between what they ordered and what they get.   \"Fantasy Diner\" map with order by reference      My hunch is that the treatment of as one object or two is going to present problems in . Consider what happens when we try to embed this composition as an endomap.   Referential order embedded in an endomap      We should have exactly one map from but effectively have a second one that passes through . The only way we can resolve this in is to separate out two unique Mary maps and .  I think the key fact here is that every -map is inherently invertable. By the uniqueness of terminal objects, each must correspond with a unique inverse map . Given that , precomposing with gives us . If we define , then it follows that and . It's easier to see this with a diagram:   Invertability of -maps      The uniqueness of our maps basically depends on whether or not . If , then we must have . If , then then we know .  I'm thinking about as uniquely defining a dual map by the property that if for every and if there exists some for which . This allows me to define an something like an injection map that records for each whether the point we came from is the same or different.  Perhaps this is setting up something similar to Russell's Paradox : \"Does the set of all sets not containing itself contain itself?\". A set which contains itself, shouldn't, and a set which doesn't contain itself, should. Maybe we can use the notion that the map admits a retraction but does not to further show that either fixes all points or no points.  To get a better idea of what's going on, lets draw an external diagram showing both the sum and product:   Sums and product maps combined      I'm thinking this diagram is uniquely defines a map from satisfying all commutative triangles. It seems reasonable to conclude that and would satisfy this property, but our result from Exercise 9 said that implies and . Maybe we can use that to contradict the distributive property somehow.  Let's try breaking down each side of the distributive property with some diagrams.   Breaking down       Breaking down      Breaking this down like this doesn't quite seem right. The way we've defined a sum, we come from those sets rather than go to them. My sum of should probably look more like this:   Fixed break-down of      Likewise, our should be updated as well:   Fixed Break down of      Alright, let's try to combine this idea with our universal mapping property. Let's use the convention to index our objects for . Our definition of product family with maps implies for any maps there's a unique map such that all triangles below commute.   Product Family      Likewise, our definition of a sum family says that for with maps implies for any maps there's a unique map such that all triangles below commute.   Sum Family      Combining those two diagrams together:   Product and Sum Families Combined      There for any set of , there should be exactly one pair such that everything commutes.  I'm not exactly sure where to take it from here, so maybe I should just let it simmer for a while.   "
},
{
  "id": "article4-p9",
  "level": "1",
  "url": "article4-p9.html",
  "type": "Section",
  "number": "5.9",
  "title": "Article 4: Universal Mapping Properties, Part 9",
  "body": " Article 4: Universal Mapping Properties, Part 9  I think I was at least on the right track last week, so let's pick up work again on the distributive property.   Exercise 20 (part 2):   Continued from .    I've been thinking about these product and sum families, and maybe the benefit of looking at indexed objects is that it allows me to gradually extend these diagrams with the sums and products of objects. Given that I already have , maybe I can let start adding combinations of these objects under the product or sum as additional objects in our category. In particular, I'm curious about the objects , because that pair shows up in both sides of the distributive property. Let's try adding those to my diagram from last week. I'm going to colorize the graph such that my evalations from the left are in blue and right in red.   Product and Sum Families Combined and Extended      Essentially, we've defined \"triple map\" from to that corresponds uniquely to our choice of :   Since every map in this category is of the form , we can use this to define a isomorphism from .   This, in turn, allows me to define some endomaps on the spaces and by the following compositions:    Let's name these and . I'm thinking that since we constructed these by splitting an isomorphism between and , we know they at least satisfy the properties and . Perhaps the question to be asking here is whether or not  are the respective identity maps or are maps with no fixed point? This allows us to define two unique maps to based on this fixed point property.  Let's continue by adding these maps to our diagram, and complete it with the other possible sums and products needed for our distributive property:   Product and Sum Families Growing Even Bigger      Maybe I've haven't been paying enough attention to the second condition: the fact that is an isomorphism. Every admits an unique map that pairs each with the respective pair. We also saw in the last exercise that can define a map based on whether or . We know we have a unique antipodal map  such that . This is important because we could use this map to swap the roles of our terminal and initial object.  I'm thinking that the existence of this map is important because it gives us our monoid through composition with itself. This gives us an isomorphism between the following sequences of maps:  It seems we should be able to assume an isomorphism here without loss of generality.  If our distributive property is to hold for arbitrary choices of , what happens if we choose and ? Subsituting into our distributive property gives us . Our result from Exercise 9 says that any terminal object in is also initial, so .  I think I'm pretty lost again, but here's my hunch as to whats happening. Both the sum and product need to each have a unique element that functions as the identity map. This gives us unique map from for . In the same way we saw a monoid arise from , there should also be dual notion of the monoid based on , and some map which swaps the behavior of these two monoids. The invertability of maps in conflicts with this because we know there can't exist a retraction for .     Exercise 21:   If denote the generic arrow and the naked dot...    So we're given that and , and in the category we know that all maps must satisfy and to preserve source and target.  Let's start by creating a section on that categorizes each element into a dot or arrow . Let's call this \"binary\" map . Since , this gives us a unique pair of injections and .  For any arrow in , we have a unique map that decomposes the arrow into a pair of dots. I think the catch here is that this projection map needs to preserve structure when we compose it with the map .  Let's consider an arbitrary pair of arrows in . These arrows can share a source, share a target, share neither, or they could share both. Each pair of arrows corresponds with a minimum of one dot and a maximum of four. We should then be able to take a sum of those dots as per the following diagram:   Product of arrows to sum of dots      Let's consider the relationship between the dots and arrows of a finite digraph . If there are dots in the diagram, there are a maxiumum of possible arrows between those dots. For each in the set of arrows , we can assign a unique index to that arrow that preserves the source and target. This gives us unique pair of maps and . Furthermore, knowing these sets are disjoint should also give us an isomorphism preserving the separation of dots and arrows. Since we know , it follows that we have a unique isomorphism as well.  Next, let's look at a pair of arrows . If there are arrows in the originial diagram, then there are possible pairs of arrows. This gives us a map that indexes those arrows. Given that we have at most as many arrows as are possible, it follows that we should have a unique map which links the index of an arrow in with an indexed pair of points in . We can effectively use this to define a map by the property that returns if there's an arrow connecting the two dots or if not.  So what happens when we try to inject our set of dots into the set of arrows ? Each dot can be thought of as an arrow where the source and target are both the same point. This gives us a map from that pairs each point with the theoretical index of an arrow pointing to itself. We've got two cases, one where there already exists a self-loop at that point and one where this arrow is a new object of its own.  This is starting to become a lot of information, so let's see if we can organize my thoughts a bit better in a diagram:   Decomposition of by indexing dots and arrows      So where does that leave us? I'm guessing that the structure preservation of maps in our category gives us that pair of maps from and we can use the sum in our category to find the unique map for which all triangles below commute:   Illustrating the sum      Maybe the key to all is to section off the points in that contain corresponding self loop in from the dots which loop, , and dots which do not , . This gives us where each is paired with an existing arrow in . If represents how many points that applies to, then the remaining end up creating new points. Each pair of arrows can be thought of as the sum of some arrows where the source and target are different, with these objects that section off the points and loops. Could this give us the we're looking for?    I'm not exactly happy with these solutions, but at this point I think the best course of action is to move forward. It sounds like some of my confusion will be addressed with the proof of the distributive property later in the text.  "
},
{
  "id": "article4-p9-3",
  "level": "2",
  "url": "article4-p9.html#article4-p9-3",
  "type": "Example",
  "number": "5.9.1",
  "title": "Exercise 20 (part 2):.",
  "body": " Exercise 20 (part 2):   Continued from .    I've been thinking about these product and sum families, and maybe the benefit of looking at indexed objects is that it allows me to gradually extend these diagrams with the sums and products of objects. Given that I already have , maybe I can let start adding combinations of these objects under the product or sum as additional objects in our category. In particular, I'm curious about the objects , because that pair shows up in both sides of the distributive property. Let's try adding those to my diagram from last week. I'm going to colorize the graph such that my evalations from the left are in blue and right in red.   Product and Sum Families Combined and Extended      Essentially, we've defined \"triple map\" from to that corresponds uniquely to our choice of :   Since every map in this category is of the form , we can use this to define a isomorphism from .   This, in turn, allows me to define some endomaps on the spaces and by the following compositions:    Let's name these and . I'm thinking that since we constructed these by splitting an isomorphism between and , we know they at least satisfy the properties and . Perhaps the question to be asking here is whether or not  are the respective identity maps or are maps with no fixed point? This allows us to define two unique maps to based on this fixed point property.  Let's continue by adding these maps to our diagram, and complete it with the other possible sums and products needed for our distributive property:   Product and Sum Families Growing Even Bigger      Maybe I've haven't been paying enough attention to the second condition: the fact that is an isomorphism. Every admits an unique map that pairs each with the respective pair. We also saw in the last exercise that can define a map based on whether or . We know we have a unique antipodal map  such that . This is important because we could use this map to swap the roles of our terminal and initial object.  I'm thinking that the existence of this map is important because it gives us our monoid through composition with itself. This gives us an isomorphism between the following sequences of maps:  It seems we should be able to assume an isomorphism here without loss of generality.  If our distributive property is to hold for arbitrary choices of , what happens if we choose and ? Subsituting into our distributive property gives us . Our result from Exercise 9 says that any terminal object in is also initial, so .  I think I'm pretty lost again, but here's my hunch as to whats happening. Both the sum and product need to each have a unique element that functions as the identity map. This gives us unique map from for . In the same way we saw a monoid arise from , there should also be dual notion of the monoid based on , and some map which swaps the behavior of these two monoids. The invertability of maps in conflicts with this because we know there can't exist a retraction for .   "
},
{
  "id": "article4-p9-4",
  "level": "2",
  "url": "article4-p9.html#article4-p9-4",
  "type": "Example",
  "number": "5.9.4",
  "title": "Exercise 21:.",
  "body": " Exercise 21:   If denote the generic arrow and the naked dot...    So we're given that and , and in the category we know that all maps must satisfy and to preserve source and target.  Let's start by creating a section on that categorizes each element into a dot or arrow . Let's call this \"binary\" map . Since , this gives us a unique pair of injections and .  For any arrow in , we have a unique map that decomposes the arrow into a pair of dots. I think the catch here is that this projection map needs to preserve structure when we compose it with the map .  Let's consider an arbitrary pair of arrows in . These arrows can share a source, share a target, share neither, or they could share both. Each pair of arrows corresponds with a minimum of one dot and a maximum of four. We should then be able to take a sum of those dots as per the following diagram:   Product of arrows to sum of dots      Let's consider the relationship between the dots and arrows of a finite digraph . If there are dots in the diagram, there are a maxiumum of possible arrows between those dots. For each in the set of arrows , we can assign a unique index to that arrow that preserves the source and target. This gives us unique pair of maps and . Furthermore, knowing these sets are disjoint should also give us an isomorphism preserving the separation of dots and arrows. Since we know , it follows that we have a unique isomorphism as well.  Next, let's look at a pair of arrows . If there are arrows in the originial diagram, then there are possible pairs of arrows. This gives us a map that indexes those arrows. Given that we have at most as many arrows as are possible, it follows that we should have a unique map which links the index of an arrow in with an indexed pair of points in . We can effectively use this to define a map by the property that returns if there's an arrow connecting the two dots or if not.  So what happens when we try to inject our set of dots into the set of arrows ? Each dot can be thought of as an arrow where the source and target are both the same point. This gives us a map from that pairs each point with the theoretical index of an arrow pointing to itself. We've got two cases, one where there already exists a self-loop at that point and one where this arrow is a new object of its own.  This is starting to become a lot of information, so let's see if we can organize my thoughts a bit better in a diagram:   Decomposition of by indexing dots and arrows      So where does that leave us? I'm guessing that the structure preservation of maps in our category gives us that pair of maps from and we can use the sum in our category to find the unique map for which all triangles below commute:   Illustrating the sum      Maybe the key to all is to section off the points in that contain corresponding self loop in from the dots which loop, , and dots which do not , . This gives us where each is paired with an existing arrow in . If represents how many points that applies to, then the remaining end up creating new points. Each pair of arrows can be thought of as the sum of some arrows where the source and target are different, with these objects that section off the points and loops. Could this give us the we're looking for?   "
},
{
  "id": "session19",
  "level": "1",
  "url": "session19.html",
  "type": "Section",
  "number": "5.10",
  "title": "Session 19: Terminal objects",
  "body": " Session 19: Terminal objects  It's actually quite refreshing to not have any exercises this week. Well, there kind of is an exercise described but it's such a trivial solution that even I'm going to leave it to the reader and give my brain a break. I think my reading this week confirms I'm on the right track, but I need to be more precise with my statements about precisely one map moving forward.  "
},
{
  "id": "session20",
  "level": "1",
  "url": "session20.html",
  "type": "Section",
  "number": "5.11",
  "title": "Session 20: Points of an object",
  "body": " Session 20: Points of an object  Another week where there aren't any explicit exercises! I really like the table in this session a well used graphic organizer. It made me wonder if my approach to Session 17 Exercise 1 was correct, which then got me looking over my notes from Session 11. I'm curious to see a better definition of the free category on graphs makes an appearance later.  "
},
{
  "id": "session21",
  "level": "1",
  "url": "session21.html",
  "type": "Section",
  "number": "5.12",
  "title": "Session 21: Products in categories",
  "body": " Session 21: Products in categories  Okay, we have formal exercises again. Time to get back to work!   Exercise 1:   Is there a map in from the day clock ...    I think reasonable place to start in this situation is with the natural product that would assign to treating each hour a pair. The natural way to show this as a product might be the following diagram:   Illustration of the product      I'm pretty sure that's the only map in satisfying the definition of product, but perhaps the real question here is if it preserves structure and I don't think it does. The problem is that one press in the day clock always corresponds with one press in the shift clock but it does not always correspond with one press in the work shift .  Well, the question of should we increment the shift? is essentially a binary value. Maybe we can use that property to separate the points our product into a sum? The hours would form one set and rest would form the other. There's also a dual notion that would split off from the rest of the set also. It's almost like behave as terminal objects, while behave as initial objects with respect to this shift change.  Maybe I should be thinking about this mystery a sum of loops and tails . Our points (or in the alternate notation) would be mapped directly to respectively, while the digits in between those values would be mapped to the respective distance along the tails. This way we'll have some way of knowing how many presses before a shift change needs to happen.  After drawing out some sample products as per Exercise 2, it's clear that the product of a cycle with a tail is a cycle with attached tails. This means that in order to produce the 24-cycle , our mystery object would need to a cycle itself and make the only possible choice the 3-cycle .   Is this our ?      My reasoning is this. There are 24 different maps from but precisely one of them maps . Namely, the modulo operation . This has the nice property enforcing means there's a unique maps and . We can put these together to form a unique projection map such that .  Essentially, I'm stepping out and using as a lens to look at the behavior of . This works because of the following external diagram:   External diagram of      In order to convince myself that these maps preserve structure, I listed out all the points in a table.   Proof that preserves structure                                                                                                                                                                                                                                                               We've got matching columns to show the structure preservation and the overall sequence iterates through every point in the product to form a cycle of 24. The first 3 rows and last row of that table seem particularly interesting. For and , we go from a self-loop to self-loop with and . However, maps a self-loop to non-self-loop  while maps a non-self-loop to self-loop  . It seems like this property might be useful in the future.     Exercise 2:   What is the product ...    I actually approached this with Python to make it easier to find products of arbitrary graphs. Using NetworkX's draw_planar function made it easy to see cycles at a glance. You can find my scratch paper  here .  After exploring for a bit, the conjecture I came up with could be stated as follows:    Given an -cycle and an -cycle , the product is composed of cycles of length where is the greatest common divisor and is the least common multiple .    I don't know if I can prove it quite yet, but it was precisely this observation that led to my solution in Exercise 1. Assuming this holds, should have 4 cycles of length 24. I confirmed this with NetworkX simple_cycles function, assuming I did my graph product right of course.    I started working on Exercise 3, as evidenced by my Jupyter Notebook for Exercise 2, but going back to the gender problem from Session 12 made me angry. Upon realizing that I was getting angry, I decided it might be best to to call it a week here. It's difficult to be objective when you're emotionally invested in the outcome.  "
},
{
  "id": "session21-3",
  "level": "2",
  "url": "session21.html#session21-3",
  "type": "Example",
  "number": "5.12.1",
  "title": "Exercise 1:.",
  "body": " Exercise 1:   Is there a map in from the day clock ...    I think reasonable place to start in this situation is with the natural product that would assign to treating each hour a pair. The natural way to show this as a product might be the following diagram:   Illustration of the product      I'm pretty sure that's the only map in satisfying the definition of product, but perhaps the real question here is if it preserves structure and I don't think it does. The problem is that one press in the day clock always corresponds with one press in the shift clock but it does not always correspond with one press in the work shift .  Well, the question of should we increment the shift? is essentially a binary value. Maybe we can use that property to separate the points our product into a sum? The hours would form one set and rest would form the other. There's also a dual notion that would split off from the rest of the set also. It's almost like behave as terminal objects, while behave as initial objects with respect to this shift change.  Maybe I should be thinking about this mystery a sum of loops and tails . Our points (or in the alternate notation) would be mapped directly to respectively, while the digits in between those values would be mapped to the respective distance along the tails. This way we'll have some way of knowing how many presses before a shift change needs to happen.  After drawing out some sample products as per Exercise 2, it's clear that the product of a cycle with a tail is a cycle with attached tails. This means that in order to produce the 24-cycle , our mystery object would need to a cycle itself and make the only possible choice the 3-cycle .   Is this our ?      My reasoning is this. There are 24 different maps from but precisely one of them maps . Namely, the modulo operation . This has the nice property enforcing means there's a unique maps and . We can put these together to form a unique projection map such that .  Essentially, I'm stepping out and using as a lens to look at the behavior of . This works because of the following external diagram:   External diagram of      In order to convince myself that these maps preserve structure, I listed out all the points in a table.   Proof that preserves structure                                                                                                                                                                                                                                                               We've got matching columns to show the structure preservation and the overall sequence iterates through every point in the product to form a cycle of 24. The first 3 rows and last row of that table seem particularly interesting. For and , we go from a self-loop to self-loop with and . However, maps a self-loop to non-self-loop  while maps a non-self-loop to self-loop  . It seems like this property might be useful in the future.   "
},
{
  "id": "session21-4",
  "level": "2",
  "url": "session21.html#session21-4",
  "type": "Example",
  "number": "5.12.6",
  "title": "Exercise 2:.",
  "body": " Exercise 2:   What is the product ...    I actually approached this with Python to make it easier to find products of arbitrary graphs. Using NetworkX's draw_planar function made it easy to see cycles at a glance. You can find my scratch paper  here .  After exploring for a bit, the conjecture I came up with could be stated as follows:    Given an -cycle and an -cycle , the product is composed of cycles of length where is the greatest common divisor and is the least common multiple .    I don't know if I can prove it quite yet, but it was precisely this observation that led to my solution in Exercise 1. Assuming this holds, should have 4 cycles of length 24. I confirmed this with NetworkX simple_cycles function, assuming I did my graph product right of course.   "
},
{
  "id": "session21-p2",
  "level": "1",
  "url": "session21-p2.html",
  "type": "Section",
  "number": "5.13",
  "title": "Session 21: Products in categories, Part 2",
  "body": " Session 21: Products in categories, Part 2  This week is going to get a little personal. There's a reason why I'm struggling with this exercise, and I feel like that being able to articulate precisely why it's difficult is a necessary prerequisite for me to progress.   Reflections on gender   What's making this so difficult?    This problem goes back to a difference in definitions of map between myself and the authors that I first observed in Article I. My model of map allowed for the output of the map to be null while the authors' didn't. Setting aside the merits of the authors' definition for the moment, my definition of gender map has the advantage that it allows for people to be non-binary in the resulting model.   My original model of a map      In contrast, L&S have defined map in such a way that every element in the domain must have an arrow pointing to an element in the codomain. This makes the bookkeeping of maps easier because there is a one-to-one correspondence between dots and arrows, but it does not allow for the expression of non-binary people in the same way as my model. Instead, a map forces each person into one of the two genders.   Map as defined in L&S      Essentially, by assuming that if you're a person then you have a gender the authors have directly implied the contrapositive that if you don't have a gender then you're not a person . I think I might understand why they did it, but it doesn't change how messed up it is to deny personhood to an entire group like that. If the goal of this is to convince me that the author's definition of map is better than the one I started with, this exercise isn't doing a very good job at it. It's starting to look more like a vacuous statement . Given that non-binary people exist, the only logical conclusion is that the map doesn't exist. Any conditional statement beginning with if is a map from the set of persons to genders is therefore automatically true because the hypothesis is always false.  Gender has been a recurring theme throughout the text so far. We saw it in Session 5 when talking about determination problems, in Composition of opposed maps at the end of Part 2, in Article 3 Exercise 17, Session 12 Exercise 3, Session 15 Exercise 6, and now again in Session 21 Exercise 3. Looking over my notes, we've gradually moved from looking at gender being defined as a map in to a map in that preserves the structure of father and mother maps. The idea here was that gender is preserved under the operations father and mother because it becomes a constant map after composition.  The authors referred to this as objectification of the subjective , implying that we can infer a person's gender from examining the behavior of these mother and father maps. In Session 15, I joked that this model excluded Stormtroopers as people because as clones of a male they lack a well defined mother map, but the truth is that this joke was merely a reflection of the fact that this model of gender fails to work for me specifically because I don't consider myself to have a father map .  Okay, maybe the truth is a little more complicated. I have something like a father map , but it's a map from rather than so it doesn't preserve the structure of this gender map in quite the same way.  Growing up, there was a family legend suggesting that one of my ancestors was Native American. In 2020, I decided to take a DNA test to determine whether or not there was any truth to it and wrote about the experience on my blog . What I omitted from the original post was the fact that my half-sister took the same test so we could compare results, and I inadvertently found out that I was born through a process of in vitro fertilization using donor sperm. My parents chose to keep this secret from me until such a time that I was going to find it out anyway, and I'm still not exactly sure how to feel about it.  It's kind of interesting that back in Session 1 I chose to look at a product of because this parallels the properties of my father map . I have a nature father that provided genetic material and a nurture father that was actually involved in my life. Under my old definition of father map it would be easy for me to think of the output being undefined , but the definitions used in the text exclude this as a possibility for the specified domain and codomain. The fact that one input corresponds to two outputs means that my father map does not meet the criteria for an endomap on . The authors are using gender as an example of a universal property, but it's not a universal property if there are people it doesn't apply to.  I've commented before how the sections including classroom dialogues have been fun to read, but I'm not sure if this father map problem is a question I'd be able to bring up in class. While looking back at the Composition of opposed maps section for clues to this problem, the idea of being put in Alysia's shoes is terrifying. Would I have the guts to say I don't have a father map in a class full of strangers? Probably not. It's far more likely that I would lie about the personal situation in favor of a simpler mathematical model.  I think what makes it even more frustrating is the fact that the logical half of my brain is screaming IT DOESN'T EVEN MATTER!! this whole time. With the way that L&S have explicitly defined the product, there should still be exactly one map such that all triangles commute. The universal mapping property is worded in such a way that it shouldn't matter whether I have two dads or no dads there's still an unique isomorphism between the models. It's just easier to see without the additional complexity.  Looking back over Session 12 again, the authors make it very clear that the model of gender in Exercise 3 is completely detached from reality. They explicitly state that [y]ou will notice that this category contains many objects and maps that cannot reasonably be interpreted as a set of people with father and mother maps . There's this underlying notion that even if this model of gender is wrong , it can still be useful . I get that basic idea in principle, but this doesn't change how dehumanizing it feels to be excluded. How much harm are we willing to impose for the sake of utility? IVF was a relatively new procedure when the first edition of this text was printed, but more recent evidence suggests that people like myself are a rapidly growing demographic . At some point mathematicians will need to stop assuming everyone comes from a traditional family structure.  I don't think I'm exaggerating when I say this is a traumatic experience . I probably wouldn't have even recognized it had it not been for my experiences learning about trauma sensitive instruction . I have to constantly remind myself that I need to treat myself with grace and kindness in this situation.  Having read Eugenia Chen's X+Y before starting this venture through L&S, I kind of expected gender to make an appearance. What I didn't expect was to start questioning my own again. I wrote before about the ways in which I consciously chose to identify as male, but now there's this alternate definition where I'm not so sure about the label. I have a gender map in but not in . It's almost as if category theory has just handed me an objective definition by which I am non-binary, should I choose to accept it, and I feel a little frightened about the prospects.  Perhaps the big idea here is that I need to do a better job of distinguishing between maps in and maps in . In Session 12, maybe they were dropping a hint when they describe a person who is its own mother and its own father . Such a person would satisfy the properties of a terminal object in the category . This would at least give me an object to observe the system through. I could enumerate all possible maps in and sort them into two groups based on whether or not they preserve the structure in .    That kind of took a lot out of me, so I think I'm just going to sketch out some general ideas about this exercise and call it a week.   Exercise 3:   Return to Exercise 3 of Session 12...    In order for to be a product , it must satisfy the following conditions:  First, we need to show is an object in , and we need a pair of maps and . Second, we need to show that for every object and every pair of maps and , there is exactly one map for which and .  Ignoring the wildcard object for now, we can take all this information and construct an external diagram of the sitation as follows:   External Diagram of Product      The first task was essentially the goal of Session 12 Exercise 3. Last time I exhaustively listed the options, but I think there's a more direct approach where we can construct a map from the product of endomaps to the endomaps of products.  Given any in , and structure preserving maps and , we can define a map such that and .  Since needs to preserve the structure of , we must have the property that and . Likewise, must preserve and . By substituting into our definition of , we get the following:    .  Since this is true for any , we can equate the maps and . This demonstrates that is a valid map in the category.  Next, let's have a look at our projection maps defined by and . For any person , we'd defined . Applying our projection maps on the left gives us and . This gives us the properties that and . I should probably point out that the necessary structure preservation properties , , , and , all follow directly from our choice of and .  I think it might also be helpful to reproduce the diagrams from Session 12 in the style used by this Session:   Endomaps and on expressed in Product Form.      I think that one of the key ideas here is to identify a terminal object in the category . I'm going to make the claim that the following object has the desired properties:   Terminal object in      Since there's only one point in the set, any point mapped to must map everything to the only point. Since both endomaps are the identity map on this point, each endomap from the source space must get mapped to the identity in order to preserve structure. Having a terminal object allows us to define a set of 5 unique maps:       I think one of the important features of this object is that it can't be mapped back to any of elements in . There's are 4 maps from , but none of them preserve the structure of because are different maps while for the only element in . There's a unique set of isomorphism in given by , , , , and . However, none of the composite maps -maps , , preserve the structure required of maps in because there's two unique maps in the codomain and only one in the domain. This seems like a reasonable way to say our product uniquely commutes, which is what we needed to complete the proof.  I've been trying to avoid using the sum here, but I think this relation is nicely summarized by the following diagram:   External Diagram of relations between product and sum      Once we start looking at the maps from which are invertable, the number of ways of breaking them into pairs is limited. One of the things I noticed while exploring was that if I defined a parent of opposite gender map , composing this map with to get into a cycle of length 4 under the respective operation .      Some further investigation into the maps revealed other interesting patterns as well. For example, I found we have the following relations:      The structure of these relations reminded me of the presentations of dynamical systems we say is Session 15. In particular, it got me thinking about the way I was trying to standardize my presentations using an isomorphism . In particular, there were two different ways of enumerating my table of pairs:   Traversing generators along two different diagonals      These two methods both enumerate all possible values, but the do so in a slightly different order. When the ordered pairs all commute, such that , then the two representations converge to a single solution. Perhaps this is why the phrase all triangles commute does such heavy lifting.  I can't help but wonder if the point of this whole category is to generalize from my zig-zag ordering of elements into two separate operators such that increments the row and increments the column. Even two observers have different enumeration maps, each map will have a unique pair of maps such that they both agree every value in the table.  I don't think I've fully answered this exercise quite yet, but at least I'll have some better notes for next time this model shows up.    "
},
{
  "id": "session21-p2-3",
  "level": "2",
  "url": "session21-p2.html#session21-p2-3",
  "type": "Example",
  "number": "5.13.1",
  "title": "Reflections on gender.",
  "body": " Reflections on gender   What's making this so difficult?    This problem goes back to a difference in definitions of map between myself and the authors that I first observed in Article I. My model of map allowed for the output of the map to be null while the authors' didn't. Setting aside the merits of the authors' definition for the moment, my definition of gender map has the advantage that it allows for people to be non-binary in the resulting model.   My original model of a map      In contrast, L&S have defined map in such a way that every element in the domain must have an arrow pointing to an element in the codomain. This makes the bookkeeping of maps easier because there is a one-to-one correspondence between dots and arrows, but it does not allow for the expression of non-binary people in the same way as my model. Instead, a map forces each person into one of the two genders.   Map as defined in L&S      Essentially, by assuming that if you're a person then you have a gender the authors have directly implied the contrapositive that if you don't have a gender then you're not a person . I think I might understand why they did it, but it doesn't change how messed up it is to deny personhood to an entire group like that. If the goal of this is to convince me that the author's definition of map is better than the one I started with, this exercise isn't doing a very good job at it. It's starting to look more like a vacuous statement . Given that non-binary people exist, the only logical conclusion is that the map doesn't exist. Any conditional statement beginning with if is a map from the set of persons to genders is therefore automatically true because the hypothesis is always false.  Gender has been a recurring theme throughout the text so far. We saw it in Session 5 when talking about determination problems, in Composition of opposed maps at the end of Part 2, in Article 3 Exercise 17, Session 12 Exercise 3, Session 15 Exercise 6, and now again in Session 21 Exercise 3. Looking over my notes, we've gradually moved from looking at gender being defined as a map in to a map in that preserves the structure of father and mother maps. The idea here was that gender is preserved under the operations father and mother because it becomes a constant map after composition.  The authors referred to this as objectification of the subjective , implying that we can infer a person's gender from examining the behavior of these mother and father maps. In Session 15, I joked that this model excluded Stormtroopers as people because as clones of a male they lack a well defined mother map, but the truth is that this joke was merely a reflection of the fact that this model of gender fails to work for me specifically because I don't consider myself to have a father map .  Okay, maybe the truth is a little more complicated. I have something like a father map , but it's a map from rather than so it doesn't preserve the structure of this gender map in quite the same way.  Growing up, there was a family legend suggesting that one of my ancestors was Native American. In 2020, I decided to take a DNA test to determine whether or not there was any truth to it and wrote about the experience on my blog . What I omitted from the original post was the fact that my half-sister took the same test so we could compare results, and I inadvertently found out that I was born through a process of in vitro fertilization using donor sperm. My parents chose to keep this secret from me until such a time that I was going to find it out anyway, and I'm still not exactly sure how to feel about it.  It's kind of interesting that back in Session 1 I chose to look at a product of because this parallels the properties of my father map . I have a nature father that provided genetic material and a nurture father that was actually involved in my life. Under my old definition of father map it would be easy for me to think of the output being undefined , but the definitions used in the text exclude this as a possibility for the specified domain and codomain. The fact that one input corresponds to two outputs means that my father map does not meet the criteria for an endomap on . The authors are using gender as an example of a universal property, but it's not a universal property if there are people it doesn't apply to.  I've commented before how the sections including classroom dialogues have been fun to read, but I'm not sure if this father map problem is a question I'd be able to bring up in class. While looking back at the Composition of opposed maps section for clues to this problem, the idea of being put in Alysia's shoes is terrifying. Would I have the guts to say I don't have a father map in a class full of strangers? Probably not. It's far more likely that I would lie about the personal situation in favor of a simpler mathematical model.  I think what makes it even more frustrating is the fact that the logical half of my brain is screaming IT DOESN'T EVEN MATTER!! this whole time. With the way that L&S have explicitly defined the product, there should still be exactly one map such that all triangles commute. The universal mapping property is worded in such a way that it shouldn't matter whether I have two dads or no dads there's still an unique isomorphism between the models. It's just easier to see without the additional complexity.  Looking back over Session 12 again, the authors make it very clear that the model of gender in Exercise 3 is completely detached from reality. They explicitly state that [y]ou will notice that this category contains many objects and maps that cannot reasonably be interpreted as a set of people with father and mother maps . There's this underlying notion that even if this model of gender is wrong , it can still be useful . I get that basic idea in principle, but this doesn't change how dehumanizing it feels to be excluded. How much harm are we willing to impose for the sake of utility? IVF was a relatively new procedure when the first edition of this text was printed, but more recent evidence suggests that people like myself are a rapidly growing demographic . At some point mathematicians will need to stop assuming everyone comes from a traditional family structure.  I don't think I'm exaggerating when I say this is a traumatic experience . I probably wouldn't have even recognized it had it not been for my experiences learning about trauma sensitive instruction . I have to constantly remind myself that I need to treat myself with grace and kindness in this situation.  Having read Eugenia Chen's X+Y before starting this venture through L&S, I kind of expected gender to make an appearance. What I didn't expect was to start questioning my own again. I wrote before about the ways in which I consciously chose to identify as male, but now there's this alternate definition where I'm not so sure about the label. I have a gender map in but not in . It's almost as if category theory has just handed me an objective definition by which I am non-binary, should I choose to accept it, and I feel a little frightened about the prospects.  Perhaps the big idea here is that I need to do a better job of distinguishing between maps in and maps in . In Session 12, maybe they were dropping a hint when they describe a person who is its own mother and its own father . Such a person would satisfy the properties of a terminal object in the category . This would at least give me an object to observe the system through. I could enumerate all possible maps in and sort them into two groups based on whether or not they preserve the structure in .   "
},
{
  "id": "session21-p2-5",
  "level": "2",
  "url": "session21-p2.html#session21-p2-5",
  "type": "Example",
  "number": "5.13.4",
  "title": "Exercise 3:.",
  "body": " Exercise 3:   Return to Exercise 3 of Session 12...    In order for to be a product , it must satisfy the following conditions:  First, we need to show is an object in , and we need a pair of maps and . Second, we need to show that for every object and every pair of maps and , there is exactly one map for which and .  Ignoring the wildcard object for now, we can take all this information and construct an external diagram of the sitation as follows:   External Diagram of Product      The first task was essentially the goal of Session 12 Exercise 3. Last time I exhaustively listed the options, but I think there's a more direct approach where we can construct a map from the product of endomaps to the endomaps of products.  Given any in , and structure preserving maps and , we can define a map such that and .  Since needs to preserve the structure of , we must have the property that and . Likewise, must preserve and . By substituting into our definition of , we get the following:    .  Since this is true for any , we can equate the maps and . This demonstrates that is a valid map in the category.  Next, let's have a look at our projection maps defined by and . For any person , we'd defined . Applying our projection maps on the left gives us and . This gives us the properties that and . I should probably point out that the necessary structure preservation properties , , , and , all follow directly from our choice of and .  I think it might also be helpful to reproduce the diagrams from Session 12 in the style used by this Session:   Endomaps and on expressed in Product Form.      I think that one of the key ideas here is to identify a terminal object in the category . I'm going to make the claim that the following object has the desired properties:   Terminal object in      Since there's only one point in the set, any point mapped to must map everything to the only point. Since both endomaps are the identity map on this point, each endomap from the source space must get mapped to the identity in order to preserve structure. Having a terminal object allows us to define a set of 5 unique maps:       I think one of the important features of this object is that it can't be mapped back to any of elements in . There's are 4 maps from , but none of them preserve the structure of because are different maps while for the only element in . There's a unique set of isomorphism in given by , , , , and . However, none of the composite maps -maps , , preserve the structure required of maps in because there's two unique maps in the codomain and only one in the domain. This seems like a reasonable way to say our product uniquely commutes, which is what we needed to complete the proof.  I've been trying to avoid using the sum here, but I think this relation is nicely summarized by the following diagram:   External Diagram of relations between product and sum      Once we start looking at the maps from which are invertable, the number of ways of breaking them into pairs is limited. One of the things I noticed while exploring was that if I defined a parent of opposite gender map , composing this map with to get into a cycle of length 4 under the respective operation .      Some further investigation into the maps revealed other interesting patterns as well. For example, I found we have the following relations:      The structure of these relations reminded me of the presentations of dynamical systems we say is Session 15. In particular, it got me thinking about the way I was trying to standardize my presentations using an isomorphism . In particular, there were two different ways of enumerating my table of pairs:   Traversing generators along two different diagonals      These two methods both enumerate all possible values, but the do so in a slightly different order. When the ordered pairs all commute, such that , then the two representations converge to a single solution. Perhaps this is why the phrase all triangles commute does such heavy lifting.  I can't help but wonder if the point of this whole category is to generalize from my zig-zag ordering of elements into two separate operators such that increments the row and increments the column. Even two observers have different enumeration maps, each map will have a unique pair of maps such that they both agree every value in the table.  I don't think I've fully answered this exercise quite yet, but at least I'll have some better notes for next time this model shows up.   "
},
{
  "id": "session22",
  "level": "1",
  "url": "session22.html",
  "type": "Section",
  "number": "5.14",
  "title": "Session 22: Universal mapping properties, Incidence Relations",
  "body": " Session 22: Universal mapping properties, Incidence Relations  I didn't quite make it all the way through the first exercise here, but that's okay. I think I made it far enough that I have some ideas to work with.   Exercise 1: (part 1\/?)   Consider the diagram of graphs...    We're given a diagram of graphs with the shape of the bipointed object below:   Given Diagram for Session 22 Exercise 1      I'm thinking that the idea here is replace the objects representing our domain and codomain with dots , so we can treat the maps like arrows . There should be unique maps to the terminal object that have the following structure:   Replacing objects with dots      All together, there are 5 objects in the diagram: 3 dots referring to respectively, and two arrows referring to the respective projection maps. I'm going to use this to construct a table of elements and their respective source and target maps by using self referential arrows for the points:   List of objects in diagram    Object  Description  Source  Target    0   0  0    1   1  1    2   2  2    3   0  1    4   0  2     The two arrows in the diagram represent the two different maps from , so we can map from to the above diagram in two distinct ways:   Maps from arrow to diagram      These two maps are incident at the one dot that represented in our original diagram. We can name these by referring to the source and target maps which are the only two maps :   Two Unique Maps from      This means we can express the incidence relation by the equation , which in the categorgy should imply or basically asserting the commutativity of the diagram below:   Incidence relation expressed as commutative diagram      I think I'm on the right track here, but I'm not quite sure how it fits into the big picture yet.    "
},
{
  "id": "session22-3",
  "level": "2",
  "url": "session22.html#session22-3",
  "type": "Example",
  "number": "5.14.1",
  "title": "Exercise 1: (part 1\/?).",
  "body": " Exercise 1: (part 1\/?)   Consider the diagram of graphs...    We're given a diagram of graphs with the shape of the bipointed object below:   Given Diagram for Session 22 Exercise 1      I'm thinking that the idea here is replace the objects representing our domain and codomain with dots , so we can treat the maps like arrows . There should be unique maps to the terminal object that have the following structure:   Replacing objects with dots      All together, there are 5 objects in the diagram: 3 dots referring to respectively, and two arrows referring to the respective projection maps. I'm going to use this to construct a table of elements and their respective source and target maps by using self referential arrows for the points:   List of objects in diagram    Object  Description  Source  Target    0   0  0    1   1  1    2   2  2    3   0  1    4   0  2     The two arrows in the diagram represent the two different maps from , so we can map from to the above diagram in two distinct ways:   Maps from arrow to diagram      These two maps are incident at the one dot that represented in our original diagram. We can name these by referring to the source and target maps which are the only two maps :   Two Unique Maps from      This means we can express the incidence relation by the equation , which in the categorgy should imply or basically asserting the commutativity of the diagram below:   Incidence relation expressed as commutative diagram      I think I'm on the right track here, but I'm not quite sure how it fits into the big picture yet.   "
},
{
  "id": "session22-p2",
  "level": "1",
  "url": "session22-p2.html",
  "type": "Section",
  "number": "5.15",
  "title": "Session 22: Universal mapping properties, Incidence Relations, Part 2",
  "body": " Session 22: Universal mapping properties, Incidence Relations, Part 2  Continuing from last week...   Exercise 1: (part 2\/?)   Consider the diagram of graphs...    It look's like the reason why I might have been getting confused was that my commutative diagram was incorrect. I think part of the confusion is that I'm confusing the objects in with the maps to the terminal object given by so I'm not really sure if my maps are the same as the projection maps or not. Perhaps it will be easier if I name my three dots  relative to the respective terminal maps . These should form a unique commutive diagram as follows:   Relation between dots and product      The maps are defined by being the only two maps from that preserve source and target relations. The fact that these arrows share a common source can be expressed through the commutative diagram below:   Incidence relation expressed as commutative diagram (Fixed?)      Suppose we have two arbitrary arrows with the same source. We can express that fact as or saying the following diagram commutes:   Incidence relation of arrows with shared source      If , the fact that these arrows share a source implies the targets of these arrows must be different. Having a map in gives us a pair of maps such that and . Knowing that means the set is isomorphic to the shape . Since the set is also isomorphic to , there's a guaranteed isomorphism between them. Since we have shown has the form of a product, we can these maps together as follows:   Completed diagram showing product      I suppose I should also note some how that these maps might reduce but the same basic structure should still hold.    I'm still not exactly confident in all this, so I'm going to leave open the possibility of coming back here after I have some time to look at Exercise 2.  "
},
{
  "id": "session22-p2-3",
  "level": "2",
  "url": "session22-p2.html#session22-p2-3",
  "type": "Example",
  "number": "5.15.1",
  "title": "Exercise 1: (part 2\/?).",
  "body": " Exercise 1: (part 2\/?)   Consider the diagram of graphs...    It look's like the reason why I might have been getting confused was that my commutative diagram was incorrect. I think part of the confusion is that I'm confusing the objects in with the maps to the terminal object given by so I'm not really sure if my maps are the same as the projection maps or not. Perhaps it will be easier if I name my three dots  relative to the respective terminal maps . These should form a unique commutive diagram as follows:   Relation between dots and product      The maps are defined by being the only two maps from that preserve source and target relations. The fact that these arrows share a common source can be expressed through the commutative diagram below:   Incidence relation expressed as commutative diagram (Fixed?)      Suppose we have two arbitrary arrows with the same source. We can express that fact as or saying the following diagram commutes:   Incidence relation of arrows with shared source      If , the fact that these arrows share a source implies the targets of these arrows must be different. Having a map in gives us a pair of maps such that and . Knowing that means the set is isomorphic to the shape . Since the set is also isomorphic to , there's a guaranteed isomorphism between them. Since we have shown has the form of a product, we can these maps together as follows:   Completed diagram showing product      I suppose I should also note some how that these maps might reduce but the same basic structure should still hold.   "
},
{
  "id": "session22-p3",
  "level": "1",
  "url": "session22-p3.html",
  "type": "Section",
  "number": "5.16",
  "title": "Session 22: Universal mapping properties, Incidence Relations, Part 3",
  "body": " Session 22: Universal mapping properties, Incidence Relations, Part 3  I think I'm going to start off on the second exercise this week so that I can keep moving forward. Maybe this will afford me some time to look at Session 15.   Exercise 2:    What is a figure of shape...     Our given shape is defined as . We have collect of three dots which I'll name with and two arrows  which I'll name such that and , and such that and .  There are 3 choose 2 = 3 ways that two of our three dots could overlap. In the case where ,it produces the shape , for it produces , and for it produces the shape . There's precisely one way all three dots could overlap such that which has shape . This last option admits one additional way of being singular, and that is when , this produces the final shape .     Exercise 3 (implicit):   Reflections on how this stuff applies to where I got stuck Session 15...    In Session 15, our endomaps and had the following shapes:   Definitions of and      Since these are both endomaps, we know there's a isomorphism betweeen dots and arrows. For every there's a unique arrow originating at the respective dot, and similarly an arrow for each . What varies from dot to dot are the number of arrows with that dot as a target. During Session 15 (Part 5) I was referring to a map I called incoming arrow count , which I think might connected to this notion of incidence , but at the time I was focused more on dots than arrows so maybe something will reveal itself by looking at them as arrows instead.  I'm also wondering if this object that was introduced here is related to what I've been calling tails . If I take to be the naked dot and to be the naked arrow, then I can use to represent arbitrarily long distances to a terminal object. This might give me a more objective way of defining the map I previously called number of steps to stabilize .  Speaking of terminal objects, I've been thinking that my answer to Article 4 Exercise 4 might be incorrect. My assumption that misses the fact that any n-cycle is potentially a terminal object in . I think the distinction that I failed to make was that and aren't necessarily the same map, they just need to have inverses because there exactly one arrow leading into and out of each point. Perhaps the terminal object in could be defined diectly as some factor of the identity map.  The other thing that I've been curious about was Article 4 Exercise 6. What if the special property of being hinted at here was really the uniqueness of prime factorizations? Given any number , there's a unique representation where are the prime numbers and . This would explain our little side venture to prove in Session 21 (Part 1) .  After playing around with this a bit in Python , I have a couple of observations. First, I noticed that my incoming arrow counts is essentially G.degree(N)-1 and I think this off-by-one error might be related to why I was short maps in Session 15.  The other thing I started thinking about is the choice of notation. I began wondering if the words choice of arrow , binary , cycle , and dot has a double meaning when interpreted as the sequence of maps . If are the initial and terminal objects in the category, any map corresponds to analagous sequence by treating the naked arrow as the initial object and naked dot as the terminal object .  It also seemed weird how the authors introduce the heavy arrow to represent epimorphism then proceed to not use it again for the rest of the session. If the naming of objects has a double meaning, then maybe the choice of are important also. Perhaps the maps defined by retraction , source , and target can be defined by sasifying the associative property on the sequence of maps .  I also found myself finding interesting properties of the maps . I think I'm starting to understand the relevance of defining incidence relations. By stepping out through mapping and we can use the unique -map compare whether or not and are the same map . If they are, then we have a terminal object in . If they are not, then define have a new pair of maps which we can apply the process two a second time.    In addition to the work here done in Python, I also spent some time this week learning Lean through this little Natural Number Game . I'm still a ways away from articulating these exercises as proofs in Lean, but I'm starting to see some connections between World and the problems I'm working on here.  "
},
{
  "id": "session22-p3-3",
  "level": "2",
  "url": "session22-p3.html#session22-p3-3",
  "type": "Example",
  "number": "5.16.1",
  "title": "Exercise 2:.",
  "body": " Exercise 2:    What is a figure of shape...     Our given shape is defined as . We have collect of three dots which I'll name with and two arrows  which I'll name such that and , and such that and .  There are 3 choose 2 = 3 ways that two of our three dots could overlap. In the case where ,it produces the shape , for it produces , and for it produces the shape . There's precisely one way all three dots could overlap such that which has shape . This last option admits one additional way of being singular, and that is when , this produces the final shape .   "
},
{
  "id": "session22-p3-4",
  "level": "2",
  "url": "session22-p3.html#session22-p3-4",
  "type": "Example",
  "number": "5.16.2",
  "title": "Exercise 3 (implicit):.",
  "body": " Exercise 3 (implicit):   Reflections on how this stuff applies to where I got stuck Session 15...    In Session 15, our endomaps and had the following shapes:   Definitions of and      Since these are both endomaps, we know there's a isomorphism betweeen dots and arrows. For every there's a unique arrow originating at the respective dot, and similarly an arrow for each . What varies from dot to dot are the number of arrows with that dot as a target. During Session 15 (Part 5) I was referring to a map I called incoming arrow count , which I think might connected to this notion of incidence , but at the time I was focused more on dots than arrows so maybe something will reveal itself by looking at them as arrows instead.  I'm also wondering if this object that was introduced here is related to what I've been calling tails . If I take to be the naked dot and to be the naked arrow, then I can use to represent arbitrarily long distances to a terminal object. This might give me a more objective way of defining the map I previously called number of steps to stabilize .  Speaking of terminal objects, I've been thinking that my answer to Article 4 Exercise 4 might be incorrect. My assumption that misses the fact that any n-cycle is potentially a terminal object in . I think the distinction that I failed to make was that and aren't necessarily the same map, they just need to have inverses because there exactly one arrow leading into and out of each point. Perhaps the terminal object in could be defined diectly as some factor of the identity map.  The other thing that I've been curious about was Article 4 Exercise 6. What if the special property of being hinted at here was really the uniqueness of prime factorizations? Given any number , there's a unique representation where are the prime numbers and . This would explain our little side venture to prove in Session 21 (Part 1) .  After playing around with this a bit in Python , I have a couple of observations. First, I noticed that my incoming arrow counts is essentially G.degree(N)-1 and I think this off-by-one error might be related to why I was short maps in Session 15.  The other thing I started thinking about is the choice of notation. I began wondering if the words choice of arrow , binary , cycle , and dot has a double meaning when interpreted as the sequence of maps . If are the initial and terminal objects in the category, any map corresponds to analagous sequence by treating the naked arrow as the initial object and naked dot as the terminal object .  It also seemed weird how the authors introduce the heavy arrow to represent epimorphism then proceed to not use it again for the rest of the session. If the naming of objects has a double meaning, then maybe the choice of are important also. Perhaps the maps defined by retraction , source , and target can be defined by sasifying the associative property on the sequence of maps .  I also found myself finding interesting properties of the maps . I think I'm starting to understand the relevance of defining incidence relations. By stepping out through mapping and we can use the unique -map compare whether or not and are the same map . If they are, then we have a terminal object in . If they are not, then define have a new pair of maps which we can apply the process two a second time.   "
},
{
  "id": "session23",
  "level": "1",
  "url": "session23.html",
  "type": "Section",
  "number": "5.17",
  "title": "Session 23: More on universal mapping properties",
  "body": " Session 23: More on universal mapping properties  Oh boy! More on universal mapping properties!   Exercise 1: (part 1\/?)   Formulate and prove in two ways...    Alright, I think I need to start here by assuming that the category has an initial object and terminal object . To make the definitions of these simplier, I'm going to introduce the notation to denote there exists precisely one map with domain and codomain .    We can rewrite these definitions using the reflexive property to demonstrate that and . Since every object in the category has an identity map, these two endomaps must be the respective identities and .  As a category, must also have an associative property such that for any maps we must have . In particular, let's consider the case where , and . Since there is only one map , both sides of the associative property must equal to this map. Namely, .  Now suppose we have an arbitrary pair of maps and . Use the definition of terminal object, we can define two unique maps: and . Likewise, the definition of initial object gives us two more: and . Let's draw these out in a commutative diagram.   Commutative diagram of product with initial and terminal objects    The uniqueness of our maps means that we can use them to describe some equivalences between our other maps.      Since we already know , we can combine the results above to say .  Now let's consider a pair of products and in this category. We'll need three maps for each: and respectively. The uniqueness of initial and terminal objects implies we have a set of unique maps , , , and These maps can be arranged together in the following diagram:      Suppose for a moment that the unique map is an isomorphism. The existence of a map would immediately define an isomorphism through the following unique compositions:  Having such maps would also define an isomorphism between , uniquely determined by the following compositions:  Since that would essentially complete our proof, I think we can proceed with the assumption that there is no inverse for . The non-existence of an inverse implies that we're either missing a section or retraction .  All of our maps come from , where the initial object is the empty set . In , there is a map from but not from . If the nature of initial and terminal objects is preserved, then we must have uniquely defined isomorpisms and . The fact that is not invertable means there must be at least one point that gets lost in the process.  I think this allows use to define a unique composition sequence: If that's is a unique composition, so is the following:   I've been wondering if this map sequence is the reason why the authors introduced the heavy arrow notation in Session 22. There is at most one such map the composition is equal to the identity map . This map is an epimorphism because it can be precomposed to any object without changing it.  This means we can still use the same techique to form our bijections, it just has one additional stop along the way:      Assuming that's correct, that would complete our direct proof. However, stepping out through the singleton in feels like a hack . I can't help but wonder if there's a better approach to this. Maybe I can somehow use as an initial object to enumerate the points of ? That would certainly make things a lot easier.    I still feel like I'm missing something, so I think I'm going to break there and explore the second half of the exercise next week.  "
},
{
  "id": "session23-3",
  "level": "2",
  "url": "session23.html#session23-3",
  "type": "Example",
  "number": "5.17.1",
  "title": "Exercise 1: (part 1\/?).",
  "body": " Exercise 1: (part 1\/?)   Formulate and prove in two ways...    Alright, I think I need to start here by assuming that the category has an initial object and terminal object . To make the definitions of these simplier, I'm going to introduce the notation to denote there exists precisely one map with domain and codomain .    We can rewrite these definitions using the reflexive property to demonstrate that and . Since every object in the category has an identity map, these two endomaps must be the respective identities and .  As a category, must also have an associative property such that for any maps we must have . In particular, let's consider the case where , and . Since there is only one map , both sides of the associative property must equal to this map. Namely, .  Now suppose we have an arbitrary pair of maps and . Use the definition of terminal object, we can define two unique maps: and . Likewise, the definition of initial object gives us two more: and . Let's draw these out in a commutative diagram.   Commutative diagram of product with initial and terminal objects    The uniqueness of our maps means that we can use them to describe some equivalences between our other maps.      Since we already know , we can combine the results above to say .  Now let's consider a pair of products and in this category. We'll need three maps for each: and respectively. The uniqueness of initial and terminal objects implies we have a set of unique maps , , , and These maps can be arranged together in the following diagram:      Suppose for a moment that the unique map is an isomorphism. The existence of a map would immediately define an isomorphism through the following unique compositions:  Having such maps would also define an isomorphism between , uniquely determined by the following compositions:  Since that would essentially complete our proof, I think we can proceed with the assumption that there is no inverse for . The non-existence of an inverse implies that we're either missing a section or retraction .  All of our maps come from , where the initial object is the empty set . In , there is a map from but not from . If the nature of initial and terminal objects is preserved, then we must have uniquely defined isomorpisms and . The fact that is not invertable means there must be at least one point that gets lost in the process.  I think this allows use to define a unique composition sequence: If that's is a unique composition, so is the following:   I've been wondering if this map sequence is the reason why the authors introduced the heavy arrow notation in Session 22. There is at most one such map the composition is equal to the identity map . This map is an epimorphism because it can be precomposed to any object without changing it.  This means we can still use the same techique to form our bijections, it just has one additional stop along the way:      Assuming that's correct, that would complete our direct proof. However, stepping out through the singleton in feels like a hack . I can't help but wonder if there's a better approach to this. Maybe I can somehow use as an initial object to enumerate the points of ? That would certainly make things a lot easier.   "
},
{
  "id": "session23-p2",
  "level": "1",
  "url": "session23-p2.html",
  "type": "Section",
  "number": "5.18",
  "title": "Session 23: More on universal mapping properties, Part 2",
  "body": " Session 23: More on universal mapping properties, Part 2  Let's pick up with the second half of Exercise 1:   Exercise 1: (Part 2\/?)   Continued from last week...    Let's begin with reconstructing the diagram:   Structure of maps in    The goal here is use these objects and in as the basis for constructing a new category .  We define an object in as an object of equiped with a pair of maps to and .  We define a map in as a map in which preserves the structure of the commutative diagram above. Specifically, any map in must satisfy the relations and .  Since every -map comes from a map , it must have a defined domain and codomain. Likewise, since the objects in come from objects in they must each have an identity map. For any object in , a simple substitution and shows the identity maps from preserve structure.  Let's take a second to verify that is closed under composition. Consider two maps .   Composition in    We can assume the following relations from the definition of -map:    In order for to be a valid -map, we need to establish both and . This follows easily from the associative property in and substitution with the relations above:    The only thing left to prove is the associative law. Let's consider a set of three -maps . Each of these maps needs to correspond with a pair of maps to and , as per the following diagram:   Associative property in    By our definition of composition above, we know we have satisfying and . Postcompose with to get with and .  Similarly, we must have satisfying and . Precompose with to get with and .  Since we know that the associative property holds in and have shown that it satisfies the structure preservation of , that should complete the proof that is a valid category.  Knowing is a category, what should the terminal object look like? Per definition, a terminal object should have the property that for every object in , there is exactly one map . As an object in , the terminal object must be accompanied by a pair of maps and such that and where are the respective pair of maps associated with .  Since every object has an identity map, this rule must also apply to . Since any is unique, then the uniqueness of implies it could only be the map . Clearly satisfies and .  Now suppose we have a -map , which we should by the definition of terminal object. In order for this map to be a map in , we'd need a pair of maps and which preserve the structure of the following diagram:   Structure preservation of    These maps need to preserve the structure of the relations and . Since is a map from , of which there is only one, we're forced to conclude that . Precomposing our structure preserving relations with gives us:    If we take and precompose with again, we get which simplifies to whichs implies that . It would also follow that is uniquely determined by the sequence of maps . Essentially, since the objects are all isomorphic to each other in we can use the uniqueness of the maps there to guarantee the uniqueness of our maps in .  I'm thinking that the idea here is that there is not just a bijection between the objects and , but one between the pairs of maps and themselves. Consequently, any bijection between automatically defines an unique bijection through composition.     Exercise 2: (part 1\/?)   Try to create the definition of a 'sum'...    I attempted something similar to this back in Article 4 Exercise 19. We let be a possibly empty set of indices and let be a possibly duplicated object in the category. This gave us the following definition of sum family :   I'm not sure if I need all that for this exercise though. I think I might get away with using only the definitions of initial object, terminal object, and sum. I'm going to mirror the wording of product from Session 21.     is an initial object of if for every object of there is exactly one -map .       is an terminal object of if for every object of there is exactly one -map .      Suppose that and are objects in a category . A sum of and (in ) is:  an object in  a pair of maps, in satisfying: for every object and every pair of maps , there is exactly one map    Pictorially:   Commutative diagram of sum      I think we'll also need the following uniqueness theorem, which we proved in Article 4 Exercise 7:    If are both initial in then the unique map is an isomorphism.    In the category , we can think of our initial object as the empty set . There is a unique map from to any other object in because there's no elements for any arrows to originate at. Likewise, we can think of the terminal object in as the singleton since there's only one object for the arrows to point to.  By substituting and , we can form the following diagram:   Sum of initial and terminal object    Since is a unique map, it follows that . Likewise, we must also have and . We can subsitute our expressions to get  There is no map from in , so the only possible choice of for the diagram above is the sum with respectively.  There's a lot to unpack here but I'm wondering if the importance is that looping the sequence provides a way to construct the monoid . Given a map , the compositions would give us all the information we need about the structure of .    I think that's a good place to stop for the week and let this sink in. Until next time!  "
},
{
  "id": "session23-p2-3",
  "level": "2",
  "url": "session23-p2.html#session23-p2-3",
  "type": "Example",
  "number": "5.18.1",
  "title": "Exercise 1: (Part 2\/?).",
  "body": " Exercise 1: (Part 2\/?)   Continued from last week...    Let's begin with reconstructing the diagram:   Structure of maps in    The goal here is use these objects and in as the basis for constructing a new category .  We define an object in as an object of equiped with a pair of maps to and .  We define a map in as a map in which preserves the structure of the commutative diagram above. Specifically, any map in must satisfy the relations and .  Since every -map comes from a map , it must have a defined domain and codomain. Likewise, since the objects in come from objects in they must each have an identity map. For any object in , a simple substitution and shows the identity maps from preserve structure.  Let's take a second to verify that is closed under composition. Consider two maps .   Composition in    We can assume the following relations from the definition of -map:    In order for to be a valid -map, we need to establish both and . This follows easily from the associative property in and substitution with the relations above:    The only thing left to prove is the associative law. Let's consider a set of three -maps . Each of these maps needs to correspond with a pair of maps to and , as per the following diagram:   Associative property in    By our definition of composition above, we know we have satisfying and . Postcompose with to get with and .  Similarly, we must have satisfying and . Precompose with to get with and .  Since we know that the associative property holds in and have shown that it satisfies the structure preservation of , that should complete the proof that is a valid category.  Knowing is a category, what should the terminal object look like? Per definition, a terminal object should have the property that for every object in , there is exactly one map . As an object in , the terminal object must be accompanied by a pair of maps and such that and where are the respective pair of maps associated with .  Since every object has an identity map, this rule must also apply to . Since any is unique, then the uniqueness of implies it could only be the map . Clearly satisfies and .  Now suppose we have a -map , which we should by the definition of terminal object. In order for this map to be a map in , we'd need a pair of maps and which preserve the structure of the following diagram:   Structure preservation of    These maps need to preserve the structure of the relations and . Since is a map from , of which there is only one, we're forced to conclude that . Precomposing our structure preserving relations with gives us:    If we take and precompose with again, we get which simplifies to whichs implies that . It would also follow that is uniquely determined by the sequence of maps . Essentially, since the objects are all isomorphic to each other in we can use the uniqueness of the maps there to guarantee the uniqueness of our maps in .  I'm thinking that the idea here is that there is not just a bijection between the objects and , but one between the pairs of maps and themselves. Consequently, any bijection between automatically defines an unique bijection through composition.   "
},
{
  "id": "session23-p2-4",
  "level": "2",
  "url": "session23-p2.html#session23-p2-4",
  "type": "Example",
  "number": "5.18.2",
  "title": "Exercise 2: (part 1\/?).",
  "body": " Exercise 2: (part 1\/?)   Try to create the definition of a 'sum'...    I attempted something similar to this back in Article 4 Exercise 19. We let be a possibly empty set of indices and let be a possibly duplicated object in the category. This gave us the following definition of sum family :   I'm not sure if I need all that for this exercise though. I think I might get away with using only the definitions of initial object, terminal object, and sum. I'm going to mirror the wording of product from Session 21.     is an initial object of if for every object of there is exactly one -map .       is an terminal object of if for every object of there is exactly one -map .      Suppose that and are objects in a category . A sum of and (in ) is:  an object in  a pair of maps, in satisfying: for every object and every pair of maps , there is exactly one map    Pictorially:   Commutative diagram of sum      I think we'll also need the following uniqueness theorem, which we proved in Article 4 Exercise 7:    If are both initial in then the unique map is an isomorphism.    In the category , we can think of our initial object as the empty set . There is a unique map from to any other object in because there's no elements for any arrows to originate at. Likewise, we can think of the terminal object in as the singleton since there's only one object for the arrows to point to.  By substituting and , we can form the following diagram:   Sum of initial and terminal object    Since is a unique map, it follows that . Likewise, we must also have and . We can subsitute our expressions to get  There is no map from in , so the only possible choice of for the diagram above is the sum with respectively.  There's a lot to unpack here but I'm wondering if the importance is that looping the sequence provides a way to construct the monoid . Given a map , the compositions would give us all the information we need about the structure of .   "
},
{
  "id": "session23-p3",
  "level": "1",
  "url": "session23-p3.html",
  "type": "Section",
  "number": "5.19",
  "title": "Session 23: More on universal mapping properties, Part 3",
  "body": " Session 23: More on universal mapping properties, Part 3  I didn't really make any progress on the exercise I started last week, so I'm just going to try and get some ideas out. I also checked in the Python code that I was playing with here . Looking back, it seems like it's as all over the place as I am.   Session 23 Brain-storming   Trying to collect my thoughts...    One of the things I was exploring in Python was about how I used the adjacency matrix to develop my presentation. I started wondering if there was a connection between my ones_vec and the universal quantifier. Since each node in the graph corresponds to a one-hot vector, I thought maybe this vector could stand in for all points .  One of the interesting things I observed is that the ones_vec took twelve steps for to repeat but only five steps for . This was strange because I expected the product of a two-cycle and three-cycle to take a minimum of six steps. I think the reason this is shorter has to do with how multiplication by my ones_vec contains less information than the exponents of the matrix itself.  The other idea I found myself playing with was the idea that my previous bijection , using a diagonal based ordering, wasn't necessarily unique . By using the uniqueness of prime factorizations, however, it should be possible to build a unique map for arbitrarily large . Using factors of two, I was able to build a second bijection . The only troublesome part of this process was getting the domain and codomain to align properly.  With these bijections comes this idea of uplifting an endomap . My idea is that if I can enumerate the points of with , then each arrow of the endomap can be mapped to a number in that expresses the source-target relationship in . This only works on endomaps because of the one-to-one relationship, but maybe I can use the prime factorization to extend this idea to an arbitrary graph somehow.  I've also found myself thinking about the gender problems again this week. In particular, I'm wondering if the real reason for the use of the word gender is really just a surface level similarity between the chromosome pairs XX and XY with maps defined over domain and codomains specifed by and . This is consistent with my hypotheses about my two missing maps from Session 15 being the result of improperly accounting for the case where and are potentially the same object.  In the same vein, I'm also wondering if I've been thinking about the binary relationship of wrong. I've been thinking of these two objects like values, but maybe the binary operation I should be paying attention to is set membership itself. If I have some map , maybe there's some way to check if using the properties of the sum ?    "
},
{
  "id": "session23-p3-3",
  "level": "2",
  "url": "session23-p3.html#session23-p3-3",
  "type": "Example",
  "number": "5.19.1",
  "title": "Session 23 Brain-storming.",
  "body": " Session 23 Brain-storming   Trying to collect my thoughts...    One of the things I was exploring in Python was about how I used the adjacency matrix to develop my presentation. I started wondering if there was a connection between my ones_vec and the universal quantifier. Since each node in the graph corresponds to a one-hot vector, I thought maybe this vector could stand in for all points .  One of the interesting things I observed is that the ones_vec took twelve steps for to repeat but only five steps for . This was strange because I expected the product of a two-cycle and three-cycle to take a minimum of six steps. I think the reason this is shorter has to do with how multiplication by my ones_vec contains less information than the exponents of the matrix itself.  The other idea I found myself playing with was the idea that my previous bijection , using a diagonal based ordering, wasn't necessarily unique . By using the uniqueness of prime factorizations, however, it should be possible to build a unique map for arbitrarily large . Using factors of two, I was able to build a second bijection . The only troublesome part of this process was getting the domain and codomain to align properly.  With these bijections comes this idea of uplifting an endomap . My idea is that if I can enumerate the points of with , then each arrow of the endomap can be mapped to a number in that expresses the source-target relationship in . This only works on endomaps because of the one-to-one relationship, but maybe I can use the prime factorization to extend this idea to an arbitrary graph somehow.  I've also found myself thinking about the gender problems again this week. In particular, I'm wondering if the real reason for the use of the word gender is really just a surface level similarity between the chromosome pairs XX and XY with maps defined over domain and codomains specifed by and . This is consistent with my hypotheses about my two missing maps from Session 15 being the result of improperly accounting for the case where and are potentially the same object.  In the same vein, I'm also wondering if I've been thinking about the binary relationship of wrong. I've been thinking of these two objects like values, but maybe the binary operation I should be paying attention to is set membership itself. If I have some map , maybe there's some way to check if using the properties of the sum ?   "
},
{
  "id": "session23-p4",
  "level": "1",
  "url": "session23-p4.html",
  "type": "Section",
  "number": "5.20",
  "title": "Session 23: More on universal mapping properties, Part 4",
  "body": " Session 23: More on universal mapping properties, Part 4  Let's try to wrap up this session this week so I can keep moving forward.   Exercise 2: (Part 2\/2)  Continued from Session 23 Part 2   I think I want to start here by organizing the information I have so far (or at least what I think I have).    Category  Initial Object             ?     ?    If I'm right about being the initial object in , maybe the initial object in will somehow pair each arrow with its opposite. The authors have previously discussed an object which acts like the inverse to . This would take a graph like and pair it with the graph . This second graph is important because while it can exist in , it does not exist in because an endomap can't have two arrows originating at the same point.  In the category we already saw that our definition of product means that and are two uniquely defined maps. If we think of the sum as put together with no overlap and no interaction , combining the empty set with anything doesn't change it giving us a unique map defined by . Combining something with a new object necessarily would have to change the set, so we'd need to have . This effectively establishes a bijection between and sets of the respective sizes: .  In the category our terminal objects aren't points but loops. However, there should be an isomorphism between the set of points and a cycle of that length. If we think of as a cycle of length 0 , then allows use to form an isomorphism .  While experimenting with Lean 4 the other week, I noticed that the category theory library contained separate definitions for small and large categories. The documentation suggested that the difference was that a large category could contain itself as an object. I'm starting to wonder if that property is related to role of in this bijection .  In , we observed that there were possible structure preserving maps from . Maybe we can use the notion of initial object to narrow that down to one. Given any cycle , we have a unique map that we could use to identify which element is point 0 .  Consider the cycle of two. There are precisely two -maps . If we combine the cycle with the initial object, we get a unique map and through composition with the unique map can construct a unique map . However, this operation can't preserve the structure of because there is no map in . It would follow that any composition would have to be unique.  In an attempt to put this all together, I'm thinking that an my objects in should have a general structure that looks like this:   Possible initial object    If the cycle has a length and the tail has length then there's precisely one map from tail of length to this object. This is consistent with my earlier hypothesis that our initial object in is actually just itself.    Having tried the exercise, I think it's about time to press on and hope the authors clarify things a bit more.  "
},
{
  "id": "session23-p4-3",
  "level": "2",
  "url": "session23-p4.html#session23-p4-3",
  "type": "Example",
  "number": "5.20.1",
  "title": "Exercise 2: (Part 2\/2).",
  "body": " Exercise 2: (Part 2\/2)  Continued from Session 23 Part 2   I think I want to start here by organizing the information I have so far (or at least what I think I have).    Category  Initial Object             ?     ?    If I'm right about being the initial object in , maybe the initial object in will somehow pair each arrow with its opposite. The authors have previously discussed an object which acts like the inverse to . This would take a graph like and pair it with the graph . This second graph is important because while it can exist in , it does not exist in because an endomap can't have two arrows originating at the same point.  In the category we already saw that our definition of product means that and are two uniquely defined maps. If we think of the sum as put together with no overlap and no interaction , combining the empty set with anything doesn't change it giving us a unique map defined by . Combining something with a new object necessarily would have to change the set, so we'd need to have . This effectively establishes a bijection between and sets of the respective sizes: .  In the category our terminal objects aren't points but loops. However, there should be an isomorphism between the set of points and a cycle of that length. If we think of as a cycle of length 0 , then allows use to form an isomorphism .  While experimenting with Lean 4 the other week, I noticed that the category theory library contained separate definitions for small and large categories. The documentation suggested that the difference was that a large category could contain itself as an object. I'm starting to wonder if that property is related to role of in this bijection .  In , we observed that there were possible structure preserving maps from . Maybe we can use the notion of initial object to narrow that down to one. Given any cycle , we have a unique map that we could use to identify which element is point 0 .  Consider the cycle of two. There are precisely two -maps . If we combine the cycle with the initial object, we get a unique map and through composition with the unique map can construct a unique map . However, this operation can't preserve the structure of because there is no map in . It would follow that any composition would have to be unique.  In an attempt to put this all together, I'm thinking that an my objects in should have a general structure that looks like this:   Possible initial object    If the cycle has a length and the tail has length then there's precisely one map from tail of length to this object. This is consistent with my earlier hypothesis that our initial object in is actually just itself.   "
},
{
  "id": "session24",
  "level": "1",
  "url": "session24.html",
  "type": "Section",
  "number": "5.21",
  "title": "Session 24: Uniqueness of products and definition of sum",
  "body": " Session 24: Uniqueness of products and definition of sum  I feel kind of relieved by this chapter. Some of the things I've been conjecturing have been make more explicit. There are still some loose ends for me to tie up, but I feel like I've gotten some confirmation that I'm on the right track.   Exercise 1:   Formulate and prove...    Suppose that and are both sums of in a given category.   Maps defined by the two sums    The definition of as a sum says that for any two maps and , there is exactly one map such that and . This shows that the following diagram commutes:   Commutative diagram of sum    By choosing , there must be a unique map such that and .   Commutative diagram of sum    We'd like to demonstrate that this map is an isomorphism, so we need to to find an inverse to it. Since is also a product in the category, this defines a unique map for which and .   Commutative diagram from second sum    Let's make the claim that are inverses. Namely, that and . Consider the following compositions:    The map composed with gives and composed with gives . By choosing and , the definition of sum says that there's a unique map satisfying and . Since this is uniquely satisfied by , we've can conclude that .  Likewise, we can reverse the roles of and examine the following compositions:    By the same reasoning, the unique map for which all and could only be the unique identity map . It follows that and completes the proof that is isomorphic to .  Having proved the result, I still feel like there's a weak spot in my understanding of that last step. I'm thinking it has to do with the properties of epimorphisms and monomorphisms in relation to the identity map. In the proof for the product, we rely on the fact that pre-composing by didn't change anything while in the proof for sum we rely on the fact that post-composing by didn't change anything. My hunch is that this is related to the connection between the section, retraction, and inverse. If an inverse map exists, then the section and retraction are both equal to it.     Exercise 2:   Prove the following...    Part (a):  Let's draw the left and right side separately, then compare results. Using the depiction of the sum, we can draw as the following map:   Graphical depiction of D plus D    Next, we can draw out :   Graphical depiction of 2 times D    Having these two diagrams, how do I then compare them for equality? I think the idea is to show they can be factored through the terminal object. In particular, the maps from arrows to the terminal object form a bijection between the arrows in the sum and product.   Graphical depiction of factoring through 1    The important characteristic I notice in this diagram is that that while we have 2 maps on each side, we have 4 maps and on the left and 5 maps on the right. This makes me wonder if two of the dots in the product need to collapse down to a single dot somehow. I'm wondering if I can resolve this difference by treating the terminal object as one of the elements in .  I'm also not yet accounting for the self-loops either. I'm thinking the way to resolve this is to treat the self-loops in the products as the identity maps on . I can group the two sets on the left into a the sum and form a bijection with my product .  Putting both of these changes together gives us the following diagram:   Graphical depiction of isomorphism betwen D+D and 2 times D    Now every dot maps to a self-loop . Since there's exactly one map our isomorphism above must be the only one. I say only in quotes, because the chose of assigning to is arbitrarily chosen but any choice is isomporphic to the other. There's a unique map such that and this map would have corresponding such that .  Now let's look at Part (b), which says . It seems like it should be obvious from the diagram of the graph product:   Graphical depiction of D times D    Every shape in the product is uniquely determined based on the point that the product is mapped to. Our map is fully determined by the domain and codomain.  For Part (C), we've already seen the graph of , so that just leaves which can be depicted as follows:   Graphical depiction of A times D    I think in this case we establish the bijection between and the inherent source and target maps of the arrow . However, it's not exactly clear to me how quite yet so lets try to factor through again.   Graphical depiction of A times D = D + D factored through 1    Like before, maybe the key here is to group the terminal object and dot together as a single object. This would give us the following isomorphism:   Graphical depiction of isomorphism betwen D+D and A times D    And that complete our proof! Or at least, I think it does...    This seems like a good place to stop for the week. I know if I start looking at Session 15 again it's going to get complicated.  "
},
{
  "id": "session24-3",
  "level": "2",
  "url": "session24.html#session24-3",
  "type": "Example",
  "number": "5.21.1",
  "title": "Exercise 1:.",
  "body": " Exercise 1:   Formulate and prove...    Suppose that and are both sums of in a given category.   Maps defined by the two sums    The definition of as a sum says that for any two maps and , there is exactly one map such that and . This shows that the following diagram commutes:   Commutative diagram of sum    By choosing , there must be a unique map such that and .   Commutative diagram of sum    We'd like to demonstrate that this map is an isomorphism, so we need to to find an inverse to it. Since is also a product in the category, this defines a unique map for which and .   Commutative diagram from second sum    Let's make the claim that are inverses. Namely, that and . Consider the following compositions:    The map composed with gives and composed with gives . By choosing and , the definition of sum says that there's a unique map satisfying and . Since this is uniquely satisfied by , we've can conclude that .  Likewise, we can reverse the roles of and examine the following compositions:    By the same reasoning, the unique map for which all and could only be the unique identity map . It follows that and completes the proof that is isomorphic to .  Having proved the result, I still feel like there's a weak spot in my understanding of that last step. I'm thinking it has to do with the properties of epimorphisms and monomorphisms in relation to the identity map. In the proof for the product, we rely on the fact that pre-composing by didn't change anything while in the proof for sum we rely on the fact that post-composing by didn't change anything. My hunch is that this is related to the connection between the section, retraction, and inverse. If an inverse map exists, then the section and retraction are both equal to it.   "
},
{
  "id": "session24-4",
  "level": "2",
  "url": "session24.html#session24-4",
  "type": "Example",
  "number": "5.21.2",
  "title": "Exercise 2:.",
  "body": " Exercise 2:   Prove the following...    Part (a):  Let's draw the left and right side separately, then compare results. Using the depiction of the sum, we can draw as the following map:   Graphical depiction of D plus D    Next, we can draw out :   Graphical depiction of 2 times D    Having these two diagrams, how do I then compare them for equality? I think the idea is to show they can be factored through the terminal object. In particular, the maps from arrows to the terminal object form a bijection between the arrows in the sum and product.   Graphical depiction of factoring through 1    The important characteristic I notice in this diagram is that that while we have 2 maps on each side, we have 4 maps and on the left and 5 maps on the right. This makes me wonder if two of the dots in the product need to collapse down to a single dot somehow. I'm wondering if I can resolve this difference by treating the terminal object as one of the elements in .  I'm also not yet accounting for the self-loops either. I'm thinking the way to resolve this is to treat the self-loops in the products as the identity maps on . I can group the two sets on the left into a the sum and form a bijection with my product .  Putting both of these changes together gives us the following diagram:   Graphical depiction of isomorphism betwen D+D and 2 times D    Now every dot maps to a self-loop . Since there's exactly one map our isomorphism above must be the only one. I say only in quotes, because the chose of assigning to is arbitrarily chosen but any choice is isomporphic to the other. There's a unique map such that and this map would have corresponding such that .  Now let's look at Part (b), which says . It seems like it should be obvious from the diagram of the graph product:   Graphical depiction of D times D    Every shape in the product is uniquely determined based on the point that the product is mapped to. Our map is fully determined by the domain and codomain.  For Part (C), we've already seen the graph of , so that just leaves which can be depicted as follows:   Graphical depiction of A times D    I think in this case we establish the bijection between and the inherent source and target maps of the arrow . However, it's not exactly clear to me how quite yet so lets try to factor through again.   Graphical depiction of A times D = D + D factored through 1    Like before, maybe the key here is to group the terminal object and dot together as a single object. This would give us the following isomorphism:   Graphical depiction of isomorphism betwen D+D and A times D    And that complete our proof! Or at least, I think it does...   "
},
{
  "id": "session24-p2",
  "level": "1",
  "url": "session24-p2.html",
  "type": "Section",
  "number": "5.22",
  "title": "Session 24: Uniqueness of products and definition of sum, Part 2",
  "body": " Session 24: Uniqueness of products and definition of sum, Part 2  I left of at the last exercise, which has both an easy part and a hard part . Let's see what kind of progress I can make.   Exercise 3:   Reread Section 5 of Session 15...    As a means of exploring this, I booted up my Python interpreter again. The code accompanying this week's Exercise can be found here .  For part (a), I took a naive approach to constructing by basically concatenating the lists of generators and relations. I used Python's built in hash method to construct unique names for the nodes in , then translated the original relations to use the new names.  To check that the sum was indeed this simple, I used the reconstruct_endomap method I built previously to confirm that the presentation produced a graph with the expected shape. Specifically, the following graph can be thought of as having 8 generators and 8 relations , , , , , , , and :   Sum of endomaps on X and Y    That basically concludes Part (a).  For part (b), I tried to cheat. I used the graph_product function I wrote previously, applied it to the graphs of and , then passed the output into my previously coded make_presentation method. It resulted in a crazy-looking presentation with 59 generators that made little sense at all.  Under closer scrutiny, I noticed that my graph_product wasn't behaving as expected. Specifically, it failed to preserve commutivity of and . In an effort to fix this, I ended up writing a graph_sum method using matrix operations and used that as a foundation for rewriting my graph_product . After confirming that it fixed the glitch, I tried again.  With my corrections in place, the resulting product had 9 generators and 9 relations:  {'generators': [0, 1, 12, 13, 14, 25, 26, 27, 38], 'relations': [((0, 6), (0, 2)), ((1, 1), (0, 1)), ((12, 4), (12, 1)), ((13, 1), (0, 1)), ((14, 1), (0, 1)), ((25, 1), (12, 1)), ((26, 1), (0, 1)), ((27, 1), (0, 1)), ((38, 1), (12, 1))]}  Going from 8 generators to 9 seems to make a lot more sense than having 59 generators. It also seems to support a hypothesis I had about a connection between the generators and the eigenvalues of the adjacency matrix. However, this make_presentation that I implemented earlier was designed specifically for endomaps . It's entirely plausible that there's still another error in my code to find.  In fact, I'm quite certain there's still a problem because I'm getting null presentations for 4 out of my 6 sub-products. I think it's more likely that I'm looking for a presentation with 16 generators, each one being a product between the generators of and . The reason my algorithm fails is that it can't identify a generator for shapes like is that there isn't a one-to-one correspondence between dots and arrows unless I somehow expand it to first.  Presently, my guess that the only two shapes in the product for which my make_presentation produces something are the two products where both shapes in the product have tails . Perhaps what the remaining shapes have in common is that the map from the initial object to that shape is unique.  If the generators of my product are, in fact, the products of the generators, than maybe the key to finding the relations lies in the result of Session 21 Exercise 2. If the product of two cycles with lengths is a cycle of length , maybe we can use that information to help find the corresponding relations.  In this case, it works nicely because there's a one-to-one relationship between our generators and the relations, so the product would have both 16 generators and 16 relations.  Each generator (which has a relation) could have that relation written in the the form for some such that , and would give the cycle length. In addition, this number defines the tail length associated with that shape. Based on the fact that my generators seem to disappear, I'd guess that the tail length of the product is the minimum of the two shapes being multiplied, but I'm not really sure.    I'm a little unsatisfied with that result, but I think I've explored it enough to keep moving forward.  "
},
{
  "id": "session24-p2-3",
  "level": "2",
  "url": "session24-p2.html#session24-p2-3",
  "type": "Example",
  "number": "5.22.1",
  "title": "Exercise 3:.",
  "body": " Exercise 3:   Reread Section 5 of Session 15...    As a means of exploring this, I booted up my Python interpreter again. The code accompanying this week's Exercise can be found here .  For part (a), I took a naive approach to constructing by basically concatenating the lists of generators and relations. I used Python's built in hash method to construct unique names for the nodes in , then translated the original relations to use the new names.  To check that the sum was indeed this simple, I used the reconstruct_endomap method I built previously to confirm that the presentation produced a graph with the expected shape. Specifically, the following graph can be thought of as having 8 generators and 8 relations , , , , , , , and :   Sum of endomaps on X and Y    That basically concludes Part (a).  For part (b), I tried to cheat. I used the graph_product function I wrote previously, applied it to the graphs of and , then passed the output into my previously coded make_presentation method. It resulted in a crazy-looking presentation with 59 generators that made little sense at all.  Under closer scrutiny, I noticed that my graph_product wasn't behaving as expected. Specifically, it failed to preserve commutivity of and . In an effort to fix this, I ended up writing a graph_sum method using matrix operations and used that as a foundation for rewriting my graph_product . After confirming that it fixed the glitch, I tried again.  With my corrections in place, the resulting product had 9 generators and 9 relations:  {'generators': [0, 1, 12, 13, 14, 25, 26, 27, 38], 'relations': [((0, 6), (0, 2)), ((1, 1), (0, 1)), ((12, 4), (12, 1)), ((13, 1), (0, 1)), ((14, 1), (0, 1)), ((25, 1), (12, 1)), ((26, 1), (0, 1)), ((27, 1), (0, 1)), ((38, 1), (12, 1))]}  Going from 8 generators to 9 seems to make a lot more sense than having 59 generators. It also seems to support a hypothesis I had about a connection between the generators and the eigenvalues of the adjacency matrix. However, this make_presentation that I implemented earlier was designed specifically for endomaps . It's entirely plausible that there's still another error in my code to find.  In fact, I'm quite certain there's still a problem because I'm getting null presentations for 4 out of my 6 sub-products. I think it's more likely that I'm looking for a presentation with 16 generators, each one being a product between the generators of and . The reason my algorithm fails is that it can't identify a generator for shapes like is that there isn't a one-to-one correspondence between dots and arrows unless I somehow expand it to first.  Presently, my guess that the only two shapes in the product for which my make_presentation produces something are the two products where both shapes in the product have tails . Perhaps what the remaining shapes have in common is that the map from the initial object to that shape is unique.  If the generators of my product are, in fact, the products of the generators, than maybe the key to finding the relations lies in the result of Session 21 Exercise 2. If the product of two cycles with lengths is a cycle of length , maybe we can use that information to help find the corresponding relations.  In this case, it works nicely because there's a one-to-one relationship between our generators and the relations, so the product would have both 16 generators and 16 relations.  Each generator (which has a relation) could have that relation written in the the form for some such that , and would give the cycle length. In addition, this number defines the tail length associated with that shape. Based on the fact that my generators seem to disappear, I'd guess that the tail length of the product is the minimum of the two shapes being multiplied, but I'm not really sure.   "
},
{
  "id": "session25",
  "level": "1",
  "url": "session25.html",
  "type": "Section",
  "number": "5.23",
  "title": "Session 25: Labelings and products of graphs",
  "body": " Session 25: Labelings and products of graphs  I started moving forward this week, but found myself doubling back to debug my code from the last Exercise in Session 24. I think these things are connected, so I'm kind of just using this week to flesh out some ideas.   Exercise 1:   Find a graph ...    I've already been thinking of a shape with two arrows in a path as per the following diagram:   I think the sort this imposes on has something to do with those tails on my presentations. Specifically, if I'm thinking of this graph as an endomap, it forms a sequence:     What makes this graph interesting is the possible ways the dots in the graph could potentially collapse through incidence. We could have the last two points combine to produce the idempotent , the first and last collapse to form a 2-cycle . the first two collapse to form a non-endomap , or all three dots collapse to form the terminal object . If the cycle was described as separating into dots mapped to and dots mapped to , this graph would seem to divide into arrows mapped from and arrows mapped from .  That non-map seems particularly interesting. If I have some arbitrary endomap , I can think of this map as mapping each dot to the product of maps .  This reminds me of the peg game from Session 17. Perhaps the solution to that problem lies in finding a map from the arrows mapped from to dots mapped to for the specific starting state and ending state . The title of this session seems to imply that I might have been on track by how I approached Session 11 Exercise 8. The general idea would be to color all the points\/arrows accessible from the start red, color all the points\/arrows accessible from the end blue, and those two points are connected if and only if there exists some kind of purple object .  I'm not really sure how to articulate how this sorting works at the moment, but it seems like this graph is certainly full of interesting properties.     Session 24 Debugging   Continued from last time...    Looking over my code from last week, I noticed another problem with my Python code. While I fixed the commutation problem, I broke my graph product. Instead of giving me 2 cycles of two as expected, I was getting the graph described in this session as . Upon fixing my graph product, it took me back up to 59 generators again. I'm starting to believe that my original result might have actually been right. The new graph_product function I came up with was defined as follows:  def graph_product(A,B): # for our product, the nodes are pairs of nodes a_size,b_size = len(A.nodes),len(B.nodes) new_size = a_size*b_size print(f\"Nodes = {a_size} x {b_size} -> {new_size}\") p_nodes = [str([a,b]) for a in A.nodes for b in B.nodes] print(p_nodes,len(p_nodes)) p_edges = [(str([a[0],b[0]]),str([a[1],b[1]])) for a in A.edges for b in B.edges] print(p_edges,len(p_edges)) output = nx.DiGraph() output.add_nodes_from(p_nodes) output.add_edges_from(p_edges) return output  I still think there's a better way of doing this using matrix operations and I think it might be connected to that shape that I was looking at. Instead of padding my matrices with zeros like I did with graph_sum , I'm thinking I can stack an identity matrix and adjacency matrix together to separate the dots and arrows of a given endomap.  Using the endomaps from Session 15, separated into a sum of two objects and into a sum of three objects. Notably one object, , falls into both sets. What's interesting is that has only one generator, but requires two. Using my graph_product between pairs of these subgraphs showed that the relationship between the number of generators wasn't as straight forward as I thought.  If my hypothesis about the generators being non-zero eigenvalues is correct, then those 59 generators do in fact come from the products of the disjoint shapes of and .    Subgraph Presentations   ,           Expect 16 generators  Expect 2 generators       Expect 29 generators  Expect 4 generators      Expect 6 generators  Expect 2 generators    These generators of the subproducts sum up to 59 total! The fact that is probably not a conincidence. Back when I was working in game development, we used to use homogenized vectors based around defining a equivalence class from to by the relation By adding a dimension, we can turn a translation into a matrix product. I'm wondering if something like that is going on here.  I also thought that unraveling my matrices might tell me something about the products. Since each arrow is a non-zero element in the adjacency matrix, I can take the outer product of flattened matrices to find where my arrows might be in the product. Since the matrix has 81 elements with exactly 9 non-zero and the has 169 elements with exactly 13 non-zero, I can take the outer product to form a matrix with exactly 117 non-zero elements. I think with some clever linear algebra it might be possible to reshape this matrix into a matrix representing the product with a pair of projection matrices of shape and respectively.  In the same way that I thought might be like stacking an identity and adjacency matrix together, I think I could extend this idea to an arbitrary using powers of the adjacency matrix. By using 13 powers of the matrix and 9 powers of the matrix I can produce matrices of the shapes I'm looking for: and . However, I haven't figured out what to do with those matrices to produce the product quite yet.    "
},
{
  "id": "session25-3",
  "level": "2",
  "url": "session25.html#session25-3",
  "type": "Example",
  "number": "5.23.1",
  "title": "Exercise 1:.",
  "body": " Exercise 1:   Find a graph ...    I've already been thinking of a shape with two arrows in a path as per the following diagram:   I think the sort this imposes on has something to do with those tails on my presentations. Specifically, if I'm thinking of this graph as an endomap, it forms a sequence:     What makes this graph interesting is the possible ways the dots in the graph could potentially collapse through incidence. We could have the last two points combine to produce the idempotent , the first and last collapse to form a 2-cycle . the first two collapse to form a non-endomap , or all three dots collapse to form the terminal object . If the cycle was described as separating into dots mapped to and dots mapped to , this graph would seem to divide into arrows mapped from and arrows mapped from .  That non-map seems particularly interesting. If I have some arbitrary endomap , I can think of this map as mapping each dot to the product of maps .  This reminds me of the peg game from Session 17. Perhaps the solution to that problem lies in finding a map from the arrows mapped from to dots mapped to for the specific starting state and ending state . The title of this session seems to imply that I might have been on track by how I approached Session 11 Exercise 8. The general idea would be to color all the points\/arrows accessible from the start red, color all the points\/arrows accessible from the end blue, and those two points are connected if and only if there exists some kind of purple object .  I'm not really sure how to articulate how this sorting works at the moment, but it seems like this graph is certainly full of interesting properties.   "
},
{
  "id": "session25-4",
  "level": "2",
  "url": "session25.html#session25-4",
  "type": "Example",
  "number": "5.23.2",
  "title": "Session 24 Debugging.",
  "body": " Session 24 Debugging   Continued from last time...    Looking over my code from last week, I noticed another problem with my Python code. While I fixed the commutation problem, I broke my graph product. Instead of giving me 2 cycles of two as expected, I was getting the graph described in this session as . Upon fixing my graph product, it took me back up to 59 generators again. I'm starting to believe that my original result might have actually been right. The new graph_product function I came up with was defined as follows:  def graph_product(A,B): # for our product, the nodes are pairs of nodes a_size,b_size = len(A.nodes),len(B.nodes) new_size = a_size*b_size print(f\"Nodes = {a_size} x {b_size} -> {new_size}\") p_nodes = [str([a,b]) for a in A.nodes for b in B.nodes] print(p_nodes,len(p_nodes)) p_edges = [(str([a[0],b[0]]),str([a[1],b[1]])) for a in A.edges for b in B.edges] print(p_edges,len(p_edges)) output = nx.DiGraph() output.add_nodes_from(p_nodes) output.add_edges_from(p_edges) return output  I still think there's a better way of doing this using matrix operations and I think it might be connected to that shape that I was looking at. Instead of padding my matrices with zeros like I did with graph_sum , I'm thinking I can stack an identity matrix and adjacency matrix together to separate the dots and arrows of a given endomap.  Using the endomaps from Session 15, separated into a sum of two objects and into a sum of three objects. Notably one object, , falls into both sets. What's interesting is that has only one generator, but requires two. Using my graph_product between pairs of these subgraphs showed that the relationship between the number of generators wasn't as straight forward as I thought.  If my hypothesis about the generators being non-zero eigenvalues is correct, then those 59 generators do in fact come from the products of the disjoint shapes of and .    Subgraph Presentations   ,           Expect 16 generators  Expect 2 generators       Expect 29 generators  Expect 4 generators      Expect 6 generators  Expect 2 generators    These generators of the subproducts sum up to 59 total! The fact that is probably not a conincidence. Back when I was working in game development, we used to use homogenized vectors based around defining a equivalence class from to by the relation By adding a dimension, we can turn a translation into a matrix product. I'm wondering if something like that is going on here.  I also thought that unraveling my matrices might tell me something about the products. Since each arrow is a non-zero element in the adjacency matrix, I can take the outer product of flattened matrices to find where my arrows might be in the product. Since the matrix has 81 elements with exactly 9 non-zero and the has 169 elements with exactly 13 non-zero, I can take the outer product to form a matrix with exactly 117 non-zero elements. I think with some clever linear algebra it might be possible to reshape this matrix into a matrix representing the product with a pair of projection matrices of shape and respectively.  In the same way that I thought might be like stacking an identity and adjacency matrix together, I think I could extend this idea to an arbitrary using powers of the adjacency matrix. By using 13 powers of the matrix and 9 powers of the matrix I can produce matrices of the shapes I'm looking for: and . However, I haven't figured out what to do with those matrices to produce the product quite yet.   "
},
{
  "id": "session25-p2",
  "level": "1",
  "url": "session25-p2.html",
  "type": "Section",
  "number": "5.24",
  "title": "Session 25: Labelings and products of graphs, Part 2",
  "body": " Session 25: Labelings and products of graphs, Part 2  As I continued to read further, I realized my solution to last week's Exercise is probably not correct. I'm also beginning to think that I need to finish my solution to certain outstanding problems (i.e. Session 15) before I can proceed any further. It's possible I might be stuck here a while...   Exercise 1: (Part 2\/?)   Proofreading last week's work...    Immediately after this Exercise, the author's define a graph with the exact graph I thought was going to be . It seems incredibly unlikely that would be the same graph, so my answer is almost certainly wrong. I decided to take a closer look at the examples leading up to his.  I've been starting to form a tighter connection between the graphs and the adjacency matrices. The object defined as the naked dot is essentially a matrix given by . Likewise, the naked arrow  can be thought of a matrix given by . By concatenating matrices along the diagonal and filling in zeroes, we can produce a graph sum such that and . I also get a nice representation of the naked loop as the matrix .  However, it's important to note that this method of a graph sum doesn't commute. The matrix is distinct from if we're using an element-wise comparison. Even though they're not the same, they're isomorphic in that they both have exactly 3 dots and one arrow connecting two of them so every thing has a pair.  Speaking of pairs, I think that's why our maps to are important. Using the matrix notation, can be thought of as which happens to be the unique antipodal matrix satisfying . Multiplying this matrix with the arrow matrix gives me the sum of a naked dot and a loop, as represented by the matrix form .  What strikes me as interesting about this matrix representation is the way the graph decribed in the text as corresponds with the matrix . This is the unique matrix that takes every element in the matrix of and swaps zeroes to ones. It got me wondering what would happen if I applied the same operation to . This matrix, given by , produces the following graph:   Graph that is two arrows short of completion    I'm starting to think that this might be the graph that I was looking for. The reason I'm so convinced of this is the way om which it resembles a particular shape on the cover of the book:   Graph depicted on cover of book    Using the notation I have been, this graph corresponds with the matrix given by (with the 2 repesenting my second self-loop). This seems relevant because taking these elements modulo 2 and multiplying by my antipodal matrix gives me back the original arrow .  I think I want to spend a little more time playing with this. I think this notion of a graph negation operation could have some useful properties with respect to my sum and product.    "
},
{
  "id": "session25-p2-3",
  "level": "2",
  "url": "session25-p2.html#session25-p2-3",
  "type": "Example",
  "number": "5.24.1",
  "title": "Exercise 1: (Part 2\/?).",
  "body": " Exercise 1: (Part 2\/?)   Proofreading last week's work...    Immediately after this Exercise, the author's define a graph with the exact graph I thought was going to be . It seems incredibly unlikely that would be the same graph, so my answer is almost certainly wrong. I decided to take a closer look at the examples leading up to his.  I've been starting to form a tighter connection between the graphs and the adjacency matrices. The object defined as the naked dot is essentially a matrix given by . Likewise, the naked arrow  can be thought of a matrix given by . By concatenating matrices along the diagonal and filling in zeroes, we can produce a graph sum such that and . I also get a nice representation of the naked loop as the matrix .  However, it's important to note that this method of a graph sum doesn't commute. The matrix is distinct from if we're using an element-wise comparison. Even though they're not the same, they're isomorphic in that they both have exactly 3 dots and one arrow connecting two of them so every thing has a pair.  Speaking of pairs, I think that's why our maps to are important. Using the matrix notation, can be thought of as which happens to be the unique antipodal matrix satisfying . Multiplying this matrix with the arrow matrix gives me the sum of a naked dot and a loop, as represented by the matrix form .  What strikes me as interesting about this matrix representation is the way the graph decribed in the text as corresponds with the matrix . This is the unique matrix that takes every element in the matrix of and swaps zeroes to ones. It got me wondering what would happen if I applied the same operation to . This matrix, given by , produces the following graph:   Graph that is two arrows short of completion    I'm starting to think that this might be the graph that I was looking for. The reason I'm so convinced of this is the way om which it resembles a particular shape on the cover of the book:   Graph depicted on cover of book    Using the notation I have been, this graph corresponds with the matrix given by (with the 2 repesenting my second self-loop). This seems relevant because taking these elements modulo 2 and multiplying by my antipodal matrix gives me back the original arrow .  I think I want to spend a little more time playing with this. I think this notion of a graph negation operation could have some useful properties with respect to my sum and product.   "
},
{
  "id": "session17-r1",
  "level": "1",
  "url": "session17-r1.html",
  "type": "Section",
  "number": "5.25",
  "title": "Revisiting Session 17,  Part 1",
  "body": " Revisiting Session 17, Part 1  Rather than trying to push further in Session 25, I decided to take some time to revisit my work on Session 17. I thought that it would be a nice change of pace to work on a problem where the solution would be self-evident and I already implemented the peg game in React . My logic was that if I could enumerate the peg game solutions programmatically, I might be able to apply the same principles to count structure preserving maps.   Revisiting Session 17's Peg Game, Part 1\/?   Attempting to solve the peg game...    I started by taking my existing JavaScript code and translating into Python. Once I had the implementation ported over, I started trying to enumerate the possible game states. Given that my original game state in JavaScript is essentially an array of boolean values, I used a binary representation of the game board to turn my state into a single integer in the range from to . Under this representation, my intitial state corresponded with and terminal state corresponded with . A hypothetical solution would correspond to a sequence of 32 game states beginning and ending with the specified values, such that each step is a valid move.  There's a slight problem with this approach, namely that it would would essentially require me to work with a adjacency matrix in order to model how these states are connected with each other. While I could step through and evalauate which states are accessible from every other state, it would take an extraordinary amount of time to do so.  This, in turn, got me thinking about the adjacency matrices of graphs that I was looking at last week. Like my game states, these too could be turned into integers by thinking of the matrix elements as the bits of a single number . If you could also encode the size of the matrix into an ordered pair , that would give you all the information you need to reconstruct the adjacency matrix. If you knew the graph is an endomap , the size wouldn't even be necessary because the size of matrix would be uniquely determined by the number of bits in the on state because this graph would necessarily have a one-to-one relation between dots and arrows .  That's where I had an epiphany. My terminal state for the peg game isn't just a board with one filled slot in the center, as my bitfield representation depicted, but rather that peg in the center needs to correspond with exactly one of the initial 32 pegs placed on the board. Since each peg can only move up 2, down 2, left 2, or right 2, they essentially forced into four distinct groups based on whether they are in odd or even  rows and columns . I numbered these slot groups 0 through 3 as per the following arrangement:  020 131 0202020 1313131 0202020 131 020  This labeling makes it clear that only four of the original 32 pegs can ever end up the center slot. Furthermore, these same four pegs have a one-to-one correspondence with the four possible peices which are removed first because the opening move must move one of those same four to the center also. Pairing an opening move with a closing move would define a class of 4 possible solutions up to rotation and reflection.  Without loss of generality, we can assume the first move to put the board into the following state:  XXX XOX XXXOXXX XXXXXXX XXXXXXX XXX XXX  We also know that the peg that ends up in the center must be one of the original set of four first moves. If this last peg is one other than the first moved, that first peg will need to move out of the center slot at some point before a new peg can move in. That final peg can also not be removed by any move, but every other peg is removed by exactly one peg. The relationship between the pegs removed and the pegs moved is onto but not necessary one-to-one . Similarly, the slots in the corners of the game board have a special property: each of these corner pegs can't be removed until after it's moved.  All of these conditions could be used together to help narrow down the possible solution space. Each solution must correspond to a sequence of 31 removals , with every one of the 32 pegs except the terminal one having exactly one turn in which it is removed. If I think of the first move and the last move as being paired together, this essentially would give me a retraction. Similarly, there should be some kind of section on this map which identifies which peg moves in a given turn. We can sort the pegs based on ones which may move more than once, move at least once, or get removed without ever moving at all.  By looking at these points as a sequence of removals , I can effectively narrow down my search space to possible permutations. This is far less than the sequences of game states I was originally looking at, but still too many for practical purposes.  In an effort to explore this, I tried to see how well I could recreate the game state from a given sequence of removals. This turned out to be a little more difficult than I anticipated. There are various different board states which knowing which peice is removed in a given turn is not sufficient identify a unique move. It's entirely possible that turns could arise in which a given peg could be jumped by two different pegs. You wouldn't know which peg does the jumping by looking at the sequence leading up to that point, so this information would need to be encoded somehow by the removals after that turn.  I'm starting to think that the key to this lies in keeping track of the domains and codomains of each these maps . In the same way that thinking of a difference between slot space and peg space helped reduce my number of options, maybe I can somehow use a product of the peg moved and peg removed to help narrow my solutions further.  Before I wrap up for the week, I think I want to document some of the maps I've encountered with this problem so far. I'm thinking this will be useful reference to have as I start organizing a sequece of compositions that results in a solution . I put solution in quotes, because identifying the exact structure of that object seems to be a large part of the problem to begin with. So far, I've had to identify the following maps:    A map from identifying the 33 slots on the 7 by 7 board.    A map from assigning each of the 33 slots with its respective row and column pair.    A map from assigning each of the 32 pegs with its initial slot.    A map from that identifies which pegs are eventually removed in a given solution.    A map from that identifies the last peg remaining on the board.    A map from that identifies the first peg removed from the board.    A map from that pairs each point with the peg that removes it or itself if it's the last peg.    An isomorphism from that pairs each point with the number of the turn in which is removed from the board, with the last peg being being thought of as removed in the last turn.    An map from that maps each turn to the peg that moves in that turn.    A map from that sorts pegs into ones that move and ones that never move.    A map from that sorts pegs based on whether they can be removed before they are moved or not.    A sequence of maps from representing the coimages of the pegs left on the board after each turn.    A set of maps from representing the state of the board with pegs left.    Several isomorphisms corresponding to rotations and reflections of the game board.    Some map describing the number of potential solutions up to rigid transformation.    A map that maps each of the turns to a pair.   While exploring, it seemed like one possible strategy might to work forward and backwards simultaneously by pairing up the turns from the beginning with turns from the end. I wonder if this might have some relation to the graph negation operation that I was looking at last week. I think if I can somehow combine this idea with the approach to Session 10 Exercise 4, I might be able to find a point where the forward and backward paths intersect.    My code from this week can be found here , but I also checked in some additional Python stuff I've been working on over the past couple weeks. The goal of this is to use the known solutions of exercises to write unit tests that help verify the integrity of my proofs. I'm hoping that structuring my code this way will make it easier to ensure that I don't break anything when I try to do things like reimplementing my graph product using matrix operations.  "
},
{
  "id": "session17-r1-3",
  "level": "2",
  "url": "session17-r1.html#session17-r1-3",
  "type": "Example",
  "number": "5.25.1",
  "title": "Revisiting Session 17s Peg Game, Part 1\/?",
  "body": " Revisiting Session 17's Peg Game, Part 1\/?   Attempting to solve the peg game...    I started by taking my existing JavaScript code and translating into Python. Once I had the implementation ported over, I started trying to enumerate the possible game states. Given that my original game state in JavaScript is essentially an array of boolean values, I used a binary representation of the game board to turn my state into a single integer in the range from to . Under this representation, my intitial state corresponded with and terminal state corresponded with . A hypothetical solution would correspond to a sequence of 32 game states beginning and ending with the specified values, such that each step is a valid move.  There's a slight problem with this approach, namely that it would would essentially require me to work with a adjacency matrix in order to model how these states are connected with each other. While I could step through and evalauate which states are accessible from every other state, it would take an extraordinary amount of time to do so.  This, in turn, got me thinking about the adjacency matrices of graphs that I was looking at last week. Like my game states, these too could be turned into integers by thinking of the matrix elements as the bits of a single number . If you could also encode the size of the matrix into an ordered pair , that would give you all the information you need to reconstruct the adjacency matrix. If you knew the graph is an endomap , the size wouldn't even be necessary because the size of matrix would be uniquely determined by the number of bits in the on state because this graph would necessarily have a one-to-one relation between dots and arrows .  That's where I had an epiphany. My terminal state for the peg game isn't just a board with one filled slot in the center, as my bitfield representation depicted, but rather that peg in the center needs to correspond with exactly one of the initial 32 pegs placed on the board. Since each peg can only move up 2, down 2, left 2, or right 2, they essentially forced into four distinct groups based on whether they are in odd or even  rows and columns . I numbered these slot groups 0 through 3 as per the following arrangement:  020 131 0202020 1313131 0202020 131 020  This labeling makes it clear that only four of the original 32 pegs can ever end up the center slot. Furthermore, these same four pegs have a one-to-one correspondence with the four possible peices which are removed first because the opening move must move one of those same four to the center also. Pairing an opening move with a closing move would define a class of 4 possible solutions up to rotation and reflection.  Without loss of generality, we can assume the first move to put the board into the following state:  XXX XOX XXXOXXX XXXXXXX XXXXXXX XXX XXX  We also know that the peg that ends up in the center must be one of the original set of four first moves. If this last peg is one other than the first moved, that first peg will need to move out of the center slot at some point before a new peg can move in. That final peg can also not be removed by any move, but every other peg is removed by exactly one peg. The relationship between the pegs removed and the pegs moved is onto but not necessary one-to-one . Similarly, the slots in the corners of the game board have a special property: each of these corner pegs can't be removed until after it's moved.  All of these conditions could be used together to help narrow down the possible solution space. Each solution must correspond to a sequence of 31 removals , with every one of the 32 pegs except the terminal one having exactly one turn in which it is removed. If I think of the first move and the last move as being paired together, this essentially would give me a retraction. Similarly, there should be some kind of section on this map which identifies which peg moves in a given turn. We can sort the pegs based on ones which may move more than once, move at least once, or get removed without ever moving at all.  By looking at these points as a sequence of removals , I can effectively narrow down my search space to possible permutations. This is far less than the sequences of game states I was originally looking at, but still too many for practical purposes.  In an effort to explore this, I tried to see how well I could recreate the game state from a given sequence of removals. This turned out to be a little more difficult than I anticipated. There are various different board states which knowing which peice is removed in a given turn is not sufficient identify a unique move. It's entirely possible that turns could arise in which a given peg could be jumped by two different pegs. You wouldn't know which peg does the jumping by looking at the sequence leading up to that point, so this information would need to be encoded somehow by the removals after that turn.  I'm starting to think that the key to this lies in keeping track of the domains and codomains of each these maps . In the same way that thinking of a difference between slot space and peg space helped reduce my number of options, maybe I can somehow use a product of the peg moved and peg removed to help narrow my solutions further.  Before I wrap up for the week, I think I want to document some of the maps I've encountered with this problem so far. I'm thinking this will be useful reference to have as I start organizing a sequece of compositions that results in a solution . I put solution in quotes, because identifying the exact structure of that object seems to be a large part of the problem to begin with. So far, I've had to identify the following maps:    A map from identifying the 33 slots on the 7 by 7 board.    A map from assigning each of the 33 slots with its respective row and column pair.    A map from assigning each of the 32 pegs with its initial slot.    A map from that identifies which pegs are eventually removed in a given solution.    A map from that identifies the last peg remaining on the board.    A map from that identifies the first peg removed from the board.    A map from that pairs each point with the peg that removes it or itself if it's the last peg.    An isomorphism from that pairs each point with the number of the turn in which is removed from the board, with the last peg being being thought of as removed in the last turn.    An map from that maps each turn to the peg that moves in that turn.    A map from that sorts pegs into ones that move and ones that never move.    A map from that sorts pegs based on whether they can be removed before they are moved or not.    A sequence of maps from representing the coimages of the pegs left on the board after each turn.    A set of maps from representing the state of the board with pegs left.    Several isomorphisms corresponding to rotations and reflections of the game board.    Some map describing the number of potential solutions up to rigid transformation.    A map that maps each of the turns to a pair.   While exploring, it seemed like one possible strategy might to work forward and backwards simultaneously by pairing up the turns from the beginning with turns from the end. I wonder if this might have some relation to the graph negation operation that I was looking at last week. I think if I can somehow combine this idea with the approach to Session 10 Exercise 4, I might be able to find a point where the forward and backward paths intersect.   "
},
{
  "id": "session25-p3",
  "level": "1",
  "url": "session25-p3.html",
  "type": "Section",
  "number": "5.26",
  "title": "Session 25: Labelings and products of graphs, Part 3",
  "body": " Session 25: Labelings and products of graphs, Part 3  I came back to Session 25 again this week to see if I could make any progress. I found it hard to focus on a single problem though. It feels like I'm still missing something important.   Exercise 1: (Part 3\/?)   Continued proofreading...    While messing around in Python this week , I decided to take a brute force to this problem. I used a brute-force method to search for structure preserving maps to see if the shape I hypothesized earlier did anything interesting.  I used couple of examples from the textbook to see if my search algorithm worked as expected. Specifically, the problems from the start of Session 11, Session 15, along with Test 2 Question 2 all gave me some simple cases to verify. I notice that my original solution to Session 11 Exercise 1 was off by 1! My new algorithm gave me a fourth map: the one where the loop maps to a fixed point.  With that in place, I testing out the sample graph I came up with in Session 25 Part 2 . I discovered a slight problem, and that's that it divide my graphs into four parts instead of just two.  After experimenting with several simple graphs, I'm starting to think that the best candidate for this map is the standard idempotent map: . By identifying a map of graphs to this object, it seems to sort out the generators of tails . More specifically, it identifies the points of which are not in the image  points which are lost through the first application of .  I think it remains to be seen whether this is actually , but at least it seems like it could be an useful property anyway.     Exercise 2: (Part 1\/?)   (a) Show that if a diagram of sets ...    We're given a generic sum diagram:   Generic sum    We're told this has the property of a coproduct but restricted to testing against the one cofigure type . Our goal is to use this to prove it's actually a coproduct.  The property in question is that for any two maps and , there is exactly one map such that and .  We're only testing against the object , so our assumption is that for any maps and , there is exactly one map such that and .  Let's assume the opposite. Suppose is not a sum. There would need to be either no maps  such that and , or more than one such map.  At least one such map should exist as long as the category contains an initial object. The unique maps from the initial object, and , can be composed with to produce a unique pair of compositions and . Since there are exactly two maps here, the set of these maps is isomorphic to the set .  Suppose that another triple of maps has the same property as . If , there exists some such that . Applying to this gives us . Applying to this gives us . However, there are only two objects in and we already know by virtue of the domains being different. The contradiction implies and are the same map.  For part (b), I think I'd like to look at the these through the lens of an adjacency matrix. The generic sum corresponds with a set of objects: three dots and two arrows . The three dots can be detemine as the dimension of the matrix to be matrix with non-zero elements corresponding to the arrows. Specifically, the matrix would be given by .  There's a unique map which maps each of the three dots to itself, corresponding to the identity matrix:   We can think of our sum as producing a pair of matrices given by and that inject a single dot into the set of three dots, into the positions that will be mapped to the third dot by our adjacency matrix. We know there's an isomorphism here because multiplying by swaps the roles of the two points and is invertable by iterating a second time.  If my hypothesis about Exercise 1 is correct, the figure corresponds with the matrix and corresponds with . Each of these has a complement formed by subtracting every element from . In this case, the complement of is and the complement of is . The reason this strikes me as curious is that we can go from back to by muliplying with but no matrix multiplication will take us from back to .  I think the idea here is that while there's isomorphisms from and , there's a retraction but it's not structure preserving. Two disjoint arrows corresponds to the matrix , there's only one matrix that will send those two arrows to the ones in our sum.  I'm not really sure where I'm going with this anymore, so maybe I'll come back later.     Exercise 3: (Part 1\/?)    Tricoloring a graph...    You'll find me exploring this a little in Python if you look at the code I checked in, so I may as well document what I observed.  I thought I could get away with NetworkX's greedy_color at first, but it didn't quite behave as described. After manually verifying a coloring first, I came up with an algorithm that produces a tricoloring from the presentation of the graph. It seemed to work for both of the endomaps from Session 15.  Implementing doesn't address either of the two parts to this question though. I found the use of parity in this implementation kind of interesting. It reminds me of an old programming problem where you have a linked list and want to determine if it contains a cycle. One of the ways you can approach it is to iterate through the list with pointers that skip elements at two relatively prime rates, i.e. by 2s and 3s. If you reach the end of the list, great, there's no loops. If the list loops, at somepoint your pointers will overlap and you can terminate the program.  I'm going to have to comeback to see how this induced coloring works, but I think there's an important connection to be made here.     Exercise 4: (Part 1\/?)   In this exercise, ...    Again, I didn't make too much progress here but did check in some Python code that seemed relevant. Considering my hypotheses about the role of adjacency matrices in representating graphs, there seems to be a corresponding map that encodes the values of an adjacency matrix into the bits of an integer. While this method doesn't work for all graphs, the fact that it could work for endomaps seems very releavant to this question.    Not as much progress as I'd hoped, but any progress is progress...  "
},
{
  "id": "session25-p3-3",
  "level": "2",
  "url": "session25-p3.html#session25-p3-3",
  "type": "Example",
  "number": "5.26.1",
  "title": "Exercise 1: (Part 3\/?).",
  "body": " Exercise 1: (Part 3\/?)   Continued proofreading...    While messing around in Python this week , I decided to take a brute force to this problem. I used a brute-force method to search for structure preserving maps to see if the shape I hypothesized earlier did anything interesting.  I used couple of examples from the textbook to see if my search algorithm worked as expected. Specifically, the problems from the start of Session 11, Session 15, along with Test 2 Question 2 all gave me some simple cases to verify. I notice that my original solution to Session 11 Exercise 1 was off by 1! My new algorithm gave me a fourth map: the one where the loop maps to a fixed point.  With that in place, I testing out the sample graph I came up with in Session 25 Part 2 . I discovered a slight problem, and that's that it divide my graphs into four parts instead of just two.  After experimenting with several simple graphs, I'm starting to think that the best candidate for this map is the standard idempotent map: . By identifying a map of graphs to this object, it seems to sort out the generators of tails . More specifically, it identifies the points of which are not in the image  points which are lost through the first application of .  I think it remains to be seen whether this is actually , but at least it seems like it could be an useful property anyway.   "
},
{
  "id": "session25-p3-4",
  "level": "2",
  "url": "session25-p3.html#session25-p3-4",
  "type": "Example",
  "number": "5.26.2",
  "title": "Exercise 2: (Part 1\/?).",
  "body": " Exercise 2: (Part 1\/?)   (a) Show that if a diagram of sets ...    We're given a generic sum diagram:   Generic sum    We're told this has the property of a coproduct but restricted to testing against the one cofigure type . Our goal is to use this to prove it's actually a coproduct.  The property in question is that for any two maps and , there is exactly one map such that and .  We're only testing against the object , so our assumption is that for any maps and , there is exactly one map such that and .  Let's assume the opposite. Suppose is not a sum. There would need to be either no maps  such that and , or more than one such map.  At least one such map should exist as long as the category contains an initial object. The unique maps from the initial object, and , can be composed with to produce a unique pair of compositions and . Since there are exactly two maps here, the set of these maps is isomorphic to the set .  Suppose that another triple of maps has the same property as . If , there exists some such that . Applying to this gives us . Applying to this gives us . However, there are only two objects in and we already know by virtue of the domains being different. The contradiction implies and are the same map.  For part (b), I think I'd like to look at the these through the lens of an adjacency matrix. The generic sum corresponds with a set of objects: three dots and two arrows . The three dots can be detemine as the dimension of the matrix to be matrix with non-zero elements corresponding to the arrows. Specifically, the matrix would be given by .  There's a unique map which maps each of the three dots to itself, corresponding to the identity matrix:   We can think of our sum as producing a pair of matrices given by and that inject a single dot into the set of three dots, into the positions that will be mapped to the third dot by our adjacency matrix. We know there's an isomorphism here because multiplying by swaps the roles of the two points and is invertable by iterating a second time.  If my hypothesis about Exercise 1 is correct, the figure corresponds with the matrix and corresponds with . Each of these has a complement formed by subtracting every element from . In this case, the complement of is and the complement of is . The reason this strikes me as curious is that we can go from back to by muliplying with but no matrix multiplication will take us from back to .  I think the idea here is that while there's isomorphisms from and , there's a retraction but it's not structure preserving. Two disjoint arrows corresponds to the matrix , there's only one matrix that will send those two arrows to the ones in our sum.  I'm not really sure where I'm going with this anymore, so maybe I'll come back later.   "
},
{
  "id": "session25-p3-5",
  "level": "2",
  "url": "session25-p3.html#session25-p3-5",
  "type": "Example",
  "number": "5.26.3",
  "title": "Exercise 3: (Part 1\/?).",
  "body": " Exercise 3: (Part 1\/?)    Tricoloring a graph...    You'll find me exploring this a little in Python if you look at the code I checked in, so I may as well document what I observed.  I thought I could get away with NetworkX's greedy_color at first, but it didn't quite behave as described. After manually verifying a coloring first, I came up with an algorithm that produces a tricoloring from the presentation of the graph. It seemed to work for both of the endomaps from Session 15.  Implementing doesn't address either of the two parts to this question though. I found the use of parity in this implementation kind of interesting. It reminds me of an old programming problem where you have a linked list and want to determine if it contains a cycle. One of the ways you can approach it is to iterate through the list with pointers that skip elements at two relatively prime rates, i.e. by 2s and 3s. If you reach the end of the list, great, there's no loops. If the list loops, at somepoint your pointers will overlap and you can terminate the program.  I'm going to have to comeback to see how this induced coloring works, but I think there's an important connection to be made here.   "
},
{
  "id": "session25-p3-6",
  "level": "2",
  "url": "session25-p3.html#session25-p3-6",
  "type": "Example",
  "number": "5.26.4",
  "title": "Exercise 4: (Part 1\/?).",
  "body": " Exercise 4: (Part 1\/?)   In this exercise, ...    Again, I didn't make too much progress here but did check in some Python code that seemed relevant. Considering my hypotheses about the role of adjacency matrices in representating graphs, there seems to be a corresponding map that encodes the values of an adjacency matrix into the bits of an integer. While this method doesn't work for all graphs, the fact that it could work for endomaps seems very releavant to this question.   "
},
{
  "id": "session25-p4",
  "level": "1",
  "url": "session25-p4.html",
  "type": "Section",
  "number": "5.27",
  "title": "Session 25: Labelings and products of graphs, Part 4",
  "body": " Session 25: Labelings and products of graphs, Part 4  I think I'd like start this week by taking a closer look at Exercise 3.   Exercise 3: (Part 2\/2?)    Tricoloring continued...    Part (a) asks us to show that an induced tricoloring is a tricoloring . Suppose there's a map that tricolors the dots of graph . By definition of tricoloring, for any arrow in we must have .  Given that our map is a -map, it must preserve structure . Namely, if and then and for every .  It should follow from these that is a tricoloring on .  Suppose is NOT a tricoloring . There must exist some arrow with such that the source and target have the same color. Expand using our definition of to get . By our structure preservation property, this is equivalent to . However, is an arrow in . The definition of tricoloring states that every so the statement generates a contradiction. Our assumption must be false, establishing that the tricoloring induced by composition is in fact a tricoloring.  I kind of wish my Python work was reliable enough to answer part (b), but for now I think I'd like to do some research on references to Fatima that might yield clues.   The book is literally dedicated to Fatima.  The name shows up in Session 1, but as a member of a set.  In Session 8, Fatima comments that maps having the same domain and codomain is a prerequisite condition for being the same map.  In Session 9, Fatima is used as an example for someone's congressional representative. The idea being that the representative is a fixed point of the endomap.  In Session 11, Fatima suggests using the associative property with the structure preservation properties. This is in the context of a map from a 3-cycle to a given graph.  In Session 20, Fatima suggests that the terminal object translates into in arithmetic. Fatimia also points out that this element corresponds with map to a loop .   In Session 22, Fatima asks about the heavy arrow notation which is defined such that any problem of factoring a map through such a map has exactly one solution . There is exactly one map such that in the following diagram:   Picture of epimorphism from Session 22     Also in Session 22, Fatima points out that the two arrows in the graph of the sum are incident at a dot.   Based on this information, I think I can expect my solution to have 3 dots to represent the 3 colors. If the number corresponds to a map to the terminal object, perhaps my other dots might be defined by loops of other sizes?  Consider the following graph:   Guess of F    An fixed point shape can only get mapped to . Any 2-cycle shape can only get mapped to . Any product-like shape would need to be mapped to . Any sum-like shape would need to be mapped to . Any cycle-like shape would have points like .  Out of curiousity, let's depict this graph with a matrix also:   Hey! Look! It's a glider from Conway's Game of Life ! I wonder if that's a coincidence?  If I'm correct, then my tricoloring map applied to from Session 15 should look something like this:     The part of this that I'm unsure of is how to treat the cycle. It seems like there's two ways of mapping the 2-cycle to the 2-cycle, which would imply that my coloring is not necessarily unique. Maybe there's someway I can step out and refer to the initial object to sort the two out? Or maybe this is the intended meaning of induced by exactly one map ? Once you decide how to map the loop, then you have exactly one map?  I think this is as close to an answer as I'm going to get for now.    "
},
{
  "id": "session25-p4-3",
  "level": "2",
  "url": "session25-p4.html#session25-p4-3",
  "type": "Example",
  "number": "5.27.1",
  "title": "Exercise 3: (Part 2\/2?).",
  "body": " Exercise 3: (Part 2\/2?)    Tricoloring continued...    Part (a) asks us to show that an induced tricoloring is a tricoloring . Suppose there's a map that tricolors the dots of graph . By definition of tricoloring, for any arrow in we must have .  Given that our map is a -map, it must preserve structure . Namely, if and then and for every .  It should follow from these that is a tricoloring on .  Suppose is NOT a tricoloring . There must exist some arrow with such that the source and target have the same color. Expand using our definition of to get . By our structure preservation property, this is equivalent to . However, is an arrow in . The definition of tricoloring states that every so the statement generates a contradiction. Our assumption must be false, establishing that the tricoloring induced by composition is in fact a tricoloring.  I kind of wish my Python work was reliable enough to answer part (b), but for now I think I'd like to do some research on references to Fatima that might yield clues.   The book is literally dedicated to Fatima.  The name shows up in Session 1, but as a member of a set.  In Session 8, Fatima comments that maps having the same domain and codomain is a prerequisite condition for being the same map.  In Session 9, Fatima is used as an example for someone's congressional representative. The idea being that the representative is a fixed point of the endomap.  In Session 11, Fatima suggests using the associative property with the structure preservation properties. This is in the context of a map from a 3-cycle to a given graph.  In Session 20, Fatima suggests that the terminal object translates into in arithmetic. Fatimia also points out that this element corresponds with map to a loop .   In Session 22, Fatima asks about the heavy arrow notation which is defined such that any problem of factoring a map through such a map has exactly one solution . There is exactly one map such that in the following diagram:   Picture of epimorphism from Session 22     Also in Session 22, Fatima points out that the two arrows in the graph of the sum are incident at a dot.   Based on this information, I think I can expect my solution to have 3 dots to represent the 3 colors. If the number corresponds to a map to the terminal object, perhaps my other dots might be defined by loops of other sizes?  Consider the following graph:   Guess of F    An fixed point shape can only get mapped to . Any 2-cycle shape can only get mapped to . Any product-like shape would need to be mapped to . Any sum-like shape would need to be mapped to . Any cycle-like shape would have points like .  Out of curiousity, let's depict this graph with a matrix also:   Hey! Look! It's a glider from Conway's Game of Life ! I wonder if that's a coincidence?  If I'm correct, then my tricoloring map applied to from Session 15 should look something like this:     The part of this that I'm unsure of is how to treat the cycle. It seems like there's two ways of mapping the 2-cycle to the 2-cycle, which would imply that my coloring is not necessarily unique. Maybe there's someway I can step out and refer to the initial object to sort the two out? Or maybe this is the intended meaning of induced by exactly one map ? Once you decide how to map the loop, then you have exactly one map?  I think this is as close to an answer as I'm going to get for now.   "
},
{
  "id": "session25-p5",
  "level": "1",
  "url": "session25-p5.html",
  "type": "Section",
  "number": "5.28",
  "title": "Session 25: Labelings and products of graphs, Part 5",
  "body": " Session 25: Labelings and products of graphs, Part 5  I was going to try to make it through this Session and move on, but our air conditionor had other plans for me. It's really hard to focus on math when it's oppressively hot like this. Still, I'm trying to make a little progress each week so I'd like to at least attempt one exercise.   Exercise 4: (Part 2\/2?)   Sequence of graphs...    Let's start with (a), because I think the idea here is that effectively represents my old model of a map . I've been struggling with the concept of map from person to gender , has been so troublesome because I allowed to be undefined . It's not that my old method is necessarily wrong, it's just that not allowing this situation will be necessary to accurately count the maps we want to find.  This question implies that we're working in the category of graphs , so thus maps must preserve source and target maps.   External diagram of f    That is to say, for every map we have both and . Since every map in comes from a map in , and there's exactly one map , we must have . It follows that for every , we have and which implies that .  Next, let's consider the map . It too must preserve structure of source and targets:   External diagram of g    For any , we must have both and . However, there are no arrows in ! It follows that are both the unique map from the empty set to the single dot in . Since , it follows from the structure preservation property that .  Furthermore, our category must be closed under composition so we can construct the following external diagram:   External diagram formed by composing the maps given in part (a)    Since there are no arrows in , as sets and therefore could only be the unique identity map on . It also follows that and would both need to be the unique map . However, the composition defines a map which does not exist as a map in . Having both and together implies a contradiction.  Finally, let's consider the case where neither nor are maps. If there is no map , then there's at least one point with no place to send it to. By the definition of , there's a unique map such that . Likewise, any must also have a corresponding such that . It follows that the composition is a map which contradicts our assumption that no such map exists.  I think the idea here is if we can look at the objects of by looking at compositions of the form . But before we do that we need to some way of telling if or . Having a map means that and , constituting an isomorphsims between and the initial object. Since having a category with sums and products guarantees a map , the non-existence of a map implies the existance of unique composition . The existance of a dot therefore gives us our map through composition.  Let's move on and consider the case in part (b).  Suppose we have a map . We know and in the following diagram:   External diagram of f'    Since doesn't have any arrows, that means that are both the unique map . That means that in order to preserve structure, we'd need to have for any arrow .  Now lets consider a map . We must have the following commutative diagram:   External diagram of g'    I think what I want to do with these is compose them. I'm also going to try to include the maps to\/from termninal\/initial objects.   External diagram formed by composing the maps given in part (b)    After putting this all together, here are some of my observations.  First, both of these maps can't exist together because is not a valid map. There is exactly one arrow in and zero arrows in , and there is no map in from the singleton to the empty set.  I think the reason we need at least one of them to exist is related to the fact that we have two unique maps named . I've indicated these by the purple. If we have a map , then that essentially gives us a map that means is isomorphic to the initial object. This retraction can't exist if is a map because there's no retraction for the unique map .  I'm thinking the idea between parts (c) and (d) is that I'm being set-up with a successor function for an inductive argument, so I'm going to try to summarize my progress so far.  The idea behind (a) was that having a map effectively means by graph isomorphism . If our graph is not empty, then there must be at least one point which is defined by a map . By the definition of terminal object , there's a unique map that we could precompose our point by to get a map .  The idea behind (b) was that a similar line of reasoning applies to our arrows. The naked arrow has two dots and the naked dot has one. Since the map is non-invertable, having both of these maps gives rise to a contradiction.  For part (c), I'm thinking of this in terms of object counts. There's 2 dots and 1 arrow in . There's 3 dots and 2 arrows in . We've got no retraction for nor , so any map must be non-invertable. Let's see what the external diagram looks like if we attempt to compose with .   External diagram formed by composing the maps given in part (c)    Having both of these maps together is problematic because the only map is necessarily the unique identity map. Both of these maps can't exist simultaneously because they're not invertable.  The logical answer for part (d) would seem to be , or the following graph: It also seems like defining would make an obvious choice. We could then start to formulate our induction hypothesis: exactly one of is a map. There's also likely a parallel statement for the dots under the convention that .    I'm still a little fuzzy on all this, but at least this gives me something to refer back to later when I'm better able to focus.  "
},
{
  "id": "session25-p5-3",
  "level": "2",
  "url": "session25-p5.html#session25-p5-3",
  "type": "Example",
  "number": "5.28.1",
  "title": "Exercise 4: (Part 2\/2?).",
  "body": " Exercise 4: (Part 2\/2?)   Sequence of graphs...    Let's start with (a), because I think the idea here is that effectively represents my old model of a map . I've been struggling with the concept of map from person to gender , has been so troublesome because I allowed to be undefined . It's not that my old method is necessarily wrong, it's just that not allowing this situation will be necessary to accurately count the maps we want to find.  This question implies that we're working in the category of graphs , so thus maps must preserve source and target maps.   External diagram of f    That is to say, for every map we have both and . Since every map in comes from a map in , and there's exactly one map , we must have . It follows that for every , we have and which implies that .  Next, let's consider the map . It too must preserve structure of source and targets:   External diagram of g    For any , we must have both and . However, there are no arrows in ! It follows that are both the unique map from the empty set to the single dot in . Since , it follows from the structure preservation property that .  Furthermore, our category must be closed under composition so we can construct the following external diagram:   External diagram formed by composing the maps given in part (a)    Since there are no arrows in , as sets and therefore could only be the unique identity map on . It also follows that and would both need to be the unique map . However, the composition defines a map which does not exist as a map in . Having both and together implies a contradiction.  Finally, let's consider the case where neither nor are maps. If there is no map , then there's at least one point with no place to send it to. By the definition of , there's a unique map such that . Likewise, any must also have a corresponding such that . It follows that the composition is a map which contradicts our assumption that no such map exists.  I think the idea here is if we can look at the objects of by looking at compositions of the form . But before we do that we need to some way of telling if or . Having a map means that and , constituting an isomorphsims between and the initial object. Since having a category with sums and products guarantees a map , the non-existence of a map implies the existance of unique composition . The existance of a dot therefore gives us our map through composition.  Let's move on and consider the case in part (b).  Suppose we have a map . We know and in the following diagram:   External diagram of f'    Since doesn't have any arrows, that means that are both the unique map . That means that in order to preserve structure, we'd need to have for any arrow .  Now lets consider a map . We must have the following commutative diagram:   External diagram of g'    I think what I want to do with these is compose them. I'm also going to try to include the maps to\/from termninal\/initial objects.   External diagram formed by composing the maps given in part (b)    After putting this all together, here are some of my observations.  First, both of these maps can't exist together because is not a valid map. There is exactly one arrow in and zero arrows in , and there is no map in from the singleton to the empty set.  I think the reason we need at least one of them to exist is related to the fact that we have two unique maps named . I've indicated these by the purple. If we have a map , then that essentially gives us a map that means is isomorphic to the initial object. This retraction can't exist if is a map because there's no retraction for the unique map .  I'm thinking the idea between parts (c) and (d) is that I'm being set-up with a successor function for an inductive argument, so I'm going to try to summarize my progress so far.  The idea behind (a) was that having a map effectively means by graph isomorphism . If our graph is not empty, then there must be at least one point which is defined by a map . By the definition of terminal object , there's a unique map that we could precompose our point by to get a map .  The idea behind (b) was that a similar line of reasoning applies to our arrows. The naked arrow has two dots and the naked dot has one. Since the map is non-invertable, having both of these maps gives rise to a contradiction.  For part (c), I'm thinking of this in terms of object counts. There's 2 dots and 1 arrow in . There's 3 dots and 2 arrows in . We've got no retraction for nor , so any map must be non-invertable. Let's see what the external diagram looks like if we attempt to compose with .   External diagram formed by composing the maps given in part (c)    Having both of these maps together is problematic because the only map is necessarily the unique identity map. Both of these maps can't exist simultaneously because they're not invertable.  The logical answer for part (d) would seem to be , or the following graph: It also seems like defining would make an obvious choice. We could then start to formulate our induction hypothesis: exactly one of is a map. There's also likely a parallel statement for the dots under the convention that .   "
},
{
  "id": "session25-p6",
  "level": "1",
  "url": "session25-p6.html",
  "type": "Section",
  "number": "5.29",
  "title": "Session 25: Labelings and products of graphs, Part 6",
  "body": " Session 25: Labelings and products of graphs, Part 6  I'm gong to give these last two exercises a chance, then I'd really like to wrap this up so I can move on.   Exercise 5:   In this exercise, and ...    So lets start by showing is not isomorphic to . Since there are two arrows in and two arrows in , any map must map arrows to arrows. This means that there are only two such maps that preserve structure:   Only two maps from B to C    In both of these cases, the respective map takes 3 dots in and maps them to only 2 dots in . Since there is no retraction from to , the only two maps are non-invertible. This proves that is not isomorphic to .  Next, let's look at the product :   Product of A times B    Similarly, let's also draw out :   Product of A times C    In both of these cases, the product contains 2 disjoint naked arrows and 6 dots total. An isomorphism can be constructed by pairing arrows with arrows and dots with dots. One such map is shown below:   Possible isomorphism    There should be 4 isomorphisms to choose from, but we only needed one. QED.     Exercise 6:   Assuming that , and are objects of a category...    Let's start with the products and . For any pair of maps and , these products define a pair maps and . The definition of product says that there's exactly one such pair of maps with that , , , and . These products can be diagrammed as follows:   X times B_1     X times B_2    Let's now construct a third product to fit the following diagram:   B_1 times B_2    Next, let's consider the sum of and . For any pair of maps and , our sum defines a pair of maps and such that there is a unique map satisfying and    Sum of B_1 and B_2    We can combine the sum and and product diagrams to get the following:   B_1 times B_2    Since our maps and are arbitrary, we can choose them to satisfy .  I think we're also going to need a fourth product for . This should correspond to the following diagram:   X times (B_1 + B_2)    We're also going to need another sum for . It should conform to the following diagram:   Sum of X times B_1 and X times B_2    Our definition sum says there is exactly one map satisfying .  With that, I think we have enough maps to construct the one we're looking for.   QED. Or, at least I hope so. I'm a little uncertain about the existence of this map , but it seems like a reasonable assumption.    And with that, I think I'm ready to push onward.  "
},
{
  "id": "session25-p6-3",
  "level": "2",
  "url": "session25-p6.html#session25-p6-3",
  "type": "Example",
  "number": "5.29.1",
  "title": "Exercise 5:.",
  "body": " Exercise 5:   In this exercise, and ...    So lets start by showing is not isomorphic to . Since there are two arrows in and two arrows in , any map must map arrows to arrows. This means that there are only two such maps that preserve structure:   Only two maps from B to C    In both of these cases, the respective map takes 3 dots in and maps them to only 2 dots in . Since there is no retraction from to , the only two maps are non-invertible. This proves that is not isomorphic to .  Next, let's look at the product :   Product of A times B    Similarly, let's also draw out :   Product of A times C    In both of these cases, the product contains 2 disjoint naked arrows and 6 dots total. An isomorphism can be constructed by pairing arrows with arrows and dots with dots. One such map is shown below:   Possible isomorphism    There should be 4 isomorphisms to choose from, but we only needed one. QED.   "
},
{
  "id": "session25-p6-4",
  "level": "2",
  "url": "session25-p6.html#session25-p6-4",
  "type": "Example",
  "number": "5.29.2",
  "title": "Exercise 6:.",
  "body": " Exercise 6:   Assuming that , and are objects of a category...    Let's start with the products and . For any pair of maps and , these products define a pair maps and . The definition of product says that there's exactly one such pair of maps with that , , , and . These products can be diagrammed as follows:   X times B_1     X times B_2    Let's now construct a third product to fit the following diagram:   B_1 times B_2    Next, let's consider the sum of and . For any pair of maps and , our sum defines a pair of maps and such that there is a unique map satisfying and    Sum of B_1 and B_2    We can combine the sum and and product diagrams to get the following:   B_1 times B_2    Since our maps and are arbitrary, we can choose them to satisfy .  I think we're also going to need a fourth product for . This should correspond to the following diagram:   X times (B_1 + B_2)    We're also going to need another sum for . It should conform to the following diagram:   Sum of X times B_1 and X times B_2    Our definition sum says there is exactly one map satisfying .  With that, I think we have enough maps to construct the one we're looking for.   QED. Or, at least I hope so. I'm a little uncertain about the existence of this map , but it seems like a reasonable assumption.   "
},
{
  "id": "session26",
  "level": "1",
  "url": "session26.html",
  "type": "Section",
  "number": "5.30",
  "title": "Session 26: Distributive categories and linear categories",
  "body": " Session 26: Distributive categories and linear categories  This Session has been an interesting read. I feel like I was on the right track with looking at my graphs as matrices, but I haven't quite been able to connect all the dots yet. This session also refers back to Exercise 20 of Article and I wasn't quite satisfied with my previous work there.   Exercise 1:   Using the above definitions...    We're asked to prove the following: Since that's kind of a lengthy expression, I'm going to call it such that   The matrix product is defined relative to a preferred operator using the matrix form: We can write this simply . I should note that the domains and codomains of these maps are , and . We can define the elements of those matrices using the injections and projections of the category. For example: .  Let's start by taking a look at the map . By the definition of matrix addition , we've defined to be the unique map such that: Applying the definition of matrix multiplication to this gives us: Let's take a closer look at the domains and codomains of that composition: By similar reasoning, we can also deduce the following:     Maybe I can take these maps and turn them into a big nested matrix :   The components of that matrix should have the following domains and codomains:   Maybe I should be thinking of this identity matrix in terms of it's properties? The idea being that and for any  and in the category. What if I were to choose and ?  Our linear category should already contain isomorphisms and . If we also have an isomorphism , then we should be able to use the injections and projections to define an isomorphism .  Consider the following:    Our definition of product and sum mean we have unique maps satisfying defined from . If we precompose by and post compose by , then we get a map which has the same domain and codomain as .  If I'm interpreting this right, this gives us a special matrix that works for any map by interchanging the roles of product and coproduct. Maybe that's the key to showing this ?    I think starting to see why the distributive property to fail in a linear category . I want to spend a little more time exploring so I'll pick this up next week.  "
},
{
  "id": "session26-3",
  "level": "2",
  "url": "session26.html#session26-3",
  "type": "Example",
  "number": "5.30.1",
  "title": "Exercise 1:.",
  "body": " Exercise 1:   Using the above definitions...    We're asked to prove the following: Since that's kind of a lengthy expression, I'm going to call it such that   The matrix product is defined relative to a preferred operator using the matrix form: We can write this simply . I should note that the domains and codomains of these maps are , and . We can define the elements of those matrices using the injections and projections of the category. For example: .  Let's start by taking a look at the map . By the definition of matrix addition , we've defined to be the unique map such that: Applying the definition of matrix multiplication to this gives us: Let's take a closer look at the domains and codomains of that composition: By similar reasoning, we can also deduce the following:     Maybe I can take these maps and turn them into a big nested matrix :   The components of that matrix should have the following domains and codomains:   Maybe I should be thinking of this identity matrix in terms of it's properties? The idea being that and for any  and in the category. What if I were to choose and ?  Our linear category should already contain isomorphisms and . If we also have an isomorphism , then we should be able to use the injections and projections to define an isomorphism .  Consider the following:    Our definition of product and sum mean we have unique maps satisfying defined from . If we precompose by and post compose by , then we get a map which has the same domain and codomain as .  If I'm interpreting this right, this gives us a special matrix that works for any map by interchanging the roles of product and coproduct. Maybe that's the key to showing this ?   "
},
{
  "id": "session26-p2",
  "level": "1",
  "url": "session26-p2.html",
  "type": "Section",
  "number": "5.31",
  "title": "Session 26: Distributive categories and linear categories, Part 2",
  "body": " Session 26: Distributive categories and linear categories, Part 2  Let's pick up where I left off. My previous work on Exercise 1 is in dire need of revision.   Exercise 1: (Part 2\/2)   Continued from last week    I'm starting to get the feeling that I'm overthinking this exercise and the real purpose was to connect the matrix product with composition. I've been basing my Python code around the properties of the adjacency matrix representation of a graph, but this idea really wasn't explicitly made in the text anywhere.  If I'm just thinking of a traditional matrix product , I would evaluate as follows:   My work from last week has a number of errors. Particularly, I mistakely had a duplicate where my should have been, and the text defined opposite to how I did. Specifically, they use such that and for . Using that notation, can write our matrix product as . This gives us the following:   So I think the trink to this is that our category must have identity maps and an associative property. Given a product , we could theoretically substitute or . That gives us and . This would give us the following two equivalences:  and    Using the properties of our identity maps and zero maps, we can simplify those to the following:  and  Considering how we've defined a sum of maps, for any and there should be uniquely defined maps satisfying and In other words, we can add a zero map to any map and get the same map back. If follows that and are both invariate with respect to this map . Our expression for the product above can then be simplified one step more:     And that completes our proof.     Exercise 2: (Part 1\/?)   Prove that a category with initial and terminal objects...    Assuming that our category has intial and terminal objects, any objects that are initial must be isomorphic and any objects that are terminal must be isomorphic. Without loss of generality, we can think of there being a unique objects together with isomorphisms and .  Since our category must also have sums and products, lets consider an arbitrary map . By the definition of as initial there's precisely one map and by the defintion of as terminal there's precisely one map .  Since our category also has sums and products, consider the sum . There should be set of 3 maps satisfying the following commutative diagram:   Commutative diagram of S+X    Likewise, the definition of a product implies the existence of maps sasifying the following:   Commutative diagram of Y times T    Thus, for any map we have the following combined diagram:   Commutative diagram of combined sum and product    By the fact that there is precisely one map , the composition must be that very same map. Since can be any map, why not choose and ? That would give use the following diagram:   Commutative diagram of combined sum and product for f = 1_X    It follows from the uniqueness of the identity map that . We'd also be able to define the unique map as the composition .  This all seems relevant, but considering that I haven't invoked the definition of a zero map yet I must still be missing something.    I think I'm going to pause here and think about this some more.  "
},
{
  "id": "session26-p2-3",
  "level": "2",
  "url": "session26-p2.html#session26-p2-3",
  "type": "Example",
  "number": "5.31.1",
  "title": "Exercise 1: (Part 2\/2).",
  "body": " Exercise 1: (Part 2\/2)   Continued from last week    I'm starting to get the feeling that I'm overthinking this exercise and the real purpose was to connect the matrix product with composition. I've been basing my Python code around the properties of the adjacency matrix representation of a graph, but this idea really wasn't explicitly made in the text anywhere.  If I'm just thinking of a traditional matrix product , I would evaluate as follows:   My work from last week has a number of errors. Particularly, I mistakely had a duplicate where my should have been, and the text defined opposite to how I did. Specifically, they use such that and for . Using that notation, can write our matrix product as . This gives us the following:   So I think the trink to this is that our category must have identity maps and an associative property. Given a product , we could theoretically substitute or . That gives us and . This would give us the following two equivalences:  and    Using the properties of our identity maps and zero maps, we can simplify those to the following:  and  Considering how we've defined a sum of maps, for any and there should be uniquely defined maps satisfying and In other words, we can add a zero map to any map and get the same map back. If follows that and are both invariate with respect to this map . Our expression for the product above can then be simplified one step more:     And that completes our proof.   "
},
{
  "id": "session26-p2-4",
  "level": "2",
  "url": "session26-p2.html#session26-p2-4",
  "type": "Example",
  "number": "5.31.2",
  "title": "Exercise 2: (Part 1\/?).",
  "body": " Exercise 2: (Part 1\/?)   Prove that a category with initial and terminal objects...    Assuming that our category has intial and terminal objects, any objects that are initial must be isomorphic and any objects that are terminal must be isomorphic. Without loss of generality, we can think of there being a unique objects together with isomorphisms and .  Since our category must also have sums and products, lets consider an arbitrary map . By the definition of as initial there's precisely one map and by the defintion of as terminal there's precisely one map .  Since our category also has sums and products, consider the sum . There should be set of 3 maps satisfying the following commutative diagram:   Commutative diagram of S+X    Likewise, the definition of a product implies the existence of maps sasifying the following:   Commutative diagram of Y times T    Thus, for any map we have the following combined diagram:   Commutative diagram of combined sum and product    By the fact that there is precisely one map , the composition must be that very same map. Since can be any map, why not choose and ? That would give use the following diagram:   Commutative diagram of combined sum and product for f = 1_X    It follows from the uniqueness of the identity map that . We'd also be able to define the unique map as the composition .  This all seems relevant, but considering that I haven't invoked the definition of a zero map yet I must still be missing something.   "
},
{
  "id": "session26-p3",
  "level": "1",
  "url": "session26-p3.html",
  "type": "Section",
  "number": "5.32",
  "title": "Session 26: Distributive categories and linear categories, Part 3",
  "body": " Session 26: Distributive categories and linear categories, Part 3  Let's try to wrap this up!   Exercise 2: (Part 2\/2)   Continued from last week...    I'm going to start by taking a step back and looking at what I'm really trying to prove here. This exercise was worded using if and only if , so I need to prove both of the following statements:    If an initial object is isomorphic to a terminal object, then the category has zero maps.    If a category has zero maps, then an initial object is isomorphic to a terminal object.    In a category with initial and terminal objects, we're assured to have exactly one map . This map is an isomorphism if and only if there's a respective inverse map such that and .  We've defined zero maps by the property that any map composed with a zero map produces another zero map. In symbolic form:   Okay, lets focus on the first statement. We assume exists then need to show that it gives rise to some zero map . Specifically, I think we can define relative to the uniquely defined maps and . Simply define as the composition .  So how can we demonstrate that is a zero map ? We'd need to look at every possible composition and to ensure we get another zero map. We can define relative to the unique maps and by . If , there would need to be some point such that . Expanding with our definitions of the zero maps: Which can only happen if But is a uniquely defined map with that codomain and domain! It follows from this contradiction that our assumption is false, and consequently that is a zero map. Likewise, we can define relative to the unique maps and by . If we assume , then there must exist some satisfying . Expanding this gives us the following: Which can only happen when: Since is the unique map with that domain and codomain, we get a contradiction. Our assumption that must therefore be false.  Essentially, by having a map we can define a zero map between any objects in through the unique composition .  Having demonstrated that we can construct our zero maps from , let's attempt to do the reverse.  Suppose we have a zero maps with the property that for any maps and , the composition and . The associative property of the category says that , so we must have the case that .  If this is true for any maps , let's choose the uniquely defined maps and . It follows from the above that . Let's see we can assemble this into the commutative diagram from last week:   Commutative diagram for 0_{(S + T)(S times T)}    In this diagram, we get a zero map from defined through this unique composition . This map has a inverse given by . Knowing that and , we could simplify these maps down to and . These maps satisfy the property of the we were looking for, namely that and .  With that, I believe this exercise is complete.    "
},
{
  "id": "session26-p3-3",
  "level": "2",
  "url": "session26-p3.html#session26-p3-3",
  "type": "Example",
  "number": "5.32.1",
  "title": "Exercise 2: (Part 2\/2).",
  "body": " Exercise 2: (Part 2\/2)   Continued from last week...    I'm going to start by taking a step back and looking at what I'm really trying to prove here. This exercise was worded using if and only if , so I need to prove both of the following statements:    If an initial object is isomorphic to a terminal object, then the category has zero maps.    If a category has zero maps, then an initial object is isomorphic to a terminal object.    In a category with initial and terminal objects, we're assured to have exactly one map . This map is an isomorphism if and only if there's a respective inverse map such that and .  We've defined zero maps by the property that any map composed with a zero map produces another zero map. In symbolic form:   Okay, lets focus on the first statement. We assume exists then need to show that it gives rise to some zero map . Specifically, I think we can define relative to the uniquely defined maps and . Simply define as the composition .  So how can we demonstrate that is a zero map ? We'd need to look at every possible composition and to ensure we get another zero map. We can define relative to the unique maps and by . If , there would need to be some point such that . Expanding with our definitions of the zero maps: Which can only happen if But is a uniquely defined map with that codomain and domain! It follows from this contradiction that our assumption is false, and consequently that is a zero map. Likewise, we can define relative to the unique maps and by . If we assume , then there must exist some satisfying . Expanding this gives us the following: Which can only happen when: Since is the unique map with that domain and codomain, we get a contradiction. Our assumption that must therefore be false.  Essentially, by having a map we can define a zero map between any objects in through the unique composition .  Having demonstrated that we can construct our zero maps from , let's attempt to do the reverse.  Suppose we have a zero maps with the property that for any maps and , the composition and . The associative property of the category says that , so we must have the case that .  If this is true for any maps , let's choose the uniquely defined maps and . It follows from the above that . Let's see we can assemble this into the commutative diagram from last week:   Commutative diagram for 0_{(S + T)(S times T)}    In this diagram, we get a zero map from defined through this unique composition . This map has a inverse given by . Knowing that and , we could simplify these maps down to and . These maps satisfy the property of the we were looking for, namely that and .  With that, I believe this exercise is complete.   "
},
{
  "id": "session27",
  "level": "1",
  "url": "session27.html",
  "type": "Section",
  "number": "5.33",
  "title": "Session 27: Examples of universal constructions",
  "body": " Session 27: Examples of universal constructions  Let's jump right in!   Exercise 1:   Prove that if and are objects and , then ...    They asked me to translate , so that's what I'll try to do!  With the statement , we're assuming we have we have a pair of projection maps such that for every object with maps there is exactly one map with and . Our category must allow compositions so we know we have some map in .  Suppose is a another map in such that . For to be true, there where would need to exist some such that . Or more explicitly: However, the composition is a map and there's only one such map: namely the identity . The right side of this can be simplified using the associative property . This implies and are the same map.  Thus, there is exactly one map and one map . This implies and are terminal objects .  And that completes the proof.    This proof seems deceptively simple. I feel like the rest of these exercises are going to get deep, so I'm going to rest here for now.  "
},
{
  "id": "session27-3",
  "level": "2",
  "url": "session27.html#session27-3",
  "type": "Example",
  "number": "5.33.1",
  "title": "Exercise 1:.",
  "body": " Exercise 1:   Prove that if and are objects and , then ...    They asked me to translate , so that's what I'll try to do!  With the statement , we're assuming we have we have a pair of projection maps such that for every object with maps there is exactly one map with and . Our category must allow compositions so we know we have some map in .  Suppose is a another map in such that . For to be true, there where would need to exist some such that . Or more explicitly: However, the composition is a map and there's only one such map: namely the identity . The right side of this can be simplified using the associative property . This implies and are the same map.  Thus, there is exactly one map and one map . This implies and are terminal objects .  And that completes the proof.   "
},
{
  "id": "session27-p2",
  "level": "1",
  "url": "session27-p2.html",
  "type": "Section",
  "number": "5.34",
  "title": "Session 27: Examples of universal constructions, Part 2",
  "body": " Session 27: Examples of universal constructions, Part 2  I think I want to try something a little different with this next exercise and write out the proofs for sum and product side by side.   Exercise 2:   a) Show that if has the property...    Part a)   Given such that for every there is at most one map , prove  Two identity maps in a product   is a product.  Given such that for every there is at most one map , prove  Two identity maps in a sum   is a sum.    For to be a product, we need to prove that for any object and pair of maps and , we have exactly one map for which and .  For to be a sum, we need to prove that for any object and pair of maps and , we have exactly one map for which and .    Let and be an arbitrary pair of maps map in the category.  Let and be an arbitrary pair of maps map in the category.    We've defined such there is at most one map . Given that exist, they must both be equal to this unique map .  We've defined such there is at most one map . Given that exist, they must both be equal to this unique map .    Since and , and both become the composition . This follows directly from the definition of the identity map, so we've effectively demonstrated that is a product.  Since and , and both become the composition . This follows directly from the definition of the identity map, so we've effectively demonstrated that is a sum.   Part b)   Show that [the above property] is equivalent to the statement that the unique map is a monomorphism .  Show that [the above property] is equivalent to the statement that the unique map is a epimorphism .    A monomorphism  is defined as an injective map such that for every pair of maps and , implies .  A epimorphism  is defined as an surjective map such that for every pair of maps and , implies .    Consider the composition defined by . By the definition of terminal object, there is exactly one map , so must be this unique map. Thus, having with the at most one map property implies is a monomorphism .  Consider the composition defined by . By the definition of initial object, there is exactly one map , so must be this unique map. Thus, having with the at most one map property implies is a epimorphism .    Next, we must prove the converse. We start by supposing is a monomorphism .  Next, we must prove the converse. We start by supposing is a epimorphism .    The statement is logically equivalent to the contrapositive . However, and are both defined with domain and codomains of and the definition of terminal objects says this map is unique.  The statement is logically equivalent to the contrapositive . However, and are both defined with domain and codomains of and the definition of initial objects says this map is unique.    By assuming there are two maps and with , there would need to exist some a map such that . However, this means the compositions and are both maps . By the definition of terminal object, there is only one such map so we're forced to conclude that are both equivalent to this unique map.  By assuming there are two maps and with , there would need to exist some a map such that . However, this means the compositions and are both maps . By the definition of initial object, there is only one such map so we're forced to conclude that are both equivalent to this unique map.    Effectively, if we have a monomorphism we can construct the unique map relative to by way of the composition . If such an inverse exists it must necessarily be unique, so the at most one map property follows from this uniqueness.  Effectively, if we have a epimorphism we can construct the unique map relative to by way of the composition . If such an inverse exists it must necessarily be unique, so the at most one map property follows from this uniqueness.     I think that was good practice. The two proofs are basically the same but mirrored. It still seems weird how we used points to test for equality when there's no points in for the category of sets, but hopefully the next exercise will help with that.  "
},
{
  "id": "session27-p2-3",
  "level": "2",
  "url": "session27-p2.html#session27-p2-3",
  "type": "Example",
  "number": "5.34.1",
  "title": "Exercise 2:.",
  "body": " Exercise 2:   a) Show that if has the property...    Part a)   Given such that for every there is at most one map , prove  Two identity maps in a product   is a product.  Given such that for every there is at most one map , prove  Two identity maps in a sum   is a sum.    For to be a product, we need to prove that for any object and pair of maps and , we have exactly one map for which and .  For to be a sum, we need to prove that for any object and pair of maps and , we have exactly one map for which and .    Let and be an arbitrary pair of maps map in the category.  Let and be an arbitrary pair of maps map in the category.    We've defined such there is at most one map . Given that exist, they must both be equal to this unique map .  We've defined such there is at most one map . Given that exist, they must both be equal to this unique map .    Since and , and both become the composition . This follows directly from the definition of the identity map, so we've effectively demonstrated that is a product.  Since and , and both become the composition . This follows directly from the definition of the identity map, so we've effectively demonstrated that is a sum.   Part b)   Show that [the above property] is equivalent to the statement that the unique map is a monomorphism .  Show that [the above property] is equivalent to the statement that the unique map is a epimorphism .    A monomorphism  is defined as an injective map such that for every pair of maps and , implies .  A epimorphism  is defined as an surjective map such that for every pair of maps and , implies .    Consider the composition defined by . By the definition of terminal object, there is exactly one map , so must be this unique map. Thus, having with the at most one map property implies is a monomorphism .  Consider the composition defined by . By the definition of initial object, there is exactly one map , so must be this unique map. Thus, having with the at most one map property implies is a epimorphism .    Next, we must prove the converse. We start by supposing is a monomorphism .  Next, we must prove the converse. We start by supposing is a epimorphism .    The statement is logically equivalent to the contrapositive . However, and are both defined with domain and codomains of and the definition of terminal objects says this map is unique.  The statement is logically equivalent to the contrapositive . However, and are both defined with domain and codomains of and the definition of initial objects says this map is unique.    By assuming there are two maps and with , there would need to exist some a map such that . However, this means the compositions and are both maps . By the definition of terminal object, there is only one such map so we're forced to conclude that are both equivalent to this unique map.  By assuming there are two maps and with , there would need to exist some a map such that . However, this means the compositions and are both maps . By the definition of initial object, there is only one such map so we're forced to conclude that are both equivalent to this unique map.    Effectively, if we have a monomorphism we can construct the unique map relative to by way of the composition . If such an inverse exists it must necessarily be unique, so the at most one map property follows from this uniqueness.  Effectively, if we have a epimorphism we can construct the unique map relative to by way of the composition . If such an inverse exists it must necessarily be unique, so the at most one map property follows from this uniqueness.    "
},
{
  "id": "session27-p3",
  "level": "1",
  "url": "session27-p3.html",
  "type": "Section",
  "number": "5.35",
  "title": "Session 27: Examples of universal constructions, Part 3",
  "body": " Session 27: Examples of universal constructions, Part 3  I feel like this week's problem is related to my earlier attempts to enumerate all possible graphs. I would feel a lot more confident about my answer here if I had some way of telling that no object other than the ones I found have the property, and induction would give me a way to do so.   Exercise 3:   Find all objects in...    We're looking for objects in , , and , such that the following is a product:  Product     Based on the preceeding text, we know satisfies this property, at least in . If is non-empty there's no map , and if is empty there is exactly one.  I'm thinking that should have this property also, at least in . By the definition of terminal object, there is exactly one map for any in . Any two maps and could only possibly be the unique identity map , so would all be the same map.  Well, what happens if ? Suppose and are arbitrary maps in the category. Is there a unique such that and ?  Maybe I can construct one using the unique antipodal map by using the property that . For any map , there is a corresponding map with the property that . We could then check this map against to see whether or they are the same map. The statement says that we have . Equivalently, with . Postcompose both sides by to get , and apply to get . This would be equivalent to saying .  In a category with an initial object and terminal object , there's exactly one map exactly one map , exactly one map , and exactly one map . There are precisely four maps , so maybe we can pair up them up somehow these with those four cases.  Given some , we need to be the unique map and need to be the unique map . However, is also a map so it must be the same as our unique one. Likewise, the composition would need to be the same as since both are the unique map .  As I start to talk myself in circles here, I'm starting to wonder if our objects our necessarily the cycles of length . In the category , the above map must preserve the structure of such that . For any object , we have two unique identity maps defined by and respectively.  Likewise, a cycle in would have two distinct identities also. There's one cycle going clockwise and another counter-clockwise , and both cycles loop back to the beginning. It would make sense that the set of objects for which is a product are precisely those which are isomorphic to the terminal object.    I'm not sure if I'm satisfied with my work here, but I also can't wait to see what comes next! This following section about Cantor's isomorphism seems very similar to how I tried to count my structure preserving maps before. Maybe I'll finally figure out what I did wrong back in Session 15!  "
},
{
  "id": "session27-p3-3",
  "level": "2",
  "url": "session27-p3.html#session27-p3-3",
  "type": "Example",
  "number": "5.35.1",
  "title": "Exercise 3:.",
  "body": " Exercise 3:   Find all objects in...    We're looking for objects in , , and , such that the following is a product:  Product     Based on the preceeding text, we know satisfies this property, at least in . If is non-empty there's no map , and if is empty there is exactly one.  I'm thinking that should have this property also, at least in . By the definition of terminal object, there is exactly one map for any in . Any two maps and could only possibly be the unique identity map , so would all be the same map.  Well, what happens if ? Suppose and are arbitrary maps in the category. Is there a unique such that and ?  Maybe I can construct one using the unique antipodal map by using the property that . For any map , there is a corresponding map with the property that . We could then check this map against to see whether or they are the same map. The statement says that we have . Equivalently, with . Postcompose both sides by to get , and apply to get . This would be equivalent to saying .  In a category with an initial object and terminal object , there's exactly one map exactly one map , exactly one map , and exactly one map . There are precisely four maps , so maybe we can pair up them up somehow these with those four cases.  Given some , we need to be the unique map and need to be the unique map . However, is also a map so it must be the same as our unique one. Likewise, the composition would need to be the same as since both are the unique map .  As I start to talk myself in circles here, I'm starting to wonder if our objects our necessarily the cycles of length . In the category , the above map must preserve the structure of such that . For any object , we have two unique identity maps defined by and respectively.  Likewise, a cycle in would have two distinct identities also. There's one cycle going clockwise and another counter-clockwise , and both cycles loop back to the beginning. It would make sense that the set of objects for which is a product are precisely those which are isomorphic to the terminal object.   "
},
{
  "id": "session27-p4",
  "level": "1",
  "url": "session27-p4.html",
  "type": "Section",
  "number": "5.36",
  "title": "Session 27: Examples of universal constructions, Part 4",
  "body": " Session 27: Examples of universal constructions, Part 4  I had previously done some Python work way back in Session 15 regarding the Pairing function , so this week's exercise provided a good opportunity to better understand how it works under the hood.   Exercise 4:   The inverse, call it , of the isomorphism...    We're given a map that enumerates pairs of natural numbers in a diagonal order. I had originally defined this in Python as follows:  For the purposes of this problem, we're really only going to need the first 5 values. Specifically: , , , , , and . We're given than the inverse map has a form defined by   The first part of this question follows from some simple substitions. Reversing our 6 point pairings for defines the following pairings for : , , , , , and .  Since we've already assumed has a specific form, these expressions become the following: Which matches our expected result. Which implies that . Which implies that . With our previous subsititions, which gives us . Applying our previous substitions gives us , which means . Applying our substitions gives us which means that and .  Having found all our constants, we can define as   For comparison, the Python code I wrote previously went like this: def zig_zag(n): last = (0,0) idx = 0 while idx < n: yield last idx += 1 if last[1] == 0: last = (0,last[0]+1) else: last = (last[0]+1,last[1]-1) def triangular(n): return int((n+1)*n\/2) def reverse_zig_zag(p): my_sum = p[0]+p[1] my_triangle = triangular(my_sum) return my_triangle+p[0]   I think my implementation is equivalent, only I swapped the order of the arguments . My zig_zag function took repeated south-east treks instead.  I think the key lies in the fact that . Knowing this fact allows us to rewrite as follows:      In my Python code, I had slightly abstracted this by referring to trianglular numbers as defined by the expression . If we subsitute we get the . Since I also swapped the order of the arguments, I needed to add an instead of a to match up with my ordering of the product.  So what does it mean to prove this is an isomorphism of sets ? Well, we'd need to show and .  I think we might be able to show using induction. We know and because of how we constructed . If we further assume for , can we prove also?  Suppose . We can define as for and for to simulate the repeated northwest treks .  For , we can simplify : But also means that our successor is , and we have        For any where , we'd have          Having met our induction hypothesis in both cases, we can now confidently say .  What about the opposite direction? Can we use the same tactic to show ?  We can establish some trivial cases to start with. For we have . For we have . For we have . For we have .  Now lets suppose . If we can prove that , , and , that should allow us to use induction to prove it for all .  Let's consider first.     This result is somewhate interesting because every diagonal has a constant sum given by .  Likewise, we can expand as follows:        Well, that's doubly interesting. It follows from both of those results that for all .  Let's consider the last case . Substituting into ...       Note that we could also infer here based on our previous result. We might even go so far as to say for all . We can easily verify that and for our initial case.  It feels like this induction is still a little unclear. Essentially, I'm doing this weird thing where I'm inducing over such that to prove the statement for all .    I think I'm going to stop here and let these ideas simmer a bit longer.  "
},
{
  "id": "session27-p4-3",
  "level": "2",
  "url": "session27-p4.html#session27-p4-3",
  "type": "Example",
  "number": "5.36.1",
  "title": "Exercise 4:.",
  "body": " Exercise 4:   The inverse, call it , of the isomorphism...    We're given a map that enumerates pairs of natural numbers in a diagonal order. I had originally defined this in Python as follows:  For the purposes of this problem, we're really only going to need the first 5 values. Specifically: , , , , , and . We're given than the inverse map has a form defined by   The first part of this question follows from some simple substitions. Reversing our 6 point pairings for defines the following pairings for : , , , , , and .  Since we've already assumed has a specific form, these expressions become the following: Which matches our expected result. Which implies that . Which implies that . With our previous subsititions, which gives us . Applying our previous substitions gives us , which means . Applying our substitions gives us which means that and .  Having found all our constants, we can define as   For comparison, the Python code I wrote previously went like this: def zig_zag(n): last = (0,0) idx = 0 while idx < n: yield last idx += 1 if last[1] == 0: last = (0,last[0]+1) else: last = (last[0]+1,last[1]-1) def triangular(n): return int((n+1)*n\/2) def reverse_zig_zag(p): my_sum = p[0]+p[1] my_triangle = triangular(my_sum) return my_triangle+p[0]   I think my implementation is equivalent, only I swapped the order of the arguments . My zig_zag function took repeated south-east treks instead.  I think the key lies in the fact that . Knowing this fact allows us to rewrite as follows:      In my Python code, I had slightly abstracted this by referring to trianglular numbers as defined by the expression . If we subsitute we get the . Since I also swapped the order of the arguments, I needed to add an instead of a to match up with my ordering of the product.  So what does it mean to prove this is an isomorphism of sets ? Well, we'd need to show and .  I think we might be able to show using induction. We know and because of how we constructed . If we further assume for , can we prove also?  Suppose . We can define as for and for to simulate the repeated northwest treks .  For , we can simplify : But also means that our successor is , and we have        For any where , we'd have          Having met our induction hypothesis in both cases, we can now confidently say .  What about the opposite direction? Can we use the same tactic to show ?  We can establish some trivial cases to start with. For we have . For we have . For we have . For we have .  Now lets suppose . If we can prove that , , and , that should allow us to use induction to prove it for all .  Let's consider first.     This result is somewhate interesting because every diagonal has a constant sum given by .  Likewise, we can expand as follows:        Well, that's doubly interesting. It follows from both of those results that for all .  Let's consider the last case . Substituting into ...       Note that we could also infer here based on our previous result. We might even go so far as to say for all . We can easily verify that and for our initial case.  It feels like this induction is still a little unclear. Essentially, I'm doing this weird thing where I'm inducing over such that to prove the statement for all .   "
},
{
  "id": "session27-p5",
  "level": "1",
  "url": "session27-p5.html",
  "type": "Section",
  "number": "5.37",
  "title": "Session 27: Examples of universal constructions, Part 5",
  "body": " Session 27: Examples of universal constructions, Part 5  I think I want to come back to Exercise 4 again to see if I can address the remaining parts of the question.   Exercise 4: (Part 2)   Continued from last week...    In one of my previous sessions, I implemented this map that I'm looking for in Python as follows:  def from_zig_zag_N(n): # inverse of reverse_zig_zag # see also https:\/\/en.wikipedia.org\/wiki\/Pairing_function w = floor((sqrt(8*n+1)-1)\/2) t = (w*w+w)\/2 x = n-t y = w-x return (int(x),int(y))  The only difference is that I'll need to swap and to match the book's northwest ordering.  Given , we can compose with one of two ways: or .  Performing the necessary swap from my code above, lets define and where and . Applying these to :         That shouldn't be suprising given that I proved last week using induction. What about the other composition? I'm still not quite confident I've established that .  Maybe it might be helpful to evaluate for some small values of . We can think of as maps . For :    For :    For :    For :    For :    For :    For :      I'm beginning to see some patterns here. The sequence goes which has copies of each . The sequence goes are matching repeated copies of my triangular numbers  . Those numbers are important because they satisfy . Each triangular number is determined by the sum of some consecutive set of natural numbers, so we should have for all . What's unclear to me is where comes from.  Given a map , we basically have a compound inequality which needs to be satisfied: We can rewrite into : Multiply everything by : Add : For , so our inequality should hold if we square everything:      The expression is basically , so...   This seems very similar to the definition of above. Maybe that's the key to finishing my induction proof from last week?  It's pretty clear that is not invertable since output values repeat for the floor function, but mabye solving for might give me some clue to go forward.         And our triangular numbers show up again! So our choice of is basically defined by the unique inverse of the trianglular numbers in the reals .  The final part of this question asks why the map can't be a polynomial, and maybe it's because those triangular numbers have a unique inverse in that map is non-polynomial in nature.    There's still some things here I'm uncertain about, but I feel better having at least attempted the rest of the exercise.  "
},
{
  "id": "session27-p5-3",
  "level": "2",
  "url": "session27-p5.html#session27-p5-3",
  "type": "Example",
  "number": "5.37.1",
  "title": "Exercise 4: (Part 2).",
  "body": " Exercise 4: (Part 2)   Continued from last week...    In one of my previous sessions, I implemented this map that I'm looking for in Python as follows:  def from_zig_zag_N(n): # inverse of reverse_zig_zag # see also https:\/\/en.wikipedia.org\/wiki\/Pairing_function w = floor((sqrt(8*n+1)-1)\/2) t = (w*w+w)\/2 x = n-t y = w-x return (int(x),int(y))  The only difference is that I'll need to swap and to match the book's northwest ordering.  Given , we can compose with one of two ways: or .  Performing the necessary swap from my code above, lets define and where and . Applying these to :         That shouldn't be suprising given that I proved last week using induction. What about the other composition? I'm still not quite confident I've established that .  Maybe it might be helpful to evaluate for some small values of . We can think of as maps . For :    For :    For :    For :    For :    For :    For :      I'm beginning to see some patterns here. The sequence goes which has copies of each . The sequence goes are matching repeated copies of my triangular numbers  . Those numbers are important because they satisfy . Each triangular number is determined by the sum of some consecutive set of natural numbers, so we should have for all . What's unclear to me is where comes from.  Given a map , we basically have a compound inequality which needs to be satisfied: We can rewrite into : Multiply everything by : Add : For , so our inequality should hold if we square everything:      The expression is basically , so...   This seems very similar to the definition of above. Maybe that's the key to finishing my induction proof from last week?  It's pretty clear that is not invertable since output values repeat for the floor function, but mabye solving for might give me some clue to go forward.         And our triangular numbers show up again! So our choice of is basically defined by the unique inverse of the trianglular numbers in the reals .  The final part of this question asks why the map can't be a polynomial, and maybe it's because those triangular numbers have a unique inverse in that map is non-polynomial in nature.   "
},
{
  "id": "session27-p6",
  "level": "1",
  "url": "session27-p6.html",
  "type": "Section",
  "number": "5.38",
  "title": "Session 27: Examples of universal constructions, Part 6",
  "body": " Session 27: Examples of universal constructions, Part 6  Time to find out what an equalizer is!   Exercise 5:   If both and are equalizers...    The text has defined an equalizer of two maps as a map if and for each for which , there is exactly one for which .  Since is also an equalizer of the same pair , then must satisfy and for each for which , there is exactly one for which .  We're asked to prove that there is a unique map for which is an isomorphism.  By the definition of as a terminal object, there is a unique map and a unique map . I claim that is actually the unique map for which and is its unique inverse . To establish this, I need to show , , and .  Suppose . There would need to exist some some such that . Expanding with my above defintion gives us . Since is a map it could only be the unique map . It follows that . Since is a map , the definition of as an equalizer says that for there is exactly one map for all satisfying , contradicting our assumption that and implying that in fact .  Expanding using those definitions above gives us . We can regroup these terms using the associative property to get . Since is a map , it could only be the unique map . Our expression for becomes or simply .  Suppose . There would need to be some such that . However, could only possibly be the map . It follows that , but this contradicts our definition of as an equalizer if we post-compose by to get . The composition is a map  so any would contradict the definition of as an equalizer.  Likewise, expanding gives us . Once again, the terms in the middle can be regrouped to get and we can use the fact that to simplify down to . If were anything other than , it would contradict our definition of as an equalizer.    This is still a bit confusing, but hopefully the follow-up exercises shed some more light on it.  "
},
{
  "id": "session27-p6-3",
  "level": "2",
  "url": "session27-p6.html#session27-p6-3",
  "type": "Example",
  "number": "5.38.1",
  "title": "Exercise 5:.",
  "body": " Exercise 5:   If both and are equalizers...    The text has defined an equalizer of two maps as a map if and for each for which , there is exactly one for which .  Since is also an equalizer of the same pair , then must satisfy and for each for which , there is exactly one for which .  We're asked to prove that there is a unique map for which is an isomorphism.  By the definition of as a terminal object, there is a unique map and a unique map . I claim that is actually the unique map for which and is its unique inverse . To establish this, I need to show , , and .  Suppose . There would need to exist some some such that . Expanding with my above defintion gives us . Since is a map it could only be the unique map . It follows that . Since is a map , the definition of as an equalizer says that for there is exactly one map for all satisfying , contradicting our assumption that and implying that in fact .  Expanding using those definitions above gives us . We can regroup these terms using the associative property to get . Since is a map , it could only be the unique map . Our expression for becomes or simply .  Suppose . There would need to be some such that . However, could only possibly be the map . It follows that , but this contradicts our definition of as an equalizer if we post-compose by to get . The composition is a map  so any would contradict the definition of as an equalizer.  Likewise, expanding gives us . Once again, the terms in the middle can be regrouped to get and we can use the fact that to simplify down to . If were anything other than , it would contradict our definition of as an equalizer.   "
},
{
  "id": "session27-p7",
  "level": "1",
  "url": "session27-p7.html",
  "type": "Section",
  "number": "5.39",
  "title": "Session 27: Examples of universal constructions, Part 7",
  "body": " Session 27: Examples of universal constructions, Part 7  Continuing where I left off with equalizers...   Exercise 6:   Any map which is an equalizer...    Given that is an equalizer of the pair , we know that for each for which there is exactly one map for which .  To demonstrate that is a monomorphsim, we need to show injectivity: that for any pair of maps and , implies .  The contrapositive of this definition says that implies .  So let's assume is not a monomorphism .  In that case, we'd have arbitrary pair of maps and with , but for which .  If , there exists some such that . But there is only one map by the definition of terminal objects. Since all terminal objects are isomorphic, we have a unique map such that and .  Let's use these maps to define two points and by the compositions and . Since there's a unique inverse map corresponding to each point , the following compositions must both produce the only map , our identity map :    Since we've already assumed , that means that . This brings us to a contradiction because the inverse maps are supposed to be unique for . There is no retraction for the map . It follows that our assumption was wrong, and is, in fact, a monomorphism.  I'm thinking that the big idea here is that having two points and and two maps allows use to define four points , but if the points in are isomorphic to the points out , then those four points need collapse to form pairs of two after we apply . Either and , or and .    I'm not really confident in all this, so I may need to come back here later.  "
},
{
  "id": "session27-p7-3",
  "level": "2",
  "url": "session27-p7.html#session27-p7-3",
  "type": "Example",
  "number": "5.39.1",
  "title": "Exercise 6:.",
  "body": " Exercise 6:   Any map which is an equalizer...    Given that is an equalizer of the pair , we know that for each for which there is exactly one map for which .  To demonstrate that is a monomorphsim, we need to show injectivity: that for any pair of maps and , implies .  The contrapositive of this definition says that implies .  So let's assume is not a monomorphism .  In that case, we'd have arbitrary pair of maps and with , but for which .  If , there exists some such that . But there is only one map by the definition of terminal objects. Since all terminal objects are isomorphic, we have a unique map such that and .  Let's use these maps to define two points and by the compositions and . Since there's a unique inverse map corresponding to each point , the following compositions must both produce the only map , our identity map :    Since we've already assumed , that means that . This brings us to a contradiction because the inverse maps are supposed to be unique for . There is no retraction for the map . It follows that our assumption was wrong, and is, in fact, a monomorphism.  I'm thinking that the big idea here is that having two points and and two maps allows use to define four points , but if the points in are isomorphic to the points out , then those four points need collapse to form pairs of two after we apply . Either and , or and .   "
},
{
  "id": "session27-p8",
  "level": "1",
  "url": "session27-p8.html",
  "type": "Section",
  "number": "5.40",
  "title": "Session 27: Examples of universal constructions, Part 8",
  "body": " Session 27: Examples of universal constructions, Part 8  Let's keep pushing forward...   Exercise 5:   If ...    We're given that and is idempotent. Recall that is idempotent if and only if . This fact follows from associative and identity properties: .  We're asked to prove that is an equalizer for the pair . Per the definition, is an equalizer of if and for each for which , there is exactly one for which .  Let's start by demonstrating that .  Given that , we can precompose by to get . By the associative property, , and . Subsitute and rewrite the identity maps to get .  Step one: complete. Our next one look a little trickier.  For every for which (or simply ), we need to prove there is exactly one map for which .  First, we need to demonstrate that some such must exist, then prove that we can't have more than one such map.  It seems obvious that for any satisfying the existance of some would be guaranteed by the composition . Clearly has the appropriate domain and codomain. Given , it follows that we can postcompose both sides by to show . The only remaining part of the question is: why can't we have more than one such map?  Suppose we have a second map satisfying for some . For us to have we'd need to have a point such that . However, there is precisely one map by the definition of terminal objects and that map needs to be an isomorphism.  Since we know , we can postcompose by and apply to get This contradicts our assumption that and proves is unique.  This feels a bit like a vacuous truth . If there's no such that , then it doesn't matter what the conclusion of the conditional statement is.    I feel like this is another week with another unsatisfactory answer. I'm left wondering if I was supposed to invoke a sum or product somehow to ensure the uniqueness of my map.  "
},
{
  "id": "session27-p8-3",
  "level": "2",
  "url": "session27-p8.html#session27-p8-3",
  "type": "Example",
  "number": "5.40.1",
  "title": "Exercise 5:.",
  "body": " Exercise 5:   If ...    We're given that and is idempotent. Recall that is idempotent if and only if . This fact follows from associative and identity properties: .  We're asked to prove that is an equalizer for the pair . Per the definition, is an equalizer of if and for each for which , there is exactly one for which .  Let's start by demonstrating that .  Given that , we can precompose by to get . By the associative property, , and . Subsitute and rewrite the identity maps to get .  Step one: complete. Our next one look a little trickier.  For every for which (or simply ), we need to prove there is exactly one map for which .  First, we need to demonstrate that some such must exist, then prove that we can't have more than one such map.  It seems obvious that for any satisfying the existance of some would be guaranteed by the composition . Clearly has the appropriate domain and codomain. Given , it follows that we can postcompose both sides by to show . The only remaining part of the question is: why can't we have more than one such map?  Suppose we have a second map satisfying for some . For us to have we'd need to have a point such that . However, there is precisely one map by the definition of terminal objects and that map needs to be an isomorphism.  Since we know , we can postcompose by and apply to get This contradicts our assumption that and proves is unique.  This feels a bit like a vacuous truth . If there's no such that , then it doesn't matter what the conclusion of the conditional statement is.   "
},
{
  "id": "session27-p9",
  "level": "1",
  "url": "session27-p9.html",
  "type": "Section",
  "number": "5.41",
  "title": "Session 27: Examples of universal constructions, Part 9",
  "body": " Session 27: Examples of universal constructions, Part 9  I'm feeling a little lost here so I'll have to break this one into parts.   Exercise 8: (Part 1)   Any parallel pair of maps in sets...    I'm going out on a limb with my metagaming here and hypothesize that the arrows named by the equalizer are related to the either the section of the product or retraction from the sum . The diagram below the problem and choice of letter are just too convenient.  Let's consider a simple example defined by and . The output of would be the sequence and the output of would be the sequence .  I'm thinking that my equalizer should be the map that produces a sequences of indices where have the same outputs. These two sequences match up for the first 3 of every 6 steps, producing the sequence the sequence . This map can be defined by the formula , but it strikes me as interesting that we kind of need to step out through in order to do division.  So how can I demonstrate that is an equalizer? Well, it makes sense that because there are countably infinite solutions to . It is also true that for each such that there is exactly one such that because is strictly monotonic and therefore one-to-one. In this case our would be uniquely defined by its relation to the inverse of . I could probably even work out for my particular example if I had to, but I think I'm already trivializing the proof I'm looking for by choosing an example where in the first place.  I think what's going on here is that we can test for equality two different ways by checking if or . For any point where , it must be true that and . Even if we have , we'd still be guaranteed to have the sum and . Perhaps the trick to this will be expressing and in terms of the initial and terminal objects.  Let's come back to the original question, which had to deal with an arbitrary equalizer to an arbitrary pair of parallel maps . By definition, and for every for which , there is exactly one for which .  Perhaps we can break this down in four cases:    is neither initial nor terminal     is initial but not terminal     is terminal but not initial     is both initial and terminal     For an initial object , we'd be able to express a zero map  through the following composition: Since that map is unique, for all .  If is an initial object then it would be isomorphic to . This gives us maps and satisfying and . Effectively, the unique map would meet the definition of an equalizer because and would both need to be unique map .  So what if is not an initial object? The definition of implies that the map is unique, but  not being intial implies this map is non-invertible: there is no retraction . That in turn gives us a pair of maps satisfying and a unique map such that . Maybe this is where I need to invoke the product?  I think I'll need to spend some more time on this.    "
},
{
  "id": "session27-p9-3",
  "level": "2",
  "url": "session27-p9.html#session27-p9-3",
  "type": "Example",
  "number": "5.41.1",
  "title": "Exercise 8: (Part 1).",
  "body": " Exercise 8: (Part 1)   Any parallel pair of maps in sets...    I'm going out on a limb with my metagaming here and hypothesize that the arrows named by the equalizer are related to the either the section of the product or retraction from the sum . The diagram below the problem and choice of letter are just too convenient.  Let's consider a simple example defined by and . The output of would be the sequence and the output of would be the sequence .  I'm thinking that my equalizer should be the map that produces a sequences of indices where have the same outputs. These two sequences match up for the first 3 of every 6 steps, producing the sequence the sequence . This map can be defined by the formula , but it strikes me as interesting that we kind of need to step out through in order to do division.  So how can I demonstrate that is an equalizer? Well, it makes sense that because there are countably infinite solutions to . It is also true that for each such that there is exactly one such that because is strictly monotonic and therefore one-to-one. In this case our would be uniquely defined by its relation to the inverse of . I could probably even work out for my particular example if I had to, but I think I'm already trivializing the proof I'm looking for by choosing an example where in the first place.  I think what's going on here is that we can test for equality two different ways by checking if or . For any point where , it must be true that and . Even if we have , we'd still be guaranteed to have the sum and . Perhaps the trick to this will be expressing and in terms of the initial and terminal objects.  Let's come back to the original question, which had to deal with an arbitrary equalizer to an arbitrary pair of parallel maps . By definition, and for every for which , there is exactly one for which .  Perhaps we can break this down in four cases:    is neither initial nor terminal     is initial but not terminal     is terminal but not initial     is both initial and terminal     For an initial object , we'd be able to express a zero map  through the following composition: Since that map is unique, for all .  If is an initial object then it would be isomorphic to . This gives us maps and satisfying and . Effectively, the unique map would meet the definition of an equalizer because and would both need to be unique map .  So what if is not an initial object? The definition of implies that the map is unique, but  not being intial implies this map is non-invertible: there is no retraction . That in turn gives us a pair of maps satisfying and a unique map such that . Maybe this is where I need to invoke the product?  I think I'll need to spend some more time on this.   "
},
{
  "id": "session27-p10",
  "level": "1",
  "url": "session27-p10.html",
  "type": "Section",
  "number": "5.42",
  "title": "Session 27: Examples of universal constructions, Part 10",
  "body": " Session 27: Examples of universal constructions, Part 10  This is the first session to go into double digit parts. That's okay though. I haven't had as much time to work on this and I feel like working out before moving on will be necessary for understanding what comes next.   Exercise 8: (Part 2\/2)   Parallel maps continued...    I think this time I want to approach this more visually. After all, the question explicitly talks about the graph reprepresentation. Let's start with another simple example of parallel maps .     I tried to make sure these maps were neither onto nor one-to-one, and tried to include a variety of relationships between mapped pairs. I'll keep the notation of red dashed for and blue dotted for as I go forward.  I think my simpliest non-trivial equalizer to this parallel pair of maps is the unique map defined by . Clearly in my diagram, and the map is uniquely defined. This equalizer would be illustrated by the solid arrow in the following diagram:     I use the extra qualifiers to exlude the maps from , because that's our initial object when we're working in . Maybe it would be appropriate to call these maps and , in an effort to enumerate all possible equalizers.  The next equalizer I see is the unique map .     Once again, it's both true that in the diagram and the map would need to be uniquely defined by domain and codomain.  We can find yet another example like this given by :     As before, we have both and unique. In fact, these maps are the only three maps for which .  I think where this gets complicated is that we can combine these maps through set union to produce new equalizers. Consider what happens the map such that there is a unique such that . When we compose this with we get the following:     Again, we have the case that and . For each of those two values, there are unique maps and that produce those two respective points in .  For the same reason, we should also have a equalizer :     Given that we seem to be okay to combine with or , what happens if we combine maps and together. Consider the following composite :     We still have the case that for in , but does this map satisfy the exactly one property?  At first, I didn't think it would, but I'm beginning to be more convinced that it does. There are unique maps and that could be paired one-to-one with the two unique maps and .  So let's take this one last step and combine all three into one last equalizer :     So, I think this gives me a set of 8 equalizers all together: , , , , , , , and . That last one strikes me as being special in that it combines all the others. It also strikes me as notable that there are exactly as many equalizers as points in , but that might just be a coincidence.  This is nice and all, but I think I'm straying from the question. I should really be concerned with the interpretation of this pair as defining a endomap on where I treat as the source and as the target. Let's see what happens to my last diagram when I add the arrows in :     Note that I could have just easily swap interpretations to make the source and the target.     In both cases, it would seem that the equalizer has the property that it maps points in to explicit self-loops of this endomap . With those fixed points, it doesn't matter which of is the source and target because they're both the same point anyway. Maybe that's all this exercise was looking for in the end?    Having hit what feels like an Occam's Razor type situation, I think I can stop here and start progressing again next week.  "
},
{
  "id": "session27-p10-3",
  "level": "2",
  "url": "session27-p10.html#session27-p10-3",
  "type": "Example",
  "number": "5.42.1",
  "title": "Exercise 8: (Part 2\/2).",
  "body": " Exercise 8: (Part 2\/2)   Parallel maps continued...    I think this time I want to approach this more visually. After all, the question explicitly talks about the graph reprepresentation. Let's start with another simple example of parallel maps .     I tried to make sure these maps were neither onto nor one-to-one, and tried to include a variety of relationships between mapped pairs. I'll keep the notation of red dashed for and blue dotted for as I go forward.  I think my simpliest non-trivial equalizer to this parallel pair of maps is the unique map defined by . Clearly in my diagram, and the map is uniquely defined. This equalizer would be illustrated by the solid arrow in the following diagram:     I use the extra qualifiers to exlude the maps from , because that's our initial object when we're working in . Maybe it would be appropriate to call these maps and , in an effort to enumerate all possible equalizers.  The next equalizer I see is the unique map .     Once again, it's both true that in the diagram and the map would need to be uniquely defined by domain and codomain.  We can find yet another example like this given by :     As before, we have both and unique. In fact, these maps are the only three maps for which .  I think where this gets complicated is that we can combine these maps through set union to produce new equalizers. Consider what happens the map such that there is a unique such that . When we compose this with we get the following:     Again, we have the case that and . For each of those two values, there are unique maps and that produce those two respective points in .  For the same reason, we should also have a equalizer :     Given that we seem to be okay to combine with or , what happens if we combine maps and together. Consider the following composite :     We still have the case that for in , but does this map satisfy the exactly one property?  At first, I didn't think it would, but I'm beginning to be more convinced that it does. There are unique maps and that could be paired one-to-one with the two unique maps and .  So let's take this one last step and combine all three into one last equalizer :     So, I think this gives me a set of 8 equalizers all together: , , , , , , , and . That last one strikes me as being special in that it combines all the others. It also strikes me as notable that there are exactly as many equalizers as points in , but that might just be a coincidence.  This is nice and all, but I think I'm straying from the question. I should really be concerned with the interpretation of this pair as defining a endomap on where I treat as the source and as the target. Let's see what happens to my last diagram when I add the arrows in :     Note that I could have just easily swap interpretations to make the source and the target.     In both cases, it would seem that the equalizer has the property that it maps points in to explicit self-loops of this endomap . With those fixed points, it doesn't matter which of is the source and target because they're both the same point anyway. Maybe that's all this exercise was looking for in the end?   "
},
{
  "id": "session27-p11",
  "level": "1",
  "url": "session27-p11.html",
  "type": "Section",
  "number": "5.43",
  "title": "Session 27: Examples of universal constructions, Part 11",
  "body": " Session 27: Examples of universal constructions, Part 11   Exercise 9: (Part 1\/?)   For any map ...    I don't know if this will become relevant, but I've got this overwhelming urge to complete the diagram above this problem:     My intuition suggests that the existence of a retraction like in the diagram depends whether or not . I think that's conceptually related to the dual of this exercise.  I think there's also an implication that the result I'm looking for follows from the universal property of products . This was defined over a (possibly empty) set of indices where each in defines a (possibly duplicated) object in the category .    A product is an object together with maps (one for each ), having the universal property:  Given any object and any maps (one for each ), there is exactly one map such that for each in .    In this hypothetical category with initial object and terminal object , there should be unique maps where satisfy the associative property. Let's start enumerating these objects of our category: , , , .  By the universalized definition of product, for any there should be a unique object and map , and maps for each such that for every . Since this product is also an object in the category, let's call it . What if we just need to iterate over all of these to handle the cases where and at the same time?  Let's start with . Any map would have to the unique map . Likewise, any would be the unique map , would be the unique map , would be the unique map , would be the unique map .  Let's move on . If any map existed, that would imply that is itself an intial object. We could then used the uniqueness of the inverse map to uniquely define the rest of the maps we're looking for through precomposition with the maps we saw previously. In fact, I think we can go one step further and assume that no exists for any .  Assuming that no map exists, then it seems reasonable to conclude that the only way can satisfy for all is if for all . I think this partially explains the wildcard notation of in the definition of .  The existence of some necessarily means we have maps . I'm thinking we could have takethe product that maps to the pair . and then somehow compare this with the projection map that pairs each with the respective . I'm thinking we can do this by stepping out somehow through a shared map .    I'm starting to get a little lost at this point, so I think I'll try to spend some more time on this later.  "
},
{
  "id": "session27-p11-2",
  "level": "2",
  "url": "session27-p11.html#session27-p11-2",
  "type": "Example",
  "number": "5.43.1",
  "title": "Exercise 9: (Part 1\/?).",
  "body": " Exercise 9: (Part 1\/?)   For any map ...    I don't know if this will become relevant, but I've got this overwhelming urge to complete the diagram above this problem:     My intuition suggests that the existence of a retraction like in the diagram depends whether or not . I think that's conceptually related to the dual of this exercise.  I think there's also an implication that the result I'm looking for follows from the universal property of products . This was defined over a (possibly empty) set of indices where each in defines a (possibly duplicated) object in the category .    A product is an object together with maps (one for each ), having the universal property:  Given any object and any maps (one for each ), there is exactly one map such that for each in .    In this hypothetical category with initial object and terminal object , there should be unique maps where satisfy the associative property. Let's start enumerating these objects of our category: , , , .  By the universalized definition of product, for any there should be a unique object and map , and maps for each such that for every . Since this product is also an object in the category, let's call it . What if we just need to iterate over all of these to handle the cases where and at the same time?  Let's start with . Any map would have to the unique map . Likewise, any would be the unique map , would be the unique map , would be the unique map , would be the unique map .  Let's move on . If any map existed, that would imply that is itself an intial object. We could then used the uniqueness of the inverse map to uniquely define the rest of the maps we're looking for through precomposition with the maps we saw previously. In fact, I think we can go one step further and assume that no exists for any .  Assuming that no map exists, then it seems reasonable to conclude that the only way can satisfy for all is if for all . I think this partially explains the wildcard notation of in the definition of .  The existence of some necessarily means we have maps . I'm thinking we could have takethe product that maps to the pair . and then somehow compare this with the projection map that pairs each with the respective . I'm thinking we can do this by stepping out somehow through a shared map .   "
},
{
  "id": "backmatter-2",
  "level": "1",
  "url": "backmatter-2.html",
  "type": "Colophon",
  "number": "",
  "title": "Colophon",
  "body": " This book was authored in PreTeXt .  "
}
]

var ptx_lunr_idx = lunr(function () {
  this.ref('id')
  this.field('title')
  this.field('body')
  this.metadataWhitelist = ['position']

  ptx_lunr_docs.forEach(function (doc) {
    this.add(doc)
  }, this)
})
