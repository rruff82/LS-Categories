<?xml version='1.0' encoding='utf-8'?>

<section xml:id="session25-p3">
    <title>Session 25: Labelings and products of graphs, Part 3</title>

    <p>
        I came back to Session 25 again this week to see if I could 
        make any progress.  I found it hard to focus on a single 
        problem though.  It feels like I'm still missing something
        important.  
    </p>

    <example>
        <title>Exercise 1: (Part 3/?)</title>
        <statement>
            <p>
                Continued proofreading...
            </p>
        </statement>
        <solution>
            <p>
                While <url href="https://github.com/rruff82/LS-Categories/blob/main/assets/notebooks/ls-ses25-p2.ipynb">
                    messing around in Python this week
                </url>, I decided to take a brute force to this problem.
                I used a brute-force method to search for structure preserving 
                maps to see if the shape I hypothesized earlier did anything
                interesting.
            </p>
            <p>
                I used couple of examples from the textbook to
                see if my search algorithm worked as expected.
                Specifically, the problems from the start of 
                Session 11, Session 15, along with Test 2 
                Question 2 all gave me some simple cases to verify.
                I notice that my original solution to Session 11
                Exercise 1 was off by 1!  My new algorithm 
                gave me a fourth map: the one where the loop 
                maps to a fixed point.
            </p>
            <p>
                With that in place, I testing out the sample
                graph I came up with in <xref ref="session25-p2">
                Session 25 Part 2</xref>.  I discovered a slight 
                problem, and that's that it divide my graphs into
                four parts instead of just two.  
            </p>
            <p>
                After experimenting with several simple graphs,
                I'm starting to think that the best candidate for
                this map <m>2_A</m> is the standard idempotent
                map: <m>\boxed{\bullet \longrightarrow \bullet \circlearrowleft}</m>.
                By identifying a map of graphs to this object, it 
                seems to sort out the generators of <q>tails</q>.
                More specifically, it identifies the points 
                of <m>X</m> which are not in the image 
                <m>\text{Im}_\alpha(X)</m> <mdash/> points 
                which are lost through the first application
                of <m>\alpha</m>.
            </p>
            <p>
                I think it remains to be seen whether this is 
                actually <m>2_A</m>, but at least it seems like it
                could be an useful property anyway. 
            </p>
        </solution>
    </example>
    <example>
        <title>Exercise 2: (Part 1/?)</title>
        <statement>
            <p>(a) Show that if a diagram of <em>sets</em>...</p>
        </statement>
        <solution>
            <p>
                We're given a generic sum diagram:
            </p>
            <image width="40%">
                <shortdescription>Generic sum</shortdescription>
                <latex-image>
                    \begin{tikzpicture}[scale=1.5]
                        \node (S1) at (0,0) {$S$};
                        \node (B1) at (1,1) {$B_1$};
                        \node (B2) at (1,-1) {$B_2$};
        
                        \path[-{stealth}]
                            (B1) edge node[above] {$j_1$} (S1)
                            (B2) edge node[below] {$j_2$} (S1)
                        ;
        
                    \end{tikzpicture}
                </latex-image>
            </image>
            <p>
                We're told this has the property of a coproduct
                <q>but restricted to testing against the one
                    cofigure type <m>Y=2</m></q>.  Our goal is to 
                use this to prove it's actually a coproduct.
            </p> 
            <p>
                The property in question is that for any 
                two maps <m>B_1 \xrightarrow{f_1} X</m>
                and <m>B_2 \xrightarrow{f_2} X</m>, there is
                exactly one map <m>S \xrightarrow{f} X</m> 
                such that <m>f_1 = f j_1</m> and <m>f_2 = f j_2</m>.
            </p>
            <p>
                We're only testing against the object <m>\mathbf{2}</m>,
                so our assumption is that for any maps 
                <m>B_1 \xrightarrow{f_1} \mathbf{2}</m>
                and <m>B_2 \xrightarrow{f_2} \mathbf{2}</m>, there
                is exactly one map <m>S \xrightarrow{f} \mathbf{2}</m>
                such that <m>f_1 = f j_1</m> and <m>f_2 = f j_2</m>.
            </p>
            <p>
                Let's assume the opposite.  Suppose <m>S</m> is not
                a sum.  There would need to be either <q>no maps</q>  
                <m>S \xrightarrow{f} \mathbf{2}</m>
                such that <m>f_1 = f j_1</m> and <m>f_2 = f j_2</m>, 
                or more than one such map.
            </p>   
            <p>
                At least one such map should exist as long as the 
                category contains an initial object. The unique
                maps from the initial object,
                 <m>I \rightarrow B_1</m> and <m>I \rightarrow B_2</m>,
                 can be composed with <m>f_1,f_2</m> 
                 to produce a unique pair of compositions 
                 <m>I \rightarrow B_1 \xrightarrow{f_1} \mathbf{2}</m>
                 and <m>I \rightarrow B_2 \xrightarrow{f_2} \mathbf{2}</m>
                .  Since there are exactly two maps here, the set of 
                these maps is isomorphic to the set <m>\mathbf{2}</m>.
            </p>
            <p>
                Suppose that another triple of maps
                <m>g: S \rightarrow \mathbf{2},k_1: S \rightarrow B_1,k_2: S \rightarrow B_2 </m>
                has the same property as <m>f</m>.  If <m>f \neq q</m>,
                there exists some <m>s \in S</m> such that <m>f s \neq g s</m>.
                Applying <m>f_1</m> to this <m>s</m> gives us
                <m>f_1 s = f j_1 s = f_1 s = g k_1 s</m>. 
                Applying <m>f_2</m> to this <m>s</m> gives us
                <m>f_2 s = f j_2 s = f_2 s = g k_2 s</m>.
                However, there are only two objects in <m>\mathbf{2}</m>
                and we already know <m>f_1 s \neq f_2 s</m> by virtue of 
                the domains being different.  The contradiction implies
                <m>f</m> and <m>g</m> are the same map.
            </p>
            <p>
                For part (b), I think I'd like to look at the these through
                the lens of an adjacency matrix.  The generic sum
                corresponds with a set of <m>\mathbf{5}</m> objects:
                three <q>dots</q> and <q>two arrows</q>.  The three
                dots can be detemine as the dimension of
                the matrix to be <m>3 \times 3</m> matrix with
                <m>2</m> non-zero elements corresponding to the arrows.
                Specifically, the matrix would be given by
                <m>\begin{bmatrix} 0 &amp; 0 &amp;1 \\
                    0 &amp; 0 &amp; 1 \\
                    0 &amp; 0 &amp; 0 \end{bmatrix} </m>
                .
            </p>
            <p>
                There's a unique map which maps each of the 
                three dots to itself, corresponding to the 
                identity matrix:
                <m>\begin{bmatrix} 1 &amp; 0 &amp; 0 \\
                    0 &amp; 1 &amp; 0 \\
                    0 &amp; 0 &amp; 1 \end{bmatrix} </m>
            </p>
            <p>
                We can think of our <q>sum</q> as producing 
                a pair of <m>3 \times 1</m> matrices 
                given by <m>\begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix} </m>
                and <m>\begin{bmatrix} 0 \\ 1 \\ 0 \end{bmatrix} </m>
                that inject a single dot into the set of three dots,
                into the positions that will be mapped to the third dot
                by our adjacency matrix. We know there's an isomorphism
                here because multiplying by  <m>\begin{bmatrix} 0 &amp; 1 &amp; 0 \\
                    1 &amp; 0 &amp; 0 \\
                    0 &amp; 0 &amp; 1 \end{bmatrix} </m> swaps the roles
                    of the two points and is invertable by iterating 
                    a second time.
            </p>
            <p>
                If my hypothesis about Exercise 1 is correct,
                the figure <m>2_D</m> corresponds with the matrix
                <m>\begin{bmatrix} 1 &amp; 1  \\
                  1 &amp; 1 \end{bmatrix} </m> and <m>2_A</m>
                  corresponds with <m>\begin{bmatrix} 1 &amp; 1  \\
                    0 &amp; 0 \end{bmatrix} </m>.  Each of these has
                a complement formed by subtracting every element from 
                <m>1</m>.  In this case, the complement of
                <m>\begin{bmatrix} 1 &amp; 1  \\
                    1 &amp; 1 \end{bmatrix} </m> is 
                    <m>\begin{bmatrix} 0 &amp; 0  \\
                        0 &amp; 0 \end{bmatrix} </m> and the complement
                        of <m>\begin{bmatrix} 1 &amp; 1  \\
             0 &amp; 0 \end{bmatrix} </m> is <m>\begin{bmatrix} 0 &amp; 0  \\
                1 &amp; 1 \end{bmatrix} </m>.  The reason this strikes 
                me as curious is that we can go from 
                 <m>\begin{bmatrix} 0 &amp; 0  \\
                       1 &amp; 1 \end{bmatrix} </m> back to 
                       <m>\begin{bmatrix} 1 &amp; 1  \\
                        0 &amp; 0 \end{bmatrix} </m> by muliplying 
                       with <m>\begin{bmatrix} 0 &amp; 1  \\
                        1 &amp; 0 \end{bmatrix} </m> but no matrix
                        multiplication will take us from
                        <m>\begin{bmatrix} 0 &amp; 0  \\
                            0 &amp; 0 \end{bmatrix} </m> back to <m>\begin{bmatrix} 1 &amp; 1  \\
                            1 &amp; 1 \end{bmatrix} </m>
                            . 
            </p>
            <p>
                I think the idea here is that while there's isomorphisms
                from <m>\mathbf{2} \leftrightarrows 2_D</m> 
                and <m>\mathbf{2} \leftrightarrows 2_A</m>, there's a retraction
                but it's not structure preserving.  Two disjoint arrows
                corresponds to the <m>4 \times 4</m> matrix
                <m>\begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 0  \\
                    0 &amp; 0 &amp; 0 &amp; 0 \\
                    0 &amp; 0 &amp; 0 &amp; 1 \\
                    0 &amp; 0 &amp; 0 &amp; 0 \end{bmatrix} </m>,
                there's only one matrix that will send those two
                arrows to the ones in our sum.
            </p>
            <p>
                I'm not really sure where I'm going with this anymore,
                so maybe I'll come back later.
            </p>
        </solution>
    </example>
    <example>
        <title>Exercise 3: (Part 1/?)</title>
        <statement>
            <p>
                <em>Tricoloring</em> a graph...
            </p>
        </statement>
        <solution>
    
            <p>
                You'll find me exploring this a little in Python if you
                look at the code I checked in, so I may as well document 
                what I observed.
            </p>
            <p>
                I thought I could get away with NetworkX's <c>greedy_color</c>
                at first, but it didn't quite behave as described.  After
                manually verifying a coloring first, I came up with 
                an algorithm that produces a tricoloring from the presentation
                of the graph.  It seemed to work for both of the endomaps from
                Session 15.
            </p>
            <p>
                Implementing doesn't address either of the two parts to this 
                question though.  I found the use of parity in this implementation
                kind of interesting.  It reminds me of an old programming problem
                where you have a linked links and want to determine if it contains
                a cycle.  One of the ways you can approach it is to iterate
                through the list with pointers that skip elements at 
                two relatively prime rates, i.e. by 2s and 3s.  If you reach
                the end of the list, great, there's no loops.  If the list 
                loops, at somepoint your pointers will overlap and you can 
                terminate the program. 
            </p>
            <p>
                I'm going to have to comeback to see how this induced
                coloring works, but I think there's an important connection
                to be made here.
            </p>
        
        </solution>
    </example>
    <example>
        <title>Exercise 4: (Part 1/?)</title>
        <statement>
            <p>
                In this exercise, ...
            </p>
        </statement>
        <solution>
            <p>
                Again, I didn't make too much progress here but did
                check in some Python code that seemed relevant.
                Considering my hypotheses about the role of adjacency
                matrices in representating graphs, there seems to 
                be a corresponding map that encodes the values 
                of an adjacency matrix into the <q>bits</q> of 
                an integer.  While this method doesn't work 
                for all graphs, the fact that it could work
                for endomaps seems very releavant to this question.
            </p>
        </solution>
    </example>
    <p>
        Not as much progress as I'd hoped, but 
        any progress is progress...
    </p>

   
</section>